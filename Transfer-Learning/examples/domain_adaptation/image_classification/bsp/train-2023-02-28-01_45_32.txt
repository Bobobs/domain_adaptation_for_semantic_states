Namespace(arch='convnext_base', batch_size=32, bottleneck_dim=256, data='Office31', epochs=20, iters_per_epoch=1000, log='bsp', lr=0.003, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', pretrain=None, pretrain_epochs=3, pretrain_lr=0.001, print_freq=100, ratio=[0.75, 1.3333333333333333], resize_size=224, root='data/office31', scale=[0.08, 1.0], scratch=False, seed=None, source=['A'], target=['W'], trade_off=1.0, trade_off_bsp=0.0002, train_resizing='default', val_resizing='default', weight_decay=0.001, workers=2)
=> using model 'convnext_base'
Pretraining the model on source domain.
/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:257: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
lr: [0.0001, 0.001, 0.001]
Epoch: [0][   0/1000]	Time 2.9 (2.9)	Data 0.0 (0.0)	Loss 2.41 (2.41)	Cls Acc 6.2 (6.2)
Epoch: [0][ 100/1000]	Time 0.7 (0.7)	Data 0.2 (0.2)	Loss 1.34 (1.56)	Cls Acc 53.1 (46.8)
Epoch: [0][ 200/1000]	Time 0.8 (0.7)	Data 0.3 (0.2)	Loss 1.16 (1.34)	Cls Acc 59.4 (53.9)
Epoch: [0][ 300/1000]	Time 0.8 (0.7)	Data 0.2 (0.2)	Loss 1.39 (1.21)	Cls Acc 50.0 (58.6)
Epoch: [0][ 400/1000]	Time 0.9 (0.7)	Data 0.3 (0.1)	Loss 1.07 (1.13)	Cls Acc 56.2 (61.6)
Epoch: [0][ 500/1000]	Time 0.8 (0.7)	Data 0.3 (0.1)	Loss 0.46 (1.06)	Cls Acc 84.4 (63.8)
Epoch: [0][ 600/1000]	Time 1.1 (0.7)	Data 0.6 (0.1)	Loss 0.52 (1.01)	Cls Acc 81.2 (65.5)
Epoch: [0][ 700/1000]	Time 0.8 (0.7)	Data 0.3 (0.1)	Loss 0.51 (0.97)	Cls Acc 81.2 (66.6)
Epoch: [0][ 800/1000]	Time 0.8 (0.7)	Data 0.3 (0.1)	Loss 0.59 (0.94)	Cls Acc 78.1 (67.8)
Epoch: [0][ 900/1000]	Time 0.9 (0.7)	Data 0.3 (0.1)	Loss 0.60 (0.92)	Cls Acc 81.2 (68.7)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:136: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top2, predicted2 = torch.topk(sm(output.data), 2, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:137: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top3, predicted3 = torch.topk(sm(output.data), 3, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:138: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top9, predicted9 = torch.topk(sm(output.data), 9, dim=1, largest=True, sorted=True)
Test: [  0/295]	Time  1.328 ( 1.328)	Loss 3.9857e-01 (3.9857e-01)	Acc@1  87.50 ( 87.50)
Test: [100/295]	Time  0.502 ( 0.371)	Loss 4.1937e-01 (3.7914e-01)	Acc@1  93.75 ( 90.59)
Test: [200/295]	Time  0.692 ( 0.362)	Loss 3.1232e-01 (3.7141e-01)	Acc@1  93.75 ( 91.04)
 * Acc@1 90.967
lr: [5.946035575013605e-05, 0.0005946035575013605, 0.0005946035575013605]
Epoch: [1][   0/1000]	Time 0.6 (0.6)	Data 0.0 (0.0)	Loss 0.67 (0.67)	Cls Acc 71.9 (71.9)
Epoch: [1][ 100/1000]	Time 0.6 (0.7)	Data 0.0 (0.1)	Loss 0.61 (0.67)	Cls Acc 71.9 (76.4)
Epoch: [1][ 200/1000]	Time 0.8 (0.7)	Data 0.3 (0.1)	Loss 0.47 (0.65)	Cls Acc 84.4 (76.9)
Epoch: [1][ 300/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.58 (0.65)	Cls Acc 87.5 (76.9)
Epoch: [1][ 400/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.57 (0.65)	Cls Acc 84.4 (77.2)
Epoch: [1][ 500/1000]	Time 0.8 (0.7)	Data 0.3 (0.1)	Loss 0.68 (0.65)	Cls Acc 84.4 (77.1)
Epoch: [1][ 600/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.76 (0.64)	Cls Acc 68.8 (77.1)
Epoch: [1][ 700/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.68 (0.64)	Cls Acc 81.2 (77.5)
Epoch: [1][ 800/1000]	Time 0.8 (0.7)	Data 0.3 (0.1)	Loss 0.74 (0.63)	Cls Acc 71.9 (77.5)
Epoch: [1][ 900/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.60 (0.63)	Cls Acc 68.8 (77.5)
Test: [  0/295]	Time  1.147 ( 1.147)	Loss 2.8702e-01 (2.8702e-01)	Acc@1  93.75 ( 93.75)
Test: [100/295]	Time  0.179 ( 0.361)	Loss 3.3652e-01 (2.9561e-01)	Acc@1  87.50 ( 93.19)
Test: [200/295]	Time  0.121 ( 0.356)	Loss 2.4460e-01 (2.9023e-01)	Acc@1  93.75 ( 93.56)
 * Acc@1 93.326
lr: [4.3869133765083086e-05, 0.0004386913376508308, 0.0004386913376508308]
Epoch: [2][   0/1000]	Time 0.6 (0.6)	Data 0.0 (0.0)	Loss 0.53 (0.53)	Cls Acc 87.5 (87.5)
Epoch: [2][ 100/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.28 (0.62)	Cls Acc 87.5 (78.0)
Epoch: [2][ 200/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.33 (0.62)	Cls Acc 90.6 (77.7)
Epoch: [2][ 300/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.42 (0.61)	Cls Acc 87.5 (78.1)
Epoch: [2][ 400/1000]	Time 0.8 (0.7)	Data 0.3 (0.1)	Loss 0.59 (0.60)	Cls Acc 78.1 (78.5)
Epoch: [2][ 500/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.69 (0.59)	Cls Acc 78.1 (78.5)
Epoch: [2][ 600/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.77 (0.59)	Cls Acc 65.6 (78.7)
Epoch: [2][ 700/1000]	Time 0.8 (0.7)	Data 0.3 (0.1)	Loss 0.48 (0.59)	Cls Acc 81.2 (78.7)
Epoch: [2][ 800/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.38 (0.58)	Cls Acc 90.6 (78.8)
Epoch: [2][ 900/1000]	Time 0.7 (0.7)	Data 0.1 (0.1)	Loss 0.54 (0.58)	Cls Acc 84.4 (78.8)
Test: [  0/295]	Time  0.952 ( 0.952)	Loss 2.7518e-01 (2.7518e-01)	Acc@1  93.75 ( 93.75)
Test: [100/295]	Time  0.561 ( 0.376)	Loss 3.2591e-01 (2.6365e-01)	Acc@1  87.50 ( 92.88)
Test: [200/295]	Time  0.118 ( 0.363)	Loss 2.2964e-01 (2.5708e-01)	Acc@1  93.75 ( 93.84)
 * Acc@1 93.666
Pretraining process is done.
after pretraining lr: 0.00030000000000000003
Epoch: [0][   0/1000]	Time  3.44 ( 3.44)	Data  0.01 ( 0.01)	Loss   2.18 (  2.18)	Cls Acc 65.6 (65.6)	Domain Acc 42.2 (42.2)
Epoch: [0][ 100/1000]	Time  1.28 ( 1.29)	Data  0.02 ( 0.02)	Loss   1.18 (  1.54)	Cls Acc 81.2 (77.7)	Domain Acc 92.2 (85.9)
Epoch: [0][ 200/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.40 (  1.41)	Cls Acc 71.9 (77.9)	Domain Acc 98.4 (90.2)
Epoch: [0][ 300/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.11 (  1.33)	Cls Acc 81.2 (78.1)	Domain Acc 96.9 (92.2)
Epoch: [0][ 400/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.43 (  1.29)	Cls Acc 68.8 (78.2)	Domain Acc 90.6 (92.6)
Epoch: [0][ 500/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   2.73 (  1.44)	Cls Acc 71.9 (78.0)	Domain Acc 64.1 (88.7)
Epoch: [0][ 600/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.50 (  1.55)	Cls Acc 78.1 (77.5)	Domain Acc 82.8 (85.6)
Epoch: [0][ 700/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.75 (  1.56)	Cls Acc 62.5 (77.4)	Domain Acc 73.4 (84.2)
Epoch: [0][ 800/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   2.25 (  1.56)	Cls Acc 65.6 (77.4)	Domain Acc 53.1 (82.8)
Epoch: [0][ 900/1000]	Time  1.28 ( 1.29)	Data  0.02 ( 0.02)	Loss   1.45 (  1.56)	Cls Acc 78.1 (77.3)	Domain Acc 81.2 (81.7)
Test: [  0/295]	Time  0.984 ( 0.984)	Loss 3.2150e-01 (3.2150e-01)	Acc@1 100.00 (100.00)
Test: [100/295]	Time  0.119 ( 0.362)	Loss 3.7200e-01 (3.3802e-01)	Acc@1  93.75 ( 92.95)
Test: [200/295]	Time  0.245 ( 0.356)	Loss 3.1274e-01 (3.3192e-01)	Acc@1  93.75 ( 93.50)
 * Acc@1 93.433
after pretraining lr: 0.00017838106725040818
Epoch: [1][   0/1000]	Time  1.25 ( 1.25)	Data  0.02 ( 0.02)	Loss   1.72 (  1.72)	Cls Acc 68.8 (68.8)	Domain Acc 71.9 (71.9)
Epoch: [1][ 100/1000]	Time  1.27 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.83 (  1.59)	Cls Acc 71.9 (77.2)	Domain Acc 60.9 (69.1)
Epoch: [1][ 200/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.59 (  1.66)	Cls Acc 87.5 (76.9)	Domain Acc 62.5 (65.7)
Epoch: [1][ 300/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.41 (  1.69)	Cls Acc 81.2 (76.8)	Domain Acc 71.9 (63.2)
Epoch: [1][ 400/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.67 (  1.65)	Cls Acc 78.1 (77.3)	Domain Acc 51.6 (63.6)
Epoch: [1][ 500/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.24 (  1.64)	Cls Acc 87.5 (77.4)	Domain Acc 68.8 (63.2)
Epoch: [1][ 600/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.59 (  1.63)	Cls Acc 81.2 (77.4)	Domain Acc 54.7 (62.7)
Epoch: [1][ 700/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.63 (  1.62)	Cls Acc 78.1 (77.4)	Domain Acc 62.5 (62.9)
Epoch: [1][ 800/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   2.01 (  1.62)	Cls Acc 81.2 (77.7)	Domain Acc 35.9 (62.4)
Epoch: [1][ 900/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.54 (  1.61)	Cls Acc 84.4 (77.8)	Domain Acc 50.0 (62.6)
Test: [  0/295]	Time  1.137 ( 1.137)	Loss 3.6260e-01 (3.6260e-01)	Acc@1  93.75 ( 93.75)
Test: [100/295]	Time  0.118 ( 0.370)	Loss 3.4491e-01 (2.9221e-01)	Acc@1  87.50 ( 94.25)
Test: [200/295]	Time  0.118 ( 0.361)	Loss 2.5668e-01 (2.9425e-01)	Acc@1  93.75 ( 94.34)
 * Acc@1 94.495
after pretraining lr: 0.00013160740129524923
Epoch: [2][   0/1000]	Time  1.24 ( 1.24)	Data  0.02 ( 0.02)	Loss   1.43 (  1.43)	Cls Acc 71.9 (71.9)	Domain Acc 71.9 (71.9)
Epoch: [2][ 100/1000]	Time  1.27 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.46 (  1.55)	Cls Acc 75.0 (77.7)	Domain Acc 53.1 (57.7)
Epoch: [2][ 200/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.97 (  1.53)	Cls Acc 78.1 (77.8)	Domain Acc 34.4 (58.8)
Epoch: [2][ 300/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.65 (  1.59)	Cls Acc 68.8 (77.4)	Domain Acc 62.5 (57.0)
Epoch: [2][ 400/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.62 (  1.61)	Cls Acc 59.4 (77.4)	Domain Acc 68.8 (56.1)
Epoch: [2][ 500/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.59 (  1.59)	Cls Acc 71.9 (77.6)	Domain Acc 54.7 (56.8)
Epoch: [2][ 600/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.48 (  1.59)	Cls Acc 84.4 (77.6)	Domain Acc 57.8 (56.1)
Epoch: [2][ 700/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   0.99 (  1.58)	Cls Acc 90.6 (77.7)	Domain Acc 81.2 (56.1)
Epoch: [2][ 800/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.36 (  1.57)	Cls Acc 87.5 (77.7)	Domain Acc 62.5 (56.7)
Epoch: [2][ 900/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.97 (  1.56)	Cls Acc 65.6 (77.8)	Domain Acc 42.2 (56.3)
Test: [  0/295]	Time  0.990 ( 0.990)	Loss 3.3111e-01 (3.3111e-01)	Acc@1  93.75 ( 93.75)
Test: [100/295]	Time  0.578 ( 0.365)	Loss 3.8121e-01 (2.8309e-01)	Acc@1  87.50 ( 93.44)
Test: [200/295]	Time  0.577 ( 0.359)	Loss 2.6394e-01 (2.8540e-01)	Acc@1  87.50 ( 93.72)
 * Acc@1 93.581
after pretraining lr: 0.00010606601717798215
Epoch: [3][   0/1000]	Time  1.24 ( 1.24)	Data  0.01 ( 0.01)	Loss   1.50 (  1.50)	Cls Acc 75.0 (75.0)	Domain Acc 59.4 (59.4)
Epoch: [3][ 100/1000]	Time  1.27 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.70 (  1.54)	Cls Acc 75.0 (78.5)	Domain Acc 59.4 (52.3)
Epoch: [3][ 200/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.61 (  1.52)	Cls Acc 78.1 (78.4)	Domain Acc 59.4 (53.9)
Epoch: [3][ 300/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.24 (  1.48)	Cls Acc 78.1 (78.9)	Domain Acc 65.6 (54.9)
Epoch: [3][ 400/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.32 (  1.46)	Cls Acc 87.5 (79.0)	Domain Acc 57.8 (56.7)
Epoch: [3][ 500/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.68 (  1.46)	Cls Acc 65.6 (78.9)	Domain Acc 48.4 (57.0)
Epoch: [3][ 600/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.22 (  1.46)	Cls Acc 78.1 (78.9)	Domain Acc 73.4 (56.3)
Epoch: [3][ 700/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.54 (  1.45)	Cls Acc 78.1 (79.1)	Domain Acc 64.1 (57.0)
Epoch: [3][ 800/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.65 (  1.44)	Cls Acc 59.4 (79.1)	Domain Acc 57.8 (57.4)
Epoch: [3][ 900/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.35 (  1.44)	Cls Acc 75.0 (79.2)	Domain Acc 59.4 (57.7)
Test: [  0/295]	Time  0.999 ( 0.999)	Loss 2.9871e-01 (2.9871e-01)	Acc@1  93.75 ( 93.75)
Test: [100/295]	Time  0.620 ( 0.365)	Loss 4.1103e-01 (3.1542e-01)	Acc@1  87.50 ( 94.68)
Test: [200/295]	Time  0.450 ( 0.356)	Loss 2.6294e-01 (3.1558e-01)	Acc@1  93.75 ( 94.96)
 * Acc@1 95.069
after pretraining lr: 8.972092687327323e-05
Epoch: [4][   0/1000]	Time  1.24 ( 1.24)	Data  0.01 ( 0.01)	Loss   1.23 (  1.23)	Cls Acc 84.4 (84.4)	Domain Acc 57.8 (57.8)
Epoch: [4][ 100/1000]	Time  1.27 ( 1.30)	Data  0.02 ( 0.05)	Loss   1.26 (  1.32)	Cls Acc 90.6 (79.7)	Domain Acc 59.4 (67.5)
Epoch: [4][ 200/1000]	Time  1.27 ( 1.29)	Data  0.02 ( 0.03)	Loss   1.33 (  1.36)	Cls Acc 81.2 (79.8)	Domain Acc 51.6 (63.2)
Epoch: [4][ 300/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.14 (  1.37)	Cls Acc 93.8 (80.1)	Domain Acc 57.8 (60.7)
Epoch: [4][ 400/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.62 (  1.39)	Cls Acc 87.5 (79.8)	Domain Acc 31.2 (59.5)
Epoch: [4][ 500/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.32 (  1.40)	Cls Acc 87.5 (79.9)	Domain Acc 43.8 (58.0)
Epoch: [4][ 600/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.35 (  1.40)	Cls Acc 81.2 (80.0)	Domain Acc 62.5 (58.1)
Epoch: [4][ 700/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.54 (  1.39)	Cls Acc 71.9 (80.0)	Domain Acc 60.9 (58.3)
Epoch: [4][ 800/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.36 (  1.39)	Cls Acc 84.4 (80.0)	Domain Acc 59.4 (58.0)
Epoch: [4][ 900/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.29 (  1.38)	Cls Acc 78.1 (80.1)	Domain Acc 51.6 (58.4)
Test: [  0/295]	Time  1.030 ( 1.030)	Loss 2.5228e-01 (2.5228e-01)	Acc@1  87.50 ( 87.50)
Test: [100/295]	Time  0.119 ( 0.376)	Loss 3.3792e-01 (2.2786e-01)	Acc@1  93.75 ( 95.48)
Test: [200/295]	Time  0.118 ( 0.364)	Loss 1.6781e-01 (2.2682e-01)	Acc@1 100.00 ( 95.52)
 * Acc@1 95.494
after pretraining lr: 7.825422900366438e-05
Epoch: [5][   0/1000]	Time  1.25 ( 1.25)	Data  0.02 ( 0.02)	Loss   1.38 (  1.38)	Cls Acc 75.0 (75.0)	Domain Acc 60.9 (60.9)
Epoch: [5][ 100/1000]	Time  1.27 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.26 (  1.41)	Cls Acc 84.4 (79.9)	Domain Acc 53.1 (54.3)
Epoch: [5][ 200/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.14 (  1.40)	Cls Acc 87.5 (79.6)	Domain Acc 60.9 (53.9)
Epoch: [5][ 300/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.30 (  1.38)	Cls Acc 84.4 (80.0)	Domain Acc 59.4 (56.1)
Epoch: [5][ 400/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.23 (  1.37)	Cls Acc 81.2 (79.9)	Domain Acc 81.2 (56.6)
Epoch: [5][ 500/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.20 (  1.36)	Cls Acc 81.2 (80.1)	Domain Acc 53.1 (57.0)
Epoch: [5][ 600/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.33 (  1.36)	Cls Acc 84.4 (80.1)	Domain Acc 56.2 (56.7)
Epoch: [5][ 700/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.55 (  1.35)	Cls Acc 78.1 (80.3)	Domain Acc 42.2 (57.7)
Epoch: [5][ 800/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.55 (  1.34)	Cls Acc 68.8 (80.3)	Domain Acc 68.8 (58.1)
Epoch: [5][ 900/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.51 (  1.34)	Cls Acc 75.0 (80.3)	Domain Acc 54.7 (57.8)
Test: [  0/295]	Time  0.977 ( 0.977)	Loss 3.2163e-01 (3.2163e-01)	Acc@1  87.50 ( 87.50)
Test: [100/295]	Time  0.553 ( 0.374)	Loss 3.1786e-01 (2.4348e-01)	Acc@1  87.50 ( 94.55)
Test: [200/295]	Time  0.568 ( 0.362)	Loss 2.6464e-01 (2.4501e-01)	Acc@1  87.50 ( 94.90)
 * Acc@1 94.963
after pretraining lr: 6.971042407276225e-05
Epoch: [6][   0/1000]	Time  1.24 ( 1.24)	Data  0.01 ( 0.01)	Loss   1.10 (  1.10)	Cls Acc 84.4 (84.4)	Domain Acc 64.1 (64.1)
Epoch: [6][ 100/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.50 (  1.30)	Cls Acc 75.0 (80.8)	Domain Acc 59.4 (61.2)
Epoch: [6][ 200/1000]	Time  1.27 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.48 (  1.30)	Cls Acc 71.9 (80.6)	Domain Acc 51.6 (62.2)
Epoch: [6][ 300/1000]	Time  1.27 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.04 (  1.31)	Cls Acc 90.6 (80.2)	Domain Acc 65.6 (60.6)
Epoch: [6][ 400/1000]	Time  1.27 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.31 (  1.31)	Cls Acc 81.2 (80.2)	Domain Acc 73.4 (60.6)
Epoch: [6][ 500/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.37 (  1.32)	Cls Acc 75.0 (80.5)	Domain Acc 71.9 (59.1)
Epoch: [6][ 600/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.39 (  1.31)	Cls Acc 78.1 (80.8)	Domain Acc 65.6 (59.7)
Epoch: [6][ 700/1000]	Time  1.26 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.29 (  1.31)	Cls Acc 75.0 (80.6)	Domain Acc 65.6 (59.6)
Epoch: [6][ 800/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.37 (  1.31)	Cls Acc 75.0 (80.8)	Domain Acc 53.1 (59.8)
Epoch: [6][ 900/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.35 (  1.31)	Cls Acc 78.1 (80.9)	Domain Acc 70.3 (60.1)
Test: [  0/295]	Time  1.126 ( 1.126)	Loss 3.2358e-01 (3.2358e-01)	Acc@1  93.75 ( 93.75)
Test: [100/295]	Time  0.399 ( 0.359)	Loss 2.6091e-01 (2.2946e-01)	Acc@1  93.75 ( 95.73)
Test: [200/295]	Time  0.396 ( 0.353)	Loss 2.1240e-01 (2.3293e-01)	Acc@1  93.75 ( 95.62)
 * Acc@1 95.537
after pretraining lr: 6.306723114402858e-05
Epoch: [7][   0/1000]	Time  1.25 ( 1.25)	Data  0.01 ( 0.01)	Loss   1.24 (  1.24)	Cls Acc 84.4 (84.4)	Domain Acc 71.9 (71.9)
Epoch: [7][ 100/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.31 (  1.26)	Cls Acc 90.6 (80.4)	Domain Acc 45.3 (62.6)
Epoch: [7][ 200/1000]	Time  1.26 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.58 (  1.28)	Cls Acc 75.0 (81.2)	Domain Acc 59.4 (60.4)
Epoch: [7][ 300/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.19 (  1.29)	Cls Acc 84.4 (80.7)	Domain Acc 75.0 (59.2)
Epoch: [7][ 400/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.34 (  1.29)	Cls Acc 78.1 (80.8)	Domain Acc 54.7 (59.3)
Epoch: [7][ 500/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.34 (  1.28)	Cls Acc 78.1 (81.1)	Domain Acc 60.9 (59.5)
Epoch: [7][ 600/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.15 (  1.28)	Cls Acc 90.6 (81.3)	Domain Acc 48.4 (59.5)
Epoch: [7][ 700/1000]	Time  1.26 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.09 (  1.28)	Cls Acc 90.6 (81.3)	Domain Acc 64.1 (59.3)
Epoch: [7][ 800/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.64 (  1.29)	Cls Acc 65.6 (81.2)	Domain Acc 67.2 (59.0)
Epoch: [7][ 900/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.08 (  1.30)	Cls Acc 84.4 (81.3)	Domain Acc 70.3 (57.7)
Test: [  0/295]	Time  1.112 ( 1.112)	Loss 2.9901e-01 (2.9901e-01)	Acc@1  93.75 ( 93.75)
Test: [100/295]	Time  0.565 ( 0.370)	Loss 2.5466e-01 (2.1809e-01)	Acc@1  93.75 ( 95.24)
Test: [200/295]	Time  0.571 ( 0.362)	Loss 1.5923e-01 (2.2150e-01)	Acc@1  93.75 ( 95.27)
 * Acc@1 95.324
after pretraining lr: 5.7735026918962585e-05
Epoch: [8][   0/1000]	Time  1.24 ( 1.24)	Data  0.01 ( 0.01)	Loss   1.16 (  1.16)	Cls Acc 81.2 (81.2)	Domain Acc 57.8 (57.8)
Epoch: [8][ 100/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.38 (  1.28)	Cls Acc 71.9 (81.7)	Domain Acc 54.7 (59.9)
Epoch: [8][ 200/1000]	Time  1.28 ( 1.29)	Data  0.02 ( 0.03)	Loss   1.13 (  1.29)	Cls Acc 84.4 (81.7)	Domain Acc 60.9 (58.3)
Epoch: [8][ 300/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.19 (  1.28)	Cls Acc 84.4 (81.7)	Domain Acc 54.7 (57.9)
Epoch: [8][ 400/1000]	Time  1.26 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.21 (  1.27)	Cls Acc 78.1 (81.7)	Domain Acc 73.4 (59.1)
Epoch: [8][ 500/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.20 (  1.27)	Cls Acc 87.5 (81.7)	Domain Acc 57.8 (58.9)
Epoch: [8][ 600/1000]	Time  1.26 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.18 (  1.27)	Cls Acc 84.4 (81.5)	Domain Acc 64.1 (59.1)
Epoch: [8][ 700/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.06 (  1.27)	Cls Acc 90.6 (81.5)	Domain Acc 59.4 (59.3)
Epoch: [8][ 800/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.10 (  1.27)	Cls Acc 84.4 (81.6)	Domain Acc 64.1 (59.0)
Epoch: [8][ 900/1000]	Time  1.26 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.13 (  1.27)	Cls Acc 81.2 (81.7)	Domain Acc 76.6 (59.0)
Test: [  0/295]	Time  1.038 ( 1.038)	Loss 3.2237e-01 (3.2237e-01)	Acc@1  93.75 ( 93.75)
Test: [100/295]	Time  0.557 ( 0.366)	Loss 2.0243e-01 (2.1004e-01)	Acc@1  93.75 ( 95.61)
Test: [200/295]	Time  0.572 ( 0.358)	Loss 1.5033e-01 (2.0993e-01)	Acc@1 100.00 ( 95.65)
 * Acc@1 95.643
after pretraining lr: 5.334838230116769e-05
Epoch: [9][   0/1000]	Time  1.23 ( 1.23)	Data  0.01 ( 0.01)	Loss   1.06 (  1.06)	Cls Acc 96.9 (96.9)	Domain Acc 56.2 (56.2)
Epoch: [9][ 100/1000]	Time  1.27 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.11 (  1.22)	Cls Acc 90.6 (81.3)	Domain Acc 45.3 (62.7)
Epoch: [9][ 200/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.39 (  1.24)	Cls Acc 71.9 (81.9)	Domain Acc 59.4 (58.6)
Epoch: [9][ 300/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.63 (  1.24)	Cls Acc 68.8 (81.8)	Domain Acc 46.9 (60.0)
Epoch: [9][ 400/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.14 (  1.24)	Cls Acc 87.5 (82.0)	Domain Acc 43.8 (60.5)
Epoch: [9][ 500/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.40 (  1.25)	Cls Acc 75.0 (82.0)	Domain Acc 70.3 (59.7)
Epoch: [9][ 600/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.05 (  1.24)	Cls Acc 84.4 (82.1)	Domain Acc 67.2 (59.8)
Epoch: [9][ 700/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.35 (  1.24)	Cls Acc 75.0 (82.1)	Domain Acc 71.9 (60.3)
Epoch: [9][ 800/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.24 (  1.24)	Cls Acc 84.4 (82.0)	Domain Acc 51.6 (60.8)
Epoch: [9][ 900/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.23 (  1.24)	Cls Acc 75.0 (82.0)	Domain Acc 65.6 (59.7)
Test: [  0/295]	Time  0.990 ( 0.990)	Loss 2.4786e-01 (2.4786e-01)	Acc@1  87.50 ( 87.50)
Test: [100/295]	Time  0.422 ( 0.362)	Loss 2.4121e-01 (2.0116e-01)	Acc@1  93.75 ( 95.67)
Test: [200/295]	Time  0.572 ( 0.355)	Loss 1.9481e-01 (2.0316e-01)	Acc@1  93.75 ( 95.68)
 * Acc@1 95.664
after pretraining lr: 4.966800782285106e-05
Epoch: [10][   0/1000]	Time  1.24 ( 1.24)	Data  0.01 ( 0.01)	Loss   1.26 (  1.26)	Cls Acc 93.8 (93.8)	Domain Acc 64.1 (64.1)
Epoch: [10][ 100/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.27 (  1.25)	Cls Acc 81.2 (81.7)	Domain Acc 60.9 (58.1)
Epoch: [10][ 200/1000]	Time  1.27 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.26 (  1.25)	Cls Acc 81.2 (82.2)	Domain Acc 62.5 (57.3)
Epoch: [10][ 300/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   0.95 (  1.24)	Cls Acc 90.6 (82.0)	Domain Acc 67.2 (59.2)
Epoch: [10][ 400/1000]	Time  1.27 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.40 (  1.24)	Cls Acc 81.2 (82.1)	Domain Acc 43.8 (59.1)
Epoch: [10][ 500/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.16 (  1.24)	Cls Acc 81.2 (82.1)	Domain Acc 71.9 (58.9)
Epoch: [10][ 600/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.18 (  1.23)	Cls Acc 81.2 (82.2)	Domain Acc 57.8 (59.5)
Epoch: [10][ 700/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.14 (  1.24)	Cls Acc 81.2 (82.2)	Domain Acc 70.3 (58.8)
Epoch: [10][ 800/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   0.95 (  1.23)	Cls Acc 93.8 (82.3)	Domain Acc 68.8 (59.6)
Epoch: [10][ 900/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.17 (  1.23)	Cls Acc 84.4 (82.4)	Domain Acc 56.2 (59.6)
Test: [  0/295]	Time  0.975 ( 0.975)	Loss 2.4073e-01 (2.4073e-01)	Acc@1  93.75 ( 93.75)
Test: [100/295]	Time  0.559 ( 0.361)	Loss 2.2472e-01 (2.0605e-01)	Acc@1  93.75 ( 95.67)
Test: [200/295]	Time  0.572 ( 0.355)	Loss 1.8628e-01 (2.0772e-01)	Acc@1  93.75 ( 95.71)
 * Acc@1 95.707
after pretraining lr: 4.6530242955104985e-05
Epoch: [11][   0/1000]	Time  1.23 ( 1.23)	Data  0.02 ( 0.02)	Loss   1.25 (  1.25)	Cls Acc 81.2 (81.2)	Domain Acc 54.7 (54.7)
Epoch: [11][ 100/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.14 (  1.24)	Cls Acc 84.4 (82.2)	Domain Acc 64.1 (57.9)
Epoch: [11][ 200/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.05 (  1.22)	Cls Acc 87.5 (82.9)	Domain Acc 65.6 (59.9)
Epoch: [11][ 300/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.03 (  1.20)	Cls Acc 90.6 (83.2)	Domain Acc 57.8 (61.0)
Epoch: [11][ 400/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.07 (  1.21)	Cls Acc 93.8 (83.2)	Domain Acc 57.8 (58.9)
Epoch: [11][ 500/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.46 (  1.21)	Cls Acc 81.2 (82.8)	Domain Acc 56.2 (59.3)
Epoch: [11][ 600/1000]	Time  1.26 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.03 (  1.21)	Cls Acc 93.8 (82.6)	Domain Acc 59.4 (60.1)
Epoch: [11][ 700/1000]	Time  3.27 ( 1.28)	Data  2.02 ( 0.02)	Loss   1.39 (  1.22)	Cls Acc 75.0 (82.6)	Domain Acc 65.6 (59.4)
Epoch: [11][ 800/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.29 (  1.22)	Cls Acc 75.0 (82.5)	Domain Acc 57.8 (60.1)
Epoch: [11][ 900/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.23 (  1.22)	Cls Acc 87.5 (82.5)	Domain Acc 56.2 (59.9)
Test: [  0/295]	Time  0.982 ( 0.982)	Loss 2.1229e-01 (2.1229e-01)	Acc@1  93.75 ( 93.75)
Test: [100/295]	Time  0.119 ( 0.369)	Loss 2.4697e-01 (1.9212e-01)	Acc@1  93.75 ( 95.73)
Test: [200/295]	Time  0.120 ( 0.360)	Loss 1.8207e-01 (1.9571e-01)	Acc@1  93.75 ( 95.55)
 * Acc@1 95.685
after pretraining lr: 4.381912897190635e-05
Epoch: [12][   0/1000]	Time  1.24 ( 1.24)	Data  0.01 ( 0.01)	Loss   1.16 (  1.16)	Cls Acc 87.5 (87.5)	Domain Acc 64.1 (64.1)
Epoch: [12][ 100/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.35 (  1.22)	Cls Acc 71.9 (82.0)	Domain Acc 62.5 (60.6)
Epoch: [12][ 200/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.26 (  1.22)	Cls Acc 75.0 (82.6)	Domain Acc 57.8 (59.5)
Epoch: [12][ 300/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.52 (  1.22)	Cls Acc 68.8 (82.4)	Domain Acc 59.4 (60.3)
Epoch: [12][ 400/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.05 (  1.21)	Cls Acc 87.5 (82.8)	Domain Acc 62.5 (60.3)
Epoch: [12][ 500/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.04 (  1.20)	Cls Acc 90.6 (83.0)	Domain Acc 68.8 (60.1)
Epoch: [12][ 600/1000]	Time  1.26 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.26 (  1.20)	Cls Acc 75.0 (82.9)	Domain Acc 62.5 (60.6)
Epoch: [12][ 700/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.41 (  1.21)	Cls Acc 75.0 (82.8)	Domain Acc 45.3 (59.8)
Epoch: [12][ 800/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.30 (  1.21)	Cls Acc 78.1 (82.9)	Domain Acc 57.8 (59.7)
Epoch: [12][ 900/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.27 (  1.21)	Cls Acc 84.4 (82.9)	Domain Acc 56.2 (60.0)
Test: [  0/295]	Time  0.990 ( 0.990)	Loss 2.4431e-01 (2.4431e-01)	Acc@1  87.50 ( 87.50)
Test: [100/295]	Time  0.558 ( 0.361)	Loss 2.4314e-01 (1.9472e-01)	Acc@1  93.75 ( 96.16)
Test: [200/295]	Time  0.119 ( 0.353)	Loss 2.0166e-01 (1.9578e-01)	Acc@1  93.75 ( 95.77)
 * Acc@1 95.877
after pretraining lr: 4.145006614859292e-05
Epoch: [13][   0/1000]	Time  1.24 ( 1.24)	Data  0.02 ( 0.02)	Loss   1.07 (  1.07)	Cls Acc 84.4 (84.4)	Domain Acc 56.2 (56.2)
Epoch: [13][ 100/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.22 (  1.18)	Cls Acc 84.4 (84.0)	Domain Acc 67.2 (62.4)
Epoch: [13][ 200/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.06 (  1.20)	Cls Acc 90.6 (83.3)	Domain Acc 59.4 (60.1)
Epoch: [13][ 300/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.02 (  1.20)	Cls Acc 93.8 (83.3)	Domain Acc 62.5 (60.4)
Epoch: [13][ 400/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   0.97 (  1.20)	Cls Acc 93.8 (83.3)	Domain Acc 70.3 (61.1)
Epoch: [13][ 500/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.16 (  1.20)	Cls Acc 87.5 (83.2)	Domain Acc 48.4 (60.2)
Epoch: [13][ 600/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.34 (  1.20)	Cls Acc 78.1 (83.3)	Domain Acc 62.5 (60.7)
Epoch: [13][ 700/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.34 (  1.20)	Cls Acc 68.8 (83.1)	Domain Acc 56.2 (60.2)
Epoch: [13][ 800/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.16 (  1.20)	Cls Acc 87.5 (83.0)	Domain Acc 50.0 (60.6)
Epoch: [13][ 900/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.22 (  1.20)	Cls Acc 78.1 (83.0)	Domain Acc 56.2 (60.7)
Test: [  0/295]	Time  0.991 ( 0.991)	Loss 1.9372e-01 (1.9372e-01)	Acc@1 100.00 (100.00)
Test: [100/295]	Time  0.201 ( 0.361)	Loss 2.5545e-01 (1.9107e-01)	Acc@1  93.75 ( 96.04)
Test: [200/295]	Time  0.118 ( 0.355)	Loss 1.8653e-01 (1.9223e-01)	Acc@1  93.75 ( 95.80)
 * Acc@1 95.664
after pretraining lr: 3.9359793425308615e-05
Epoch: [14][   0/1000]	Time  1.24 ( 1.24)	Data  0.01 ( 0.01)	Loss   1.15 (  1.15)	Cls Acc 81.2 (81.2)	Domain Acc 64.1 (64.1)
Epoch: [14][ 100/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.04)	Loss   1.22 (  1.23)	Cls Acc 78.1 (82.1)	Domain Acc 51.6 (58.4)
Epoch: [14][ 200/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.02 (  1.21)	Cls Acc 87.5 (82.6)	Domain Acc 60.9 (59.0)
Epoch: [14][ 300/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.30 (  1.20)	Cls Acc 81.2 (82.8)	Domain Acc 59.4 (60.0)
Epoch: [14][ 400/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.18 (  1.20)	Cls Acc 84.4 (82.6)	Domain Acc 65.6 (60.9)
Epoch: [14][ 500/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.32 (  1.20)	Cls Acc 81.2 (82.7)	Domain Acc 46.9 (60.0)
Epoch: [14][ 600/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.20 (  1.20)	Cls Acc 65.6 (82.6)	Domain Acc 76.6 (59.8)
Epoch: [14][ 700/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.02 (  1.20)	Cls Acc 87.5 (82.7)	Domain Acc 59.4 (60.2)
Epoch: [14][ 800/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.20 (  1.20)	Cls Acc 90.6 (82.8)	Domain Acc 35.9 (60.1)
Epoch: [14][ 900/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.20 (  1.20)	Cls Acc 71.9 (82.8)	Domain Acc 68.8 (60.2)
Test: [  0/295]	Time  1.124 ( 1.124)	Loss 2.6579e-01 (2.6579e-01)	Acc@1  87.50 ( 87.50)
Test: [100/295]	Time  0.558 ( 0.365)	Loss 2.6076e-01 (1.8491e-01)	Acc@1  93.75 ( 95.85)
Test: [200/295]	Time  0.569 ( 0.360)	Loss 2.0730e-01 (1.8574e-01)	Acc@1  93.75 ( 95.58)
 * Acc@1 95.728
after pretraining lr: 3.7500000000000003e-05
Epoch: [15][   0/1000]	Time  1.23 ( 1.23)	Data  0.01 ( 0.01)	Loss   1.03 (  1.03)	Cls Acc 90.6 (90.6)	Domain Acc 53.1 (53.1)
Epoch: [15][ 100/1000]	Time  1.27 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.38 (  1.21)	Cls Acc 75.0 (83.9)	Domain Acc 53.1 (52.8)
Epoch: [15][ 200/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.19 (  1.18)	Cls Acc 78.1 (84.3)	Domain Acc 59.4 (58.4)
Epoch: [15][ 300/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.47 (  1.18)	Cls Acc 65.6 (83.7)	Domain Acc 53.1 (59.8)
Epoch: [15][ 400/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.27 (  1.18)	Cls Acc 78.1 (83.6)	Domain Acc 62.5 (60.7)
Epoch: [15][ 500/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.09 (  1.18)	Cls Acc 78.1 (83.5)	Domain Acc 65.6 (60.7)
Epoch: [15][ 600/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.25 (  1.18)	Cls Acc 75.0 (83.4)	Domain Acc 53.1 (60.6)
Epoch: [15][ 700/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.01 (  1.18)	Cls Acc 84.4 (83.4)	Domain Acc 71.9 (60.7)
Epoch: [15][ 800/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.14 (  1.18)	Cls Acc 84.4 (83.5)	Domain Acc 54.7 (60.6)
Epoch: [15][ 900/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.00 (  1.18)	Cls Acc 90.6 (83.5)	Domain Acc 70.3 (60.2)
Test: [  0/295]	Time  1.133 ( 1.133)	Loss 2.5389e-01 (2.5389e-01)	Acc@1  93.75 ( 93.75)
Test: [100/295]	Time  0.119 ( 0.356)	Loss 2.0401e-01 (1.8295e-01)	Acc@1  93.75 ( 96.35)
Test: [200/295]	Time  0.119 ( 0.353)	Loss 1.6191e-01 (1.8769e-01)	Acc@1  93.75 ( 95.90)
 * Acc@1 96.026
after pretraining lr: 3.583311502709878e-05
Epoch: [16][   0/1000]	Time  1.24 ( 1.24)	Data  0.01 ( 0.01)	Loss   1.00 (  1.00)	Cls Acc 87.5 (87.5)	Domain Acc 60.9 (60.9)
Epoch: [16][ 100/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.13 (  1.22)	Cls Acc 87.5 (82.4)	Domain Acc 48.4 (57.9)
Epoch: [16][ 200/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.55 (  1.22)	Cls Acc 65.6 (82.4)	Domain Acc 51.6 (57.5)
Epoch: [16][ 300/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.26 (  1.21)	Cls Acc 78.1 (82.6)	Domain Acc 62.5 (58.3)
Epoch: [16][ 400/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.28 (  1.21)	Cls Acc 81.2 (82.7)	Domain Acc 60.9 (58.3)
Epoch: [16][ 500/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.24 (  1.20)	Cls Acc 81.2 (82.7)	Domain Acc 54.7 (59.0)
Epoch: [16][ 600/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.08 (  1.20)	Cls Acc 84.4 (82.8)	Domain Acc 68.8 (59.9)
Epoch: [16][ 700/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.27 (  1.20)	Cls Acc 75.0 (82.9)	Domain Acc 56.2 (59.1)
Epoch: [16][ 800/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   0.95 (  1.20)	Cls Acc 93.8 (82.9)	Domain Acc 64.1 (58.9)
Epoch: [16][ 900/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.09 (  1.19)	Cls Acc 87.5 (83.0)	Domain Acc 68.8 (59.3)
Test: [  0/295]	Time  1.101 ( 1.101)	Loss 1.8941e-01 (1.8941e-01)	Acc@1  93.75 ( 93.75)
Test: [100/295]	Time  0.118 ( 0.367)	Loss 1.8061e-01 (1.5955e-01)	Acc@1  93.75 ( 96.29)
Test: [200/295]	Time  0.118 ( 0.357)	Loss 1.9879e-01 (1.6172e-01)	Acc@1  93.75 ( 96.18)
 * Acc@1 96.217
after pretraining lr: 3.432945239845196e-05
Epoch: [17][   0/1000]	Time  1.23 ( 1.23)	Data  0.01 ( 0.01)	Loss   1.02 (  1.02)	Cls Acc 93.8 (93.8)	Domain Acc 62.5 (62.5)
Epoch: [17][ 100/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.12 (  1.17)	Cls Acc 84.4 (84.4)	Domain Acc 53.1 (59.1)
Epoch: [17][ 200/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.28 (  1.18)	Cls Acc 78.1 (83.9)	Domain Acc 59.4 (58.1)
Epoch: [17][ 300/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   0.88 (  1.18)	Cls Acc 100.0 (84.2)	Domain Acc 56.2 (58.5)
Epoch: [17][ 400/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   0.95 (  1.18)	Cls Acc 96.9 (84.0)	Domain Acc 56.2 (58.9)
Epoch: [17][ 500/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.07 (  1.18)	Cls Acc 93.8 (84.1)	Domain Acc 62.5 (58.7)
Epoch: [17][ 600/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   0.94 (  1.17)	Cls Acc 93.8 (83.9)	Domain Acc 76.6 (59.7)
Epoch: [17][ 700/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.38 (  1.18)	Cls Acc 84.4 (83.7)	Domain Acc 50.0 (60.0)
Epoch: [17][ 800/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.11 (  1.18)	Cls Acc 84.4 (83.6)	Domain Acc 67.2 (59.4)
Epoch: [17][ 900/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.16 (  1.18)	Cls Acc 84.4 (83.6)	Domain Acc 65.6 (59.6)
Test: [  0/295]	Time  1.119 ( 1.119)	Loss 2.4940e-01 (2.4940e-01)	Acc@1  87.50 ( 87.50)
Test: [100/295]	Time  0.120 ( 0.360)	Loss 2.0316e-01 (1.6607e-01)	Acc@1  93.75 ( 96.16)
Test: [200/295]	Time  0.118 ( 0.357)	Loss 2.0074e-01 (1.6837e-01)	Acc@1  93.75 ( 96.02)
 * Acc@1 96.047
after pretraining lr: 3.2965225735734386e-05
Epoch: [18][   0/1000]	Time  1.24 ( 1.24)	Data  0.01 ( 0.01)	Loss   1.24 (  1.24)	Cls Acc 84.4 (84.4)	Domain Acc 64.1 (64.1)
Epoch: [18][ 100/1000]	Time  1.27 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.41 (  1.18)	Cls Acc 65.6 (84.0)	Domain Acc 48.4 (55.6)
Epoch: [18][ 200/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.03)	Loss   1.07 (  1.18)	Cls Acc 90.6 (83.6)	Domain Acc 54.7 (58.5)
Epoch: [18][ 300/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.18 (  1.17)	Cls Acc 87.5 (83.8)	Domain Acc 62.5 (59.6)
Epoch: [18][ 400/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.31 (  1.16)	Cls Acc 71.9 (83.9)	Domain Acc 62.5 (59.5)
Epoch: [18][ 500/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.26 (  1.17)	Cls Acc 75.0 (83.8)	Domain Acc 46.9 (59.8)
Epoch: [18][ 600/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.03 (  1.17)	Cls Acc 81.2 (83.7)	Domain Acc 64.1 (59.2)
Epoch: [18][ 700/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.32 (  1.17)	Cls Acc 75.0 (83.6)	Domain Acc 59.4 (59.2)
Epoch: [18][ 800/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.40 (  1.18)	Cls Acc 81.2 (83.5)	Domain Acc 56.2 (59.2)
Epoch: [18][ 900/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.34 (  1.17)	Cls Acc 71.9 (83.4)	Domain Acc 60.9 (59.6)
Test: [  0/295]	Time  0.980 ( 0.980)	Loss 2.5053e-01 (2.5053e-01)	Acc@1  93.75 ( 93.75)
Test: [100/295]	Time  0.119 ( 0.357)	Loss 1.8590e-01 (1.7726e-01)	Acc@1  93.75 ( 96.41)
Test: [200/295]	Time  0.118 ( 0.353)	Loss 1.6467e-01 (1.7994e-01)	Acc@1  93.75 ( 96.08)
 * Acc@1 96.281
after pretraining lr: 3.1721137903216925e-05
Epoch: [19][   0/1000]	Time  1.24 ( 1.24)	Data  0.01 ( 0.01)	Loss   0.96 (  0.96)	Cls Acc 90.6 (90.6)	Domain Acc 65.6 (65.6)
Epoch: [19][ 100/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.26 (  1.14)	Cls Acc 81.2 (83.8)	Domain Acc 62.5 (62.1)
Epoch: [19][ 200/1000]	Time  1.28 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.09 (  1.14)	Cls Acc 84.4 (83.8)	Domain Acc 62.5 (64.7)
Epoch: [19][ 300/1000]	Time  1.28 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.27 (  1.15)	Cls Acc 78.1 (83.8)	Domain Acc 59.4 (62.2)
Epoch: [19][ 400/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.03)	Loss   0.96 (  1.16)	Cls Acc 87.5 (83.7)	Domain Acc 71.9 (61.4)
Epoch: [19][ 500/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.08 (  1.15)	Cls Acc 87.5 (83.9)	Domain Acc 54.7 (61.4)
Epoch: [19][ 600/1000]	Time  1.26 ( 1.28)	Data  0.02 ( 0.02)	Loss   0.95 (  1.16)	Cls Acc 93.8 (83.6)	Domain Acc 56.2 (60.9)
Epoch: [19][ 700/1000]	Time  1.27 ( 1.28)	Data  0.02 ( 0.02)	Loss   1.00 (  1.16)	Cls Acc 90.6 (83.6)	Domain Acc 64.1 (61.0)
Epoch: [19][ 800/1000]	Time  1.26 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.12 (  1.16)	Cls Acc 87.5 (83.8)	Domain Acc 57.8 (60.9)
Epoch: [19][ 900/1000]	Time  1.26 ( 1.27)	Data  0.02 ( 0.02)	Loss   0.99 (  1.16)	Cls Acc 90.6 (83.7)	Domain Acc 68.8 (60.6)
Test: [  0/295]	Time  0.983 ( 0.983)	Loss 2.1712e-01 (2.1712e-01)	Acc@1  87.50 ( 87.50)
Test: [100/295]	Time  0.118 ( 0.363)	Loss 2.0537e-01 (1.6929e-01)	Acc@1  93.75 ( 96.41)
Test: [200/295]	Time  0.117 ( 0.357)	Loss 2.0625e-01 (1.7240e-01)	Acc@1  93.75 ( 96.24)
 * Acc@1 96.323
best_acc1 = 96.3
Test: [  0/432]	Time  1.239 ( 1.239)	Loss 2.5937e+00 (2.5937e+00)	Acc@1   0.00 (  0.00)
Traceback (most recent call last):
  File "cloth_bsp.py", line 461, in <module>
    main(args)
  File "cloth_bsp.py", line 296, in main
    acc1 = utils.validate(test_loader, classifier, args, device)
  File "/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py", line 127, in validate
    for i, data in enumerate(val_loader):
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
RuntimeError: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 61, in fetch
    return self.collate_fn(data)
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 265, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 143, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 143, in <listcomp>
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 120, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 163, in collate_tensor_fn
    return torch.stack(batch, 0, out=out)
RuntimeError: stack expects each tensor to be equal size, but got [3, 224, 242] at entry 0 and [3, 224, 322] at entry 5

