Namespace(arch='convnext_base', batch_size=32, bottleneck_dim=256, data='Office31', epochs=20, iters_per_epoch=1000, log='bsp', lr=0.003, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', pretrain=None, pretrain_epochs=3, pretrain_lr=0.001, print_freq=100, ratio=[0.75, 1.3333333333333333], resize_size=224, root='data/office31', scale=[0.08, 1.0], scratch=False, seed=None, source=['A'], target=['W'], trade_off=1.0, trade_off_bsp=0.0002, train_resizing='default', val_resizing='default', weight_decay=0.001, workers=2)
=> using model 'convnext_base'
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:136: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top2, predicted2 = torch.topk(sm(output.data), 2, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:137: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top3, predicted3 = torch.topk(sm(output.data), 3, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:138: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top9, predicted9 = torch.topk(sm(output.data), 9, dim=1, largest=True, sorted=True)
Test: [   0/6903]	Time  5.679 ( 5.679)	Loss 1.6303e+00 (1.6303e+00)	Acc@1   0.00 (  0.00)
Test: [ 100/6903]	Time  0.026 ( 0.081)	Loss 1.8778e+00 (1.8181e+00)	Acc@1   0.00 (  0.00)
Test: [ 200/6903]	Time  0.023 ( 0.053)	Loss 1.9938e+00 (1.8201e+00)	Acc@1   0.00 (  0.00)
Test: [ 300/6903]	Time  0.025 ( 0.044)	Loss 1.8653e-01 (1.9052e+00)	Acc@1 100.00 (  0.33)
Test: [ 400/6903]	Time  0.027 ( 0.039)	Loss 2.8084e-02 (1.4528e+00)	Acc@1 100.00 ( 25.19)
Test: [ 500/6903]	Time  0.021 ( 0.037)	Loss 3.1678e-01 (1.2740e+00)	Acc@1 100.00 ( 32.14)
Test: [ 600/6903]	Time  0.028 ( 0.035)	Loss 1.8701e+00 (1.2023e+00)	Acc@1   0.00 ( 38.27)
Test: [ 700/6903]	Time  0.026 ( 0.033)	Loss 3.2339e-02 (1.0642e+00)	Acc@1 100.00 ( 45.36)
Test: [ 800/6903]	Time  0.027 ( 0.032)	Loss 1.2672e-01 (1.0553e+00)	Acc@1 100.00 ( 48.44)
Test: [ 900/6903]	Time  0.025 ( 0.032)	Loss 3.5308e-02 (9.4429e-01)	Acc@1 100.00 ( 54.16)
Test: [1000/6903]	Time  0.023 ( 0.031)	Loss 1.8083e-02 (8.5222e-01)	Acc@1 100.00 ( 58.74)
Test: [1100/6903]	Time  0.025 ( 0.031)	Loss 2.4307e+00 (8.3095e-01)	Acc@1   0.00 ( 59.85)
Test: [1200/6903]	Time  0.026 ( 0.030)	Loss 2.4463e+00 (9.8033e-01)	Acc@1   0.00 ( 54.87)
Test: [1300/6903]	Time  0.026 ( 0.030)	Loss 3.3052e+00 (1.1160e+00)	Acc@1   0.00 ( 50.65)
Test: [1400/6903]	Time  0.026 ( 0.029)	Loss 1.9698e+00 (1.2036e+00)	Acc@1   0.00 ( 47.04)
Test: [1500/6903]	Time  0.026 ( 0.029)	Loss 3.1980e+00 (1.2816e+00)	Acc@1   0.00 ( 43.90)
Test: [1600/6903]	Time  0.026 ( 0.029)	Loss 2.3207e+00 (1.3754e+00)	Acc@1   0.00 ( 41.16)
Test: [1700/6903]	Time  0.026 ( 0.029)	Loss 2.8324e+00 (1.4448e+00)	Acc@1   0.00 ( 38.74)
Test: [1800/6903]	Time  0.023 ( 0.029)	Loss 3.0173e+00 (1.5288e+00)	Acc@1   0.00 ( 36.59)
Test: [1900/6903]	Time  0.023 ( 0.028)	Loss 4.0444e+00 (1.6469e+00)	Acc@1   0.00 ( 34.67)
Test: [2000/6903]	Time  0.025 ( 0.028)	Loss 4.5595e+00 (1.7892e+00)	Acc@1   0.00 ( 32.93)
Test: [2100/6903]	Time  0.027 ( 0.028)	Loss 1.2222e-02 (1.8995e+00)	Acc@1 100.00 ( 31.65)
Test: [2200/6903]	Time  0.026 ( 0.028)	Loss 1.8551e-02 (1.8140e+00)	Acc@1 100.00 ( 34.76)
Test: [2300/6903]	Time  0.026 ( 0.028)	Loss 5.7690e-02 (1.7369e+00)	Acc@1 100.00 ( 37.59)
Test: [2400/6903]	Time  0.026 ( 0.028)	Loss 2.3097e-02 (1.6662e+00)	Acc@1 100.00 ( 40.19)
Test: [2500/6903]	Time  0.026 ( 0.028)	Loss 4.4306e+00 (1.6459e+00)	Acc@1   0.00 ( 41.54)
Test: [2600/6903]	Time  0.026 ( 0.028)	Loss 4.7908e+00 (1.7555e+00)	Acc@1   0.00 ( 39.95)
Test: [2700/6903]	Time  0.026 ( 0.027)	Loss 1.1878e+00 (1.8064e+00)	Acc@1   0.00 ( 38.47)
Test: [2800/6903]	Time  0.023 ( 0.027)	Loss 9.4523e-02 (1.7652e+00)	Acc@1 100.00 ( 39.13)
Test: [2900/6903]	Time  0.023 ( 0.027)	Loss 3.8269e-02 (1.7062e+00)	Acc@1 100.00 ( 41.23)
Test: [3000/6903]	Time  0.026 ( 0.027)	Loss 2.5374e-02 (1.6506e+00)	Acc@1 100.00 ( 43.19)
Test: [3100/6903]	Time  0.027 ( 0.027)	Loss 1.7085e-02 (1.5983e+00)	Acc@1 100.00 ( 45.02)
Test: [3200/6903]	Time  0.026 ( 0.027)	Loss 1.5952e-02 (1.5494e+00)	Acc@1 100.00 ( 46.74)
Test: [3300/6903]	Time  0.026 ( 0.027)	Loss 1.3382e-02 (1.5030e+00)	Acc@1 100.00 ( 48.35)
Test: [3400/6903]	Time  0.026 ( 0.027)	Loss 2.8215e-02 (1.4593e+00)	Acc@1 100.00 ( 49.87)
Test: [3500/6903]	Time  0.026 ( 0.027)	Loss 5.3777e-02 (1.4187e+00)	Acc@1 100.00 ( 51.30)
Test: [3600/6903]	Time  0.026 ( 0.027)	Loss 1.0120e-01 (1.3814e+00)	Acc@1 100.00 ( 52.65)
Test: [3700/6903]	Time  0.026 ( 0.027)	Loss 8.4509e-02 (1.3475e+00)	Acc@1 100.00 ( 53.93)
Test: [3800/6903]	Time  0.025 ( 0.027)	Loss 4.0006e-01 (1.3201e+00)	Acc@1 100.00 ( 55.06)
Test: [3900/6903]	Time  0.026 ( 0.027)	Loss 3.7456e-02 (1.2901e+00)	Acc@1 100.00 ( 56.22)
Test: [4000/6903]	Time  0.028 ( 0.027)	Loss 2.6501e+00 (1.2678e+00)	Acc@1   0.00 ( 56.91)
Test: [4100/6903]	Time  0.028 ( 0.027)	Loss 2.0868e+00 (1.2840e+00)	Acc@1   0.00 ( 55.52)
Test: [4200/6903]	Time  0.029 ( 0.027)	Loss 1.9953e+00 (1.3068e+00)	Acc@1   0.00 ( 54.20)
Test: [4300/6903]	Time  0.025 ( 0.027)	Loss 1.9768e+00 (1.3220e+00)	Acc@1   0.00 ( 52.94)
Test: [4400/6903]	Time  0.025 ( 0.027)	Loss 1.5364e-01 (1.3241e+00)	Acc@1 100.00 ( 52.31)
Test: [4500/6903]	Time  0.028 ( 0.027)	Loss 1.3945e-01 (1.2967e+00)	Acc@1 100.00 ( 53.37)
Test: [4600/6903]	Time  0.026 ( 0.027)	Loss 3.0265e-02 (1.2871e+00)	Acc@1 100.00 ( 53.27)
Test: [4700/6903]	Time  0.026 ( 0.027)	Loss 6.0573e-01 (1.2649e+00)	Acc@1 100.00 ( 54.16)
Test: [4800/6903]	Time  0.026 ( 0.027)	Loss 2.3854e+00 (1.2788e+00)	Acc@1   0.00 ( 53.66)
Test: [4900/6903]	Time  0.029 ( 0.027)	Loss 2.3567e+00 (1.3013e+00)	Acc@1   0.00 ( 52.56)
Test: [5000/6903]	Time  0.028 ( 0.027)	Loss 2.7154e+00 (1.3294e+00)	Acc@1   0.00 ( 51.51)
Test: [5100/6903]	Time  0.027 ( 0.027)	Loss 2.7557e+00 (1.3544e+00)	Acc@1   0.00 ( 50.50)
Test: [5200/6903]	Time  0.026 ( 0.027)	Loss 4.2209e-01 (1.3437e+00)	Acc@1 100.00 ( 50.99)
Test: [5300/6903]	Time  0.026 ( 0.027)	Loss 1.2006e-02 (1.3199e+00)	Acc@1 100.00 ( 51.91)
Test: [5400/6903]	Time  0.023 ( 0.027)	Loss 9.1868e-02 (1.2997e+00)	Acc@1 100.00 ( 52.71)
Test: [5500/6903]	Time  0.028 ( 0.027)	Loss 1.3687e-02 (1.2765e+00)	Acc@1 100.00 ( 53.57)
Test: [5600/6903]	Time  0.027 ( 0.027)	Loss 3.4463e+00 (1.2591e+00)	Acc@1   0.00 ( 54.26)
Test: [5700/6903]	Time  0.026 ( 0.027)	Loss 1.2151e-01 (1.2559e+00)	Acc@1 100.00 ( 54.46)
Test: [5800/6903]	Time  0.025 ( 0.026)	Loss 3.6357e-02 (1.2357e+00)	Acc@1 100.00 ( 55.25)
Test: [5900/6903]	Time  0.028 ( 0.026)	Loss 3.4428e-01 (1.2161e+00)	Acc@1 100.00 ( 56.01)
Test: [6000/6903]	Time  0.026 ( 0.026)	Loss 4.3240e+00 (1.2295e+00)	Acc@1   0.00 ( 55.67)
Test: [6100/6903]	Time  0.026 ( 0.026)	Loss 1.4642e+00 (1.2676e+00)	Acc@1   0.00 ( 54.78)
Test: [6200/6903]	Time  0.026 ( 0.026)	Loss 3.3867e-02 (1.2485e+00)	Acc@1 100.00 ( 55.47)
Test: [6300/6903]	Time  0.026 ( 0.026)	Loss 4.9515e-02 (1.2293e+00)	Acc@1 100.00 ( 56.18)
Test: [6400/6903]	Time  0.017 ( 0.026)	Loss 9.0940e-02 (1.2118e+00)	Acc@1 100.00 ( 56.87)
Test: [6500/6903]	Time  0.026 ( 0.026)	Loss 4.3423e-01 (1.1988e+00)	Acc@1 100.00 ( 57.53)
Test: [6600/6903]	Time  0.026 ( 0.026)	Loss 7.0263e-01 (1.1906e+00)	Acc@1 100.00 ( 58.13)
Test: [6700/6903]	Time  0.026 ( 0.026)	Loss 7.4986e-02 (1.1824e+00)	Acc@1 100.00 ( 58.69)
Test: [6800/6903]	Time  0.028 ( 0.026)	Loss 4.3143e-02 (1.1660e+00)	Acc@1 100.00 ( 59.30)
Test: [6900/6903]	Time  0.026 ( 0.026)	Loss 2.3543e-02 (1.1495e+00)	Acc@1 100.00 ( 59.89)
 * Acc@1 59.901
test_acc1 = 59.9
Traceback (most recent call last):
  File "testing_bsp.py", line 477, in <module>
    main(args)
  File "testing_bsp.py", line 305, in main
    from bokeh.plotting import figure, show
ModuleNotFoundError: No module named 'bokeh'
