Namespace(arch='convnext_base', batch_size=32, bottleneck_dim=256, data='Office31', epochs=20, iters_per_epoch=1000, log='bsp', lr=0.003, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', pretrain=None, pretrain_epochs=3, pretrain_lr=0.001, print_freq=100, ratio=[0.75, 1.3333333333333333], resize_size=224, root='data/office31', scale=[0.08, 1.0], scratch=False, seed=None, source=['A'], target=['W'], trade_off=1.0, trade_off_bsp=0.0002, train_resizing='default', val_resizing='default', weight_decay=0.001, workers=2)
=> using model 'convnext_base'
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:136: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top2, predicted2 = torch.topk(sm(output.data), 2, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:137: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top3, predicted3 = torch.topk(sm(output.data), 3, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:138: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top9, predicted9 = torch.topk(sm(output.data), 9, dim=1, largest=True, sorted=True)
Test: [   0/6903]	Time  5.467 ( 5.467)	Loss 2.8544e+00 (2.8544e+00)	Acc@1   0.00 (  0.00)
Test: [ 100/6903]	Time  0.026 ( 0.079)	Loss 3.7433e+00 (3.4400e+00)	Acc@1   0.00 (  0.00)
Test: [ 200/6903]	Time  0.027 ( 0.052)	Loss 3.5944e+00 (3.5255e+00)	Acc@1   0.00 (  0.00)
Test: [ 300/6903]	Time  0.017 ( 0.043)	Loss 4.7782e-02 (3.4852e+00)	Acc@1 100.00 (  0.33)
Test: [ 400/6903]	Time  0.026 ( 0.039)	Loss 4.9503e-03 (2.6206e+00)	Acc@1 100.00 ( 25.19)
Test: [ 500/6903]	Time  0.026 ( 0.036)	Loss 4.1354e-02 (2.2789e+00)	Acc@1 100.00 ( 29.74)
Test: [ 600/6903]	Time  0.025 ( 0.034)	Loss 2.6414e+00 (2.0889e+00)	Acc@1   0.00 ( 36.27)
Test: [ 700/6903]	Time  0.026 ( 0.033)	Loss 8.0382e-03 (1.8360e+00)	Acc@1 100.00 ( 43.65)
Test: [ 800/6903]	Time  0.025 ( 0.032)	Loss 1.7784e-01 (1.6933e+00)	Acc@1 100.00 ( 47.82)
Test: [ 900/6903]	Time  0.027 ( 0.031)	Loss 1.7183e-02 (1.5120e+00)	Acc@1 100.00 ( 53.61)
Test: [1000/6903]	Time  0.014 ( 0.031)	Loss 5.7411e-02 (1.3630e+00)	Acc@1 100.00 ( 58.24)
Test: [1100/6903]	Time  0.013 ( 0.029)	Loss 1.5958e+00 (1.2829e+00)	Acc@1   0.00 ( 60.94)
Test: [1200/6903]	Time  0.026 ( 0.029)	Loss 2.0747e+00 (1.3393e+00)	Acc@1   0.00 ( 55.87)
Test: [1300/6903]	Time  0.024 ( 0.028)	Loss 3.1909e+00 (1.4297e+00)	Acc@1   0.00 ( 51.58)
Test: [1400/6903]	Time  0.013 ( 0.027)	Loss 2.3958e+00 (1.5290e+00)	Acc@1   0.00 ( 47.89)
Test: [1500/6903]	Time  0.026 ( 0.027)	Loss 3.4758e+00 (1.6031e+00)	Acc@1   0.00 ( 44.70)
Test: [1600/6903]	Time  0.027 ( 0.026)	Loss 2.5067e+00 (1.7053e+00)	Acc@1   0.00 ( 41.91)
Test: [1700/6903]	Time  0.020 ( 0.026)	Loss 3.0091e+00 (1.7529e+00)	Acc@1   0.00 ( 39.45)
Test: [1800/6903]	Time  0.027 ( 0.025)	Loss 3.5143e+00 (1.8287e+00)	Acc@1   0.00 ( 37.26)
Test: [1900/6903]	Time  0.012 ( 0.025)	Loss 3.8330e+00 (1.9269e+00)	Acc@1   0.00 ( 35.30)
Test: [2000/6903]	Time  0.026 ( 0.025)	Loss 3.7477e+00 (2.0170e+00)	Acc@1   0.00 ( 33.53)
Test: [2100/6903]	Time  0.026 ( 0.025)	Loss 9.9569e-02 (2.0801e+00)	Acc@1 100.00 ( 32.22)
Test: [2200/6903]	Time  0.025 ( 0.024)	Loss 8.0402e-02 (1.9889e+00)	Acc@1 100.00 ( 35.30)
Test: [2300/6903]	Time  0.026 ( 0.024)	Loss 1.1608e-01 (1.9065e+00)	Acc@1 100.00 ( 38.11)
Test: [2400/6903]	Time  0.020 ( 0.024)	Loss 6.4979e-02 (1.8306e+00)	Acc@1 100.00 ( 40.69)
Test: [2500/6903]	Time  0.014 ( 0.024)	Loss 3.6359e+00 (1.7960e+00)	Acc@1   0.00 ( 42.02)
Test: [2600/6903]	Time  0.013 ( 0.024)	Loss 3.7991e+00 (1.8631e+00)	Acc@1   0.00 ( 40.41)
Test: [2700/6903]	Time  0.029 ( 0.023)	Loss 8.4805e-01 (1.8782e+00)	Acc@1   0.00 ( 38.91)
Test: [2800/6903]	Time  0.026 ( 0.023)	Loss 2.7706e-01 (1.8322e+00)	Acc@1 100.00 ( 40.77)
Test: [2900/6903]	Time  0.026 ( 0.023)	Loss 1.5210e-01 (1.7775e+00)	Acc@1 100.00 ( 42.81)
Test: [3000/6903]	Time  0.028 ( 0.023)	Loss 3.0793e-02 (1.7206e+00)	Acc@1 100.00 ( 44.72)
Test: [3100/6903]	Time  0.013 ( 0.023)	Loss 5.5603e-03 (1.6659e+00)	Acc@1 100.00 ( 46.50)
Test: [3200/6903]	Time  0.013 ( 0.023)	Loss 1.1080e-02 (1.6142e+00)	Acc@1 100.00 ( 48.17)
Test: [3300/6903]	Time  0.015 ( 0.023)	Loss 1.1523e-02 (1.5656e+00)	Acc@1 100.00 ( 49.74)
Test: [3400/6903]	Time  0.014 ( 0.023)	Loss 3.4868e-02 (1.5203e+00)	Acc@1 100.00 ( 51.22)
Test: [3500/6903]	Time  0.026 ( 0.023)	Loss 3.9874e-02 (1.4779e+00)	Acc@1 100.00 ( 52.61)
Test: [3600/6903]	Time  0.028 ( 0.023)	Loss 8.6846e-02 (1.4385e+00)	Acc@1 100.00 ( 53.93)
Test: [3700/6903]	Time  0.026 ( 0.022)	Loss 9.8661e-01 (1.4245e+00)	Acc@1   0.00 ( 53.61)
Test: [3800/6903]	Time  0.026 ( 0.022)	Loss 6.4784e+00 (1.5223e+00)	Acc@1   0.00 ( 52.38)
Test: [3900/6903]	Time  0.026 ( 0.022)	Loss 6.2502e-01 (1.5936e+00)	Acc@1 100.00 ( 51.47)
Test: [4000/6903]	Time  0.026 ( 0.022)	Loss 2.8401e+00 (1.5696e+00)	Acc@1   0.00 ( 52.19)
Test: [4100/6903]	Time  0.028 ( 0.022)	Loss 2.9903e+00 (1.6001e+00)	Acc@1   0.00 ( 50.91)
Test: [4200/6903]	Time  0.013 ( 0.022)	Loss 3.4049e+00 (1.6453e+00)	Acc@1   0.00 ( 49.70)
Test: [4300/6903]	Time  0.037 ( 0.022)	Loss 3.7378e+00 (1.6902e+00)	Acc@1   0.00 ( 48.55)
Test: [4400/6903]	Time  0.028 ( 0.022)	Loss 3.1259e-02 (1.7146e+00)	Acc@1 100.00 ( 48.01)
Test: [4500/6903]	Time  0.025 ( 0.023)	Loss 6.3902e-02 (1.6769e+00)	Acc@1 100.00 ( 49.17)
Test: [4600/6903]	Time  0.049 ( 0.023)	Loss 8.2042e-03 (1.6571e+00)	Acc@1 100.00 ( 49.21)
Test: [4700/6903]	Time  0.028 ( 0.023)	Loss 1.4055e-01 (1.6265e+00)	Acc@1 100.00 ( 50.18)
Test: [4800/6903]	Time  0.046 ( 0.023)	Loss 2.7848e+00 (1.6373e+00)	Acc@1   0.00 ( 49.76)
Test: [4900/6903]	Time  0.018 ( 0.023)	Loss 4.1534e+00 (1.6625e+00)	Acc@1   0.00 ( 48.75)
Test: [5000/6903]	Time  0.040 ( 0.023)	Loss 3.6134e+00 (1.7031e+00)	Acc@1   0.00 ( 47.77)
Test: [5100/6903]	Time  0.036 ( 0.023)	Loss 4.3030e+00 (1.7464e+00)	Acc@1   0.00 ( 46.83)
Test: [5200/6903]	Time  0.029 ( 0.023)	Loss 1.0864e-01 (1.7323e+00)	Acc@1 100.00 ( 47.39)
Test: [5300/6903]	Time  0.040 ( 0.023)	Loss 1.8332e-02 (1.7000e+00)	Acc@1 100.00 ( 48.39)
Test: [5400/6903]	Time  0.028 ( 0.023)	Loss 2.9362e-02 (1.6723e+00)	Acc@1 100.00 ( 49.25)
Test: [5500/6903]	Time  0.028 ( 0.023)	Loss 2.6873e-02 (1.6426e+00)	Acc@1 100.00 ( 50.17)
Test: [5600/6903]	Time  0.028 ( 0.023)	Loss 1.9893e+00 (1.6165e+00)	Acc@1   0.00 ( 50.92)
Test: [5700/6903]	Time  0.026 ( 0.023)	Loss 9.7558e-02 (1.5949e+00)	Acc@1 100.00 ( 51.60)
Test: [5800/6903]	Time  0.020 ( 0.023)	Loss 8.7370e-03 (1.5678e+00)	Acc@1 100.00 ( 52.44)
Test: [5900/6903]	Time  0.014 ( 0.023)	Loss 1.2632e+00 (1.5426e+00)	Acc@1   0.00 ( 53.23)
Test: [6000/6903]	Time  0.014 ( 0.023)	Loss 2.6455e+00 (1.5375e+00)	Acc@1   0.00 ( 53.26)
Test: [6100/6903]	Time  0.026 ( 0.023)	Loss 6.1995e-01 (1.5516e+00)	Acc@1 100.00 ( 52.52)
Test: [6200/6903]	Time  0.026 ( 0.023)	Loss 1.8180e-02 (1.5302e+00)	Acc@1 100.00 ( 53.28)
Test: [6300/6903]	Time  0.026 ( 0.023)	Loss 1.3310e-01 (1.5074e+00)	Acc@1 100.00 ( 54.02)
Test: [6400/6903]	Time  0.023 ( 0.023)	Loss 2.1849e-01 (1.4861e+00)	Acc@1 100.00 ( 54.74)
Test: [6500/6903]	Time  0.023 ( 0.023)	Loss 3.9153e+00 (1.5088e+00)	Acc@1   0.00 ( 54.44)
Test: [6600/6903]	Time  0.026 ( 0.023)	Loss 6.2411e+00 (1.5646e+00)	Acc@1   0.00 ( 53.61)
Test: [6700/6903]	Time  0.026 ( 0.023)	Loss 2.9194e+00 (1.6276e+00)	Acc@1   0.00 ( 52.81)
Test: [6800/6903]	Time  0.026 ( 0.023)	Loss 7.2944e-02 (1.6139e+00)	Acc@1 100.00 ( 52.93)
Test: [6900/6903]	Time  0.026 ( 0.023)	Loss 8.9823e-02 (1.5919e+00)	Acc@1 100.00 ( 53.62)
 * Acc@1 53.629
test_acc1 = 53.6
Traceback (most recent call last):
  File "testing_bsp.py", line 477, in <module>
    main(args)
  File "testing_bsp.py", line 305, in main
    from bokeh.plotting import figure, show
ModuleNotFoundError: No module named 'bokeh'
