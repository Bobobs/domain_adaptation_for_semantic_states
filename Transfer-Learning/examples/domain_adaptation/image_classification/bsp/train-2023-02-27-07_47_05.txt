Namespace(arch='convnext_base', batch_size=32, bottleneck_dim=256, data='Office31', epochs=20, iters_per_epoch=1000, log='bsp', lr=0.003, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', pretrain=None, pretrain_epochs=3, pretrain_lr=0.001, print_freq=100, ratio=[0.75, 1.3333333333333333], resize_size=224, root='data/office31', scale=[0.08, 1.0], scratch=False, seed=None, source=['A'], target=['W'], trade_off=1.0, trade_off_bsp=0.0002, train_resizing='default', val_resizing='default', weight_decay=0.001, workers=2)
=> using model 'convnext_base'
Pretraining the model on source domain.
/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:257: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
lr: [0.0001, 0.001, 0.001]
Epoch: [0][   0/1000]	Time 3.0 (3.0)	Data 0.0 (0.0)	Loss 2.24 (2.24)	Cls Acc 9.4 (9.4)
Epoch: [0][ 100/1000]	Time 0.6 (0.7)	Data 0.0 (0.1)	Loss 0.88 (1.56)	Cls Acc 78.1 (45.7)
Epoch: [0][ 200/1000]	Time 0.6 (0.7)	Data 0.0 (0.1)	Loss 1.25 (1.34)	Cls Acc 56.2 (53.9)
Epoch: [0][ 300/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.98 (1.21)	Cls Acc 75.0 (58.5)
Epoch: [0][ 400/1000]	Time 0.9 (0.7)	Data 0.4 (0.2)	Loss 1.06 (1.13)	Cls Acc 65.6 (61.2)
Epoch: [0][ 500/1000]	Time 0.8 (0.7)	Data 0.3 (0.2)	Loss 0.65 (1.07)	Cls Acc 71.9 (63.5)
Epoch: [0][ 600/1000]	Time 0.8 (0.7)	Data 0.3 (0.2)	Loss 0.82 (1.02)	Cls Acc 68.8 (65.2)
Epoch: [0][ 700/1000]	Time 0.8 (0.7)	Data 0.3 (0.2)	Loss 0.58 (0.98)	Cls Acc 87.5 (66.4)
Epoch: [0][ 800/1000]	Time 0.8 (0.7)	Data 0.3 (0.2)	Loss 0.70 (0.95)	Cls Acc 71.9 (67.2)
Epoch: [0][ 900/1000]	Time 0.9 (0.7)	Data 0.3 (0.2)	Loss 0.57 (0.92)	Cls Acc 84.4 (68.0)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:136: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top2, predicted2 = torch.topk(sm(output.data), 2, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:137: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top3, predicted3 = torch.topk(sm(output.data), 3, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:138: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top9, predicted9 = torch.topk(sm(output.data), 9, dim=1, largest=True, sorted=True)
Test: [  0/295]	Time  1.149 ( 1.149)	Loss 4.4563e-01 (4.4563e-01)	Acc@1  81.25 ( 81.25)
Test: [100/295]	Time  0.186 ( 0.365)	Loss 4.5927e-01 (3.9554e-01)	Acc@1  81.25 ( 90.04)
Test: [200/295]	Time  0.171 ( 0.358)	Loss 3.1962e-01 (3.8210e-01)	Acc@1  87.50 ( 90.30)
 * Acc@1 90.776
lr: [5.946035575013605e-05, 0.0005946035575013605, 0.0005946035575013605]
Epoch: [1][   0/1000]	Time 0.6 (0.6)	Data 0.0 (0.0)	Loss 0.62 (0.62)	Cls Acc 81.2 (81.2)
Epoch: [1][ 100/1000]	Time 0.8 (0.7)	Data 0.3 (0.1)	Loss 0.61 (0.66)	Cls Acc 78.1 (76.4)
Epoch: [1][ 200/1000]	Time 0.8 (0.7)	Data 0.2 (0.2)	Loss 0.58 (0.66)	Cls Acc 75.0 (76.2)
Epoch: [1][ 300/1000]	Time 0.8 (0.7)	Data 0.3 (0.2)	Loss 0.71 (0.66)	Cls Acc 81.2 (76.6)
Epoch: [1][ 400/1000]	Time 0.8 (0.7)	Data 0.3 (0.2)	Loss 1.02 (0.65)	Cls Acc 71.9 (76.7)
Epoch: [1][ 500/1000]	Time 0.8 (0.7)	Data 0.3 (0.2)	Loss 0.37 (0.65)	Cls Acc 87.5 (77.0)
Epoch: [1][ 600/1000]	Time 0.9 (0.7)	Data 0.3 (0.2)	Loss 0.66 (0.64)	Cls Acc 87.5 (77.3)
Epoch: [1][ 700/1000]	Time 0.6 (0.7)	Data 0.1 (0.2)	Loss 0.52 (0.64)	Cls Acc 81.2 (77.4)
Epoch: [1][ 800/1000]	Time 0.8 (0.7)	Data 0.3 (0.2)	Loss 0.67 (0.63)	Cls Acc 84.4 (77.5)
Epoch: [1][ 900/1000]	Time 0.8 (0.7)	Data 0.3 (0.2)	Loss 0.38 (0.63)	Cls Acc 81.2 (77.5)
Test: [  0/295]	Time  0.958 ( 0.958)	Loss 2.9253e-01 (2.9253e-01)	Acc@1  93.75 ( 93.75)
Test: [100/295]	Time  0.572 ( 0.361)	Loss 4.3265e-01 (3.0981e-01)	Acc@1  87.50 ( 92.70)
Test: [200/295]	Time  0.177 ( 0.357)	Loss 2.6187e-01 (2.9980e-01)	Acc@1  93.75 ( 93.10)
 * Acc@1 93.135
lr: [4.3869133765083086e-05, 0.0004386913376508308, 0.0004386913376508308]
Epoch: [2][   0/1000]	Time 0.6 (0.6)	Data 0.0 (0.0)	Loss 0.41 (0.41)	Cls Acc 90.6 (90.6)
Epoch: [2][ 100/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.73 (0.59)	Cls Acc 75.0 (78.8)
Epoch: [2][ 200/1000]	Time 0.9 (0.7)	Data 0.3 (0.1)	Loss 0.53 (0.60)	Cls Acc 78.1 (78.7)
Epoch: [2][ 300/1000]	Time 0.9 (0.7)	Data 0.3 (0.1)	Loss 0.64 (0.59)	Cls Acc 68.8 (78.7)
Epoch: [2][ 400/1000]	Time 0.8 (0.7)	Data 0.3 (0.2)	Loss 0.44 (0.59)	Cls Acc 81.2 (78.5)
Epoch: [2][ 500/1000]	Time 0.8 (0.7)	Data 0.2 (0.2)	Loss 0.42 (0.58)	Cls Acc 75.0 (78.9)
Epoch: [2][ 600/1000]	Time 0.8 (0.7)	Data 0.3 (0.2)	Loss 0.72 (0.58)	Cls Acc 71.9 (78.8)
Epoch: [2][ 700/1000]	Time 0.9 (0.7)	Data 0.3 (0.2)	Loss 0.54 (0.57)	Cls Acc 84.4 (79.0)
Epoch: [2][ 800/1000]	Time 0.8 (0.7)	Data 0.3 (0.2)	Loss 0.60 (0.57)	Cls Acc 75.0 (79.0)
Epoch: [2][ 900/1000]	Time 0.9 (0.7)	Data 0.3 (0.2)	Loss 0.57 (0.57)	Cls Acc 81.2 (78.9)
Test: [  0/295]	Time  1.093 ( 1.093)	Loss 2.5738e-01 (2.5738e-01)	Acc@1  93.75 ( 93.75)
Test: [100/295]	Time  0.569 ( 0.369)	Loss 4.5831e-01 (2.6920e-01)	Acc@1  81.25 ( 92.82)
Test: [200/295]	Time  0.537 ( 0.361)	Loss 2.0854e-01 (2.6042e-01)	Acc@1  93.75 ( 93.35)
 * Acc@1 93.284
Pretraining process is done.
after pretraining lr: 0.00030000000000000003
Epoch: [0][   0/1000]	Time  3.42 ( 3.42)	Data  0.02 ( 0.02)	Loss   2.23 (  2.23)	Cls Acc 68.8 (68.8)	Domain Acc 45.3 (45.3)
Epoch: [0][ 100/1000]	Time  1.26 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.74 (  1.56)	Cls Acc 68.8 (76.4)	Domain Acc 92.2 (84.4)
Epoch: [0][ 200/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   0.88 (  1.38)	Cls Acc 87.5 (77.3)	Domain Acc 100.0 (90.7)
Epoch: [0][ 300/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.05 (  1.28)	Cls Acc 87.5 (77.5)	Domain Acc 100.0 (93.3)
Epoch: [0][ 400/1000]	Time  1.26 ( 1.26)	Data  0.03 ( 0.02)	Loss   0.88 (  1.23)	Cls Acc 87.5 (77.9)	Domain Acc 98.4 (94.5)
Epoch: [0][ 500/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   0.86 (  1.19)	Cls Acc 87.5 (78.1)	Domain Acc 95.3 (94.8)
Epoch: [0][ 600/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   2.65 (  1.33)	Cls Acc 65.6 (78.1)	Domain Acc 59.4 (91.6)
Epoch: [0][ 700/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.02)	Loss   2.66 (  1.49)	Cls Acc 84.4 (77.5)	Domain Acc 31.2 (88.1)
Epoch: [0][ 800/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.44 (  1.53)	Cls Acc 75.0 (77.1)	Domain Acc 87.5 (86.5)
Epoch: [0][ 900/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.02)	Loss   2.28 (  1.61)	Cls Acc 87.5 (76.7)	Domain Acc 50.0 (83.7)
Test: [  0/295]	Time  1.007 ( 1.007)	Loss 7.8148e-01 (7.8148e-01)	Acc@1  68.75 ( 68.75)
Test: [100/295]	Time  0.119 ( 0.366)	Loss 5.4107e-01 (5.3039e-01)	Acc@1  75.00 ( 81.56)
Test: [200/295]	Time  0.118 ( 0.361)	Loss 5.6849e-01 (5.1479e-01)	Acc@1  75.00 ( 82.77)
 * Acc@1 82.827
after pretraining lr: 0.00017838106725040818
Epoch: [1][   0/1000]	Time  1.23 ( 1.23)	Data  0.01 ( 0.01)	Loss   3.24 (  3.24)	Cls Acc 81.2 (81.2)	Domain Acc 29.7 (29.7)
Epoch: [1][ 100/1000]	Time  1.25 ( 1.27)	Data  0.02 ( 0.03)	Loss   2.20 (  2.14)	Cls Acc 65.6 (73.1)	Domain Acc 56.2 (61.1)
Epoch: [1][ 200/1000]	Time  1.26 ( 1.27)	Data  0.02 ( 0.03)	Loss   1.33 (  2.04)	Cls Acc 78.1 (73.4)	Domain Acc 90.6 (62.7)
Epoch: [1][ 300/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.65 (  2.04)	Cls Acc 68.8 (72.9)	Domain Acc 81.2 (63.5)
Epoch: [1][ 400/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.72 (  2.00)	Cls Acc 68.8 (73.5)	Domain Acc 65.6 (62.8)
Epoch: [1][ 500/1000]	Time  1.24 ( 1.26)	Data  0.02 ( 0.03)	Loss   2.17 (  2.02)	Cls Acc 68.8 (73.6)	Domain Acc 54.7 (60.8)
Epoch: [1][ 600/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   2.14 (  2.05)	Cls Acc 81.2 (73.5)	Domain Acc 35.9 (59.7)
Epoch: [1][ 700/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.02)	Loss   2.05 (  2.04)	Cls Acc 59.4 (73.3)	Domain Acc 70.3 (59.2)
Epoch: [1][ 800/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.82 (  2.09)	Cls Acc 65.6 (73.0)	Domain Acc 68.8 (57.6)
Epoch: [1][ 900/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   2.54 (  2.11)	Cls Acc 59.4 (73.0)	Domain Acc 48.4 (56.3)
Test: [  0/295]	Time  0.988 ( 0.988)	Loss 1.4981e+01 (1.4981e+01)	Acc@1  18.75 ( 18.75)
Test: [100/295]	Time  0.391 ( 0.363)	Loss 1.0004e+01 (1.2904e+01)	Acc@1  37.50 ( 27.41)
Test: [200/295]	Time  0.118 ( 0.359)	Loss 1.2410e+01 (1.2714e+01)	Acc@1  25.00 ( 28.33)
 * Acc@1 28.693
after pretraining lr: 0.00013160740129524923
Epoch: [2][   0/1000]	Time  1.22 ( 1.22)	Data  0.01 ( 0.01)	Loss   1.52 (  1.52)	Cls Acc 71.9 (71.9)	Domain Acc 79.7 (79.7)
Epoch: [2][ 100/1000]	Time  1.26 ( 1.25)	Data  0.02 ( 0.02)	Loss   1.82 (  1.91)	Cls Acc 68.8 (71.5)	Domain Acc 60.9 (56.0)
Epoch: [2][ 200/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.78 (  1.93)	Cls Acc 68.8 (71.9)	Domain Acc 50.0 (53.4)
Epoch: [2][ 300/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.74 (  1.87)	Cls Acc 68.8 (72.6)	Domain Acc 39.1 (52.7)
Epoch: [2][ 400/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.69 (  1.83)	Cls Acc 84.4 (73.2)	Domain Acc 46.9 (51.8)
Epoch: [2][ 500/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.96 (  1.80)	Cls Acc 71.9 (73.8)	Domain Acc 37.5 (51.6)
Epoch: [2][ 600/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.52 (  1.81)	Cls Acc 81.2 (73.7)	Domain Acc 48.4 (49.8)
Epoch: [2][ 700/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.59 (  1.81)	Cls Acc 78.1 (73.7)	Domain Acc 53.1 (48.7)
Epoch: [2][ 800/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.46 (  1.78)	Cls Acc 78.1 (73.8)	Domain Acc 56.2 (49.8)
Epoch: [2][ 900/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.91 (  1.77)	Cls Acc 65.6 (73.9)	Domain Acc 39.1 (50.2)
Test: [  0/295]	Time  1.000 ( 1.000)	Loss 6.9236e+00 (6.9236e+00)	Acc@1  25.00 ( 25.00)
Test: [100/295]	Time  0.679 ( 0.369)	Loss 1.8976e+00 (3.7634e+00)	Acc@1  56.25 ( 43.50)
Test: [200/295]	Time  0.583 ( 0.366)	Loss 3.0784e+00 (3.7424e+00)	Acc@1  50.00 ( 43.63)
 * Acc@1 43.719
after pretraining lr: 0.00010606601717798215
Epoch: [3][   0/1000]	Time  1.22 ( 1.22)	Data  0.01 ( 0.01)	Loss   1.47 (  1.47)	Cls Acc 75.0 (75.0)	Domain Acc 46.9 (46.9)
Epoch: [3][ 100/1000]	Time  1.26 ( 1.25)	Data  0.02 ( 0.02)	Loss   1.54 (  1.51)	Cls Acc 78.1 (76.5)	Domain Acc 53.1 (57.5)
Epoch: [3][ 200/1000]	Time  1.25 ( 1.25)	Data  0.02 ( 0.02)	Loss   1.35 (  1.50)	Cls Acc 87.5 (76.5)	Domain Acc 46.9 (55.9)
Epoch: [3][ 300/1000]	Time  1.24 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.49 (  1.54)	Cls Acc 84.4 (76.3)	Domain Acc 43.8 (52.4)
Epoch: [3][ 400/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.55 (  1.56)	Cls Acc 78.1 (76.3)	Domain Acc 40.6 (50.3)
Epoch: [3][ 500/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.43 (  1.54)	Cls Acc 81.2 (76.5)	Domain Acc 48.4 (51.5)
Epoch: [3][ 600/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.75 (  1.51)	Cls Acc 78.1 (76.6)	Domain Acc 28.1 (53.9)
Epoch: [3][ 700/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.07 (  1.52)	Cls Acc 81.2 (76.7)	Domain Acc 76.6 (53.6)
Epoch: [3][ 800/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.57 (  1.52)	Cls Acc 68.8 (76.7)	Domain Acc 62.5 (53.9)
Epoch: [3][ 900/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.43 (  1.52)	Cls Acc 75.0 (76.5)	Domain Acc 65.6 (53.4)
Test: [  0/295]	Time  1.053 ( 1.053)	Loss 8.6419e+00 (8.6419e+00)	Acc@1  18.75 ( 18.75)
Test: [100/295]	Time  0.575 ( 0.365)	Loss 3.6124e+00 (4.7211e+00)	Acc@1  56.25 ( 37.13)
Test: [200/295]	Time  0.117 ( 0.362)	Loss 3.9646e+00 (4.6710e+00)	Acc@1  50.00 ( 38.28)
 * Acc@1 39.001
after pretraining lr: 8.972092687327323e-05
Epoch: [4][   0/1000]	Time  1.22 ( 1.22)	Data  0.01 ( 0.01)	Loss   1.10 (  1.10)	Cls Acc 90.6 (90.6)	Domain Acc 59.4 (59.4)
Epoch: [4][ 100/1000]	Time  1.26 ( 1.27)	Data  0.02 ( 0.04)	Loss   1.31 (  1.45)	Cls Acc 71.9 (76.9)	Domain Acc 59.4 (51.9)
Epoch: [4][ 200/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.64 (  1.45)	Cls Acc 75.0 (77.4)	Domain Acc 45.3 (50.5)
Epoch: [4][ 300/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.18 (  1.41)	Cls Acc 90.6 (77.9)	Domain Acc 46.9 (53.3)
Epoch: [4][ 400/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.52 (  1.42)	Cls Acc 78.1 (78.1)	Domain Acc 54.7 (52.4)
Epoch: [4][ 500/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.52 (  1.42)	Cls Acc 71.9 (78.0)	Domain Acc 25.0 (52.7)
Epoch: [4][ 600/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.14 (  1.40)	Cls Acc 93.8 (78.1)	Domain Acc 54.7 (55.1)
Epoch: [4][ 700/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.29 (  1.41)	Cls Acc 75.0 (78.2)	Domain Acc 71.9 (54.0)
Epoch: [4][ 800/1000]	Time  1.24 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.21 (  1.41)	Cls Acc 87.5 (78.1)	Domain Acc 56.2 (53.2)
Epoch: [4][ 900/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.45 (  1.41)	Cls Acc 87.5 (78.1)	Domain Acc 48.4 (53.4)
Test: [  0/295]	Time  0.978 ( 0.978)	Loss 1.4017e+01 (1.4017e+01)	Acc@1  18.75 ( 18.75)
Test: [100/295]	Time  0.206 ( 0.364)	Loss 7.0091e+00 (9.8110e+00)	Acc@1  37.50 ( 27.41)
Test: [200/295]	Time  0.152 ( 0.358)	Loss 8.7080e+00 (9.6654e+00)	Acc@1  25.00 ( 28.33)
 * Acc@1 28.693
after pretraining lr: 7.825422900366438e-05
Epoch: [5][   0/1000]	Time  1.22 ( 1.22)	Data  0.01 ( 0.01)	Loss   1.28 (  1.28)	Cls Acc 78.1 (78.1)	Domain Acc 42.2 (42.2)
Epoch: [5][ 100/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.42 (  1.35)	Cls Acc 87.5 (79.0)	Domain Acc 51.6 (54.1)
Epoch: [5][ 200/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.44 (  1.38)	Cls Acc 81.2 (78.8)	Domain Acc 50.0 (52.6)
Epoch: [5][ 300/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.61 (  1.37)	Cls Acc 71.9 (78.4)	Domain Acc 48.4 (53.8)
Epoch: [5][ 400/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.47 (  1.37)	Cls Acc 75.0 (78.7)	Domain Acc 48.4 (52.4)
Epoch: [5][ 500/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.51 (  1.37)	Cls Acc 78.1 (78.6)	Domain Acc 48.4 (54.4)
Epoch: [5][ 600/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.22 (  1.37)	Cls Acc 84.4 (78.6)	Domain Acc 68.8 (53.6)
Epoch: [5][ 700/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.33 (  1.36)	Cls Acc 75.0 (78.7)	Domain Acc 64.1 (54.5)
Epoch: [5][ 800/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.34 (  1.35)	Cls Acc 71.9 (78.7)	Domain Acc 71.9 (54.6)
Epoch: [5][ 900/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.52 (  1.35)	Cls Acc 75.0 (78.7)	Domain Acc 35.9 (54.9)
Test: [  0/295]	Time  1.018 ( 1.018)	Loss 8.7258e+00 (8.7258e+00)	Acc@1  25.00 ( 25.00)
Test: [100/295]	Time  0.566 ( 0.366)	Loss 3.9692e+00 (5.8738e+00)	Acc@1  37.50 ( 28.71)
Test: [200/295]	Time  0.586 ( 0.361)	Loss 4.3552e+00 (5.7922e+00)	Acc@1  25.00 ( 29.48)
 * Acc@1 29.883
after pretraining lr: 6.971042407276225e-05
Epoch: [6][   0/1000]	Time  1.22 ( 1.22)	Data  0.01 ( 0.01)	Loss   1.42 (  1.42)	Cls Acc 78.1 (78.1)	Domain Acc 56.2 (56.2)
Epoch: [6][ 100/1000]	Time  1.26 ( 1.24)	Data  0.02 ( 0.02)	Loss   1.17 (  1.36)	Cls Acc 84.4 (80.0)	Domain Acc 64.1 (50.9)
Epoch: [6][ 200/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.18 (  1.33)	Cls Acc 78.1 (79.8)	Domain Acc 65.6 (54.2)
Epoch: [6][ 300/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.56 (  1.34)	Cls Acc 75.0 (79.8)	Domain Acc 46.9 (52.8)
Epoch: [6][ 400/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.52 (  1.35)	Cls Acc 75.0 (79.6)	Domain Acc 62.5 (52.9)
Epoch: [6][ 500/1000]	Time  1.24 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.23 (  1.33)	Cls Acc 87.5 (79.6)	Domain Acc 48.4 (54.6)
Epoch: [6][ 600/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.41 (  1.33)	Cls Acc 68.8 (79.5)	Domain Acc 54.7 (54.4)
Epoch: [6][ 700/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.32 (  1.33)	Cls Acc 78.1 (79.5)	Domain Acc 46.9 (54.3)
Epoch: [6][ 800/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.19 (  1.33)	Cls Acc 81.2 (79.6)	Domain Acc 56.2 (54.4)
Epoch: [6][ 900/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.18 (  1.33)	Cls Acc 87.5 (79.6)	Domain Acc 50.0 (54.2)
Test: [  0/295]	Time  0.993 ( 0.993)	Loss 7.3586e+00 (7.3586e+00)	Acc@1  31.25 ( 31.25)
Test: [100/295]	Time  0.118 ( 0.363)	Loss 2.6238e+00 (4.3198e+00)	Acc@1  56.25 ( 43.19)
Test: [200/295]	Time  0.264 ( 0.360)	Loss 3.2074e+00 (4.2745e+00)	Acc@1  50.00 ( 44.22)
 * Acc@1 44.803
after pretraining lr: 6.306723114402858e-05
Epoch: [7][   0/1000]	Time  1.22 ( 1.22)	Data  0.01 ( 0.01)	Loss   1.23 (  1.23)	Cls Acc 87.5 (87.5)	Domain Acc 59.4 (59.4)
Epoch: [7][ 100/1000]	Time  1.24 ( 1.24)	Data  0.02 ( 0.02)	Loss   1.40 (  1.35)	Cls Acc 75.0 (78.5)	Domain Acc 56.2 (51.3)
Epoch: [7][ 200/1000]	Time  1.26 ( 1.25)	Data  0.02 ( 0.02)	Loss   1.41 (  1.32)	Cls Acc 68.8 (78.3)	Domain Acc 68.8 (57.9)
Epoch: [7][ 300/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.37 (  1.33)	Cls Acc 84.4 (79.1)	Domain Acc 39.1 (54.9)
Epoch: [7][ 400/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.35 (  1.31)	Cls Acc 71.9 (79.3)	Domain Acc 65.6 (56.5)
Epoch: [7][ 500/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.58 (  1.30)	Cls Acc 75.0 (79.7)	Domain Acc 43.8 (57.0)
Epoch: [7][ 600/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.32 (  1.31)	Cls Acc 84.4 (79.6)	Domain Acc 50.0 (56.2)
Epoch: [7][ 700/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.32 (  1.30)	Cls Acc 84.4 (79.6)	Domain Acc 54.7 (56.7)
Epoch: [7][ 800/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.19 (  1.30)	Cls Acc 78.1 (79.8)	Domain Acc 50.0 (55.8)
Epoch: [7][ 900/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.18 (  1.30)	Cls Acc 84.4 (79.9)	Domain Acc 76.6 (57.0)
Test: [  0/295]	Time  0.981 ( 0.981)	Loss 7.1193e+00 (7.1193e+00)	Acc@1  18.75 ( 18.75)
Test: [100/295]	Time  0.575 ( 0.372)	Loss 2.6496e+00 (4.3231e+00)	Acc@1  56.25 ( 44.99)
Test: [200/295]	Time  0.573 ( 0.364)	Loss 3.2606e+00 (4.2547e+00)	Acc@1  50.00 ( 45.68)
 * Acc@1 46.121
after pretraining lr: 5.7735026918962585e-05
Epoch: [8][   0/1000]	Time  1.23 ( 1.23)	Data  0.01 ( 0.01)	Loss   1.43 (  1.43)	Cls Acc 81.2 (81.2)	Domain Acc 46.9 (46.9)
Epoch: [8][ 100/1000]	Time  1.25 ( 1.24)	Data  0.02 ( 0.02)	Loss   1.17 (  1.26)	Cls Acc 84.4 (80.7)	Domain Acc 51.6 (61.0)
Epoch: [8][ 200/1000]	Time  1.27 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.44 (  1.27)	Cls Acc 78.1 (80.6)	Domain Acc 59.4 (57.4)
Epoch: [8][ 300/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.33 (  1.28)	Cls Acc 81.2 (80.7)	Domain Acc 51.6 (55.9)
Epoch: [8][ 400/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.50 (  1.27)	Cls Acc 75.0 (80.5)	Domain Acc 60.9 (57.4)
Epoch: [8][ 500/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.16 (  1.27)	Cls Acc 78.1 (80.6)	Domain Acc 71.9 (57.6)
Epoch: [8][ 600/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.22 (  1.27)	Cls Acc 84.4 (80.6)	Domain Acc 42.2 (57.4)
Epoch: [8][ 700/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.32 (  1.27)	Cls Acc 78.1 (80.6)	Domain Acc 65.6 (57.1)
Epoch: [8][ 800/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.27 (  1.27)	Cls Acc 78.1 (80.7)	Domain Acc 50.0 (57.1)
Epoch: [8][ 900/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.40 (  1.27)	Cls Acc 75.0 (80.8)	Domain Acc 45.3 (56.9)
Test: [  0/295]	Time  0.992 ( 0.992)	Loss 7.4174e+00 (7.4174e+00)	Acc@1  31.25 ( 31.25)
Test: [100/295]	Time  0.686 ( 0.370)	Loss 2.5263e+00 (4.2375e+00)	Acc@1  81.25 ( 58.73)
Test: [200/295]	Time  0.411 ( 0.361)	Loss 3.0926e+00 (4.1670e+00)	Acc@1  62.50 ( 59.36)
 * Acc@1 59.490
after pretraining lr: 5.334838230116769e-05
Epoch: [9][   0/1000]	Time  1.23 ( 1.23)	Data  0.01 ( 0.01)	Loss   1.35 (  1.35)	Cls Acc 75.0 (75.0)	Domain Acc 67.2 (67.2)
Epoch: [9][ 100/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.27 (  1.26)	Cls Acc 87.5 (80.3)	Domain Acc 39.1 (56.7)
Epoch: [9][ 200/1000]	Time  1.27 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.24 (  1.27)	Cls Acc 90.6 (80.7)	Domain Acc 60.9 (54.8)
Epoch: [9][ 300/1000]	Time  1.27 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.56 (  1.27)	Cls Acc 71.9 (80.7)	Domain Acc 67.2 (55.3)
Epoch: [9][ 400/1000]	Time  1.26 ( 1.27)	Data  0.02 ( 0.03)	Loss   1.36 (  1.26)	Cls Acc 81.2 (80.7)	Domain Acc 50.0 (57.0)
Epoch: [9][ 500/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.25 (  1.27)	Cls Acc 68.8 (80.7)	Domain Acc 64.1 (55.3)
Epoch: [9][ 600/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.28 (  1.26)	Cls Acc 84.4 (80.9)	Domain Acc 59.4 (57.7)
Epoch: [9][ 700/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.33 (  1.26)	Cls Acc 81.2 (80.9)	Domain Acc 39.1 (56.4)
Epoch: [9][ 800/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.37 (  1.27)	Cls Acc 78.1 (80.8)	Domain Acc 51.6 (56.0)
Epoch: [9][ 900/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.31 (  1.26)	Cls Acc 78.1 (80.8)	Domain Acc 51.6 (56.6)
Test: [  0/295]	Time  1.013 ( 1.013)	Loss 8.5560e+00 (8.5560e+00)	Acc@1  18.75 ( 18.75)
Test: [100/295]	Time  0.558 ( 0.364)	Loss 3.4703e+00 (5.0671e+00)	Acc@1  56.25 ( 37.93)
Test: [200/295]	Time  0.591 ( 0.362)	Loss 4.2395e+00 (4.9863e+00)	Acc@1  43.75 ( 38.77)
 * Acc@1 39.532
after pretraining lr: 4.966800782285106e-05
Epoch: [10][   0/1000]	Time  1.22 ( 1.22)	Data  0.01 ( 0.01)	Loss   1.51 (  1.51)	Cls Acc 75.0 (75.0)	Domain Acc 54.7 (54.7)
Epoch: [10][ 100/1000]	Time  1.25 ( 1.24)	Data  0.02 ( 0.02)	Loss   1.03 (  1.24)	Cls Acc 87.5 (81.3)	Domain Acc 56.2 (57.5)
Epoch: [10][ 200/1000]	Time  1.26 ( 1.25)	Data  0.02 ( 0.03)	Loss   1.11 (  1.26)	Cls Acc 90.6 (81.1)	Domain Acc 56.2 (53.2)
Epoch: [10][ 300/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.50 (  1.25)	Cls Acc 68.8 (81.4)	Domain Acc 70.3 (55.2)
Epoch: [10][ 400/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.34 (  1.24)	Cls Acc 78.1 (81.5)	Domain Acc 67.2 (55.8)
Epoch: [10][ 500/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.21 (  1.24)	Cls Acc 78.1 (81.4)	Domain Acc 62.5 (56.8)
Epoch: [10][ 600/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.37 (  1.24)	Cls Acc 81.2 (81.4)	Domain Acc 54.7 (56.9)
Epoch: [10][ 700/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.26 (  1.24)	Cls Acc 78.1 (81.4)	Domain Acc 51.6 (56.5)
Epoch: [10][ 800/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.21 (  1.23)	Cls Acc 75.0 (81.4)	Domain Acc 67.2 (57.5)
Epoch: [10][ 900/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.34 (  1.23)	Cls Acc 81.2 (81.4)	Domain Acc 59.4 (57.6)
Test: [  0/295]	Time  0.984 ( 0.984)	Loss 7.7368e+00 (7.7368e+00)	Acc@1  18.75 ( 18.75)
Test: [100/295]	Time  0.703 ( 0.379)	Loss 2.9849e+00 (4.4607e+00)	Acc@1  56.25 ( 40.78)
Test: [200/295]	Time  0.583 ( 0.370)	Loss 3.6589e+00 (4.3884e+00)	Acc@1  50.00 ( 41.11)
 * Acc@1 41.785
after pretraining lr: 4.6530242955104985e-05
Epoch: [11][   0/1000]	Time  1.23 ( 1.23)	Data  0.01 ( 0.01)	Loss   1.15 (  1.15)	Cls Acc 84.4 (84.4)	Domain Acc 57.8 (57.8)
Epoch: [11][ 100/1000]	Time  1.26 ( 1.24)	Data  0.02 ( 0.02)	Loss   1.32 (  1.25)	Cls Acc 71.9 (81.2)	Domain Acc 53.1 (53.2)
Epoch: [11][ 200/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.05 (  1.21)	Cls Acc 81.2 (81.7)	Domain Acc 70.3 (58.5)
Epoch: [11][ 300/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.11 (  1.22)	Cls Acc 87.5 (81.6)	Domain Acc 56.2 (57.7)
Epoch: [11][ 400/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.31 (  1.23)	Cls Acc 87.5 (81.6)	Domain Acc 56.2 (56.2)
Epoch: [11][ 500/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.02)	Loss   1.34 (  1.23)	Cls Acc 84.4 (81.8)	Domain Acc 76.6 (57.2)
Epoch: [11][ 600/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.17 (  1.23)	Cls Acc 87.5 (81.8)	Domain Acc 51.6 (56.9)
Epoch: [11][ 700/1000]	Time  2.90 ( 1.26)	Data  1.67 ( 0.03)	Loss   1.37 (  1.23)	Cls Acc 71.9 (81.6)	Domain Acc 57.8 (56.9)
Epoch: [11][ 800/1000]	Time  1.26 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.22 (  1.23)	Cls Acc 78.1 (81.5)	Domain Acc 48.4 (57.4)
Epoch: [11][ 900/1000]	Time  1.25 ( 1.26)	Data  0.02 ( 0.03)	Loss   1.16 (  1.23)	Cls Acc 90.6 (81.6)	Domain Acc 45.3 (56.5)
Test: [  0/295]	Time  0.982 ( 0.982)	Loss 7.6332e+00 (7.6332e+00)	Acc@1  18.75 ( 18.75)
Test: [100/295]	Time  0.215 ( 0.361)	Loss 2.9323e+00 (4.4064e+00)	Acc@1  56.25 ( 42.64)
Test: [200/295]	Time  0.573 ( 0.359)	Loss 3.6315e+00 (4.3355e+00)	Acc@1  50.00 ( 42.79)
 * Acc@1 43.316
after pretraining lr: 4.381912897190635e-05
Epoch: [12][   0/1000]	Time  1.23 ( 1.23)	Data  0.02 ( 0.02)	Loss   1.05 (  1.05)	Cls Acc 84.4 (84.4)	Domain Acc 62.5 (62.5)
Epoch: [12][ 100/1000]	Time  1.25 ( 1.24)	Data  0.02 ( 0.02)	Loss   1.06 (  1.19)	Cls Acc 84.4 (82.5)	Domain Acc 59.4 (63.8)
Traceback (most recent call last):
  File "cloth_bsp.py", line 461, in <module>
    main(args)
  File "cloth_bsp.py", line 279, in main
    train(train_source_iter, train_target_iter, classifier, domain_adv, bsp_penalty, optimizer,
  File "cloth_bsp.py", line 367, in train
    optimizer.step()
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/optim/optimizer.py", line 140, in wrapper
    out = func(*args, **kwargs)
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/optim/optimizer.py", line 23, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/optim/sgd.py", line 151, in step
    sgd(params_with_grad,
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/optim/sgd.py", line 202, in sgd
    func(params,
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/optim/sgd.py", line 241, in _single_tensor_sgd
    d_p = d_p.add(buf, alpha=momentum)
KeyboardInterrupt
