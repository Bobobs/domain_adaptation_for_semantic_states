Namespace(arch='convnext_base', batch_size=32, bottleneck_dim=256, data='Office31', epochs=20, iters_per_epoch=1000, log='bsp', lr=0.003, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', pretrain=None, pretrain_epochs=3, pretrain_lr=0.001, print_freq=100, ratio=[0.75, 1.3333333333333333], resize_size=224, root='data/office31', scale=[0.08, 1.0], scratch=False, seed=None, source=['A'], target=['W'], trade_off=1.0, trade_off_bsp=0.0002, train_resizing='default', val_resizing='default', weight_decay=0.001, workers=2)
=> using model 'convnext_base'
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:136: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top2, predicted2 = torch.topk(sm(output.data), 2, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:137: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top3, predicted3 = torch.topk(sm(output.data), 3, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:138: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top9, predicted9 = torch.topk(sm(output.data), 9, dim=1, largest=True, sorted=True)
Test: [   0/6903]	Time  4.176 ( 4.176)	Loss 1.6025e+00 (1.6025e+00)	Acc@1   0.00 (  0.00)
Test: [ 100/6903]	Time  0.018 ( 0.098)	Loss 2.6114e+00 (2.6869e+00)	Acc@1   0.00 (  0.00)
Test: [ 200/6903]	Time  0.052 ( 0.063)	Loss 2.2247e+00 (2.5789e+00)	Acc@1   0.00 (  0.00)
Test: [ 300/6903]	Time  0.018 ( 0.051)	Loss 4.4584e-02 (2.4916e+00)	Acc@1 100.00 (  0.33)
Test: [ 400/6903]	Time  0.018 ( 0.045)	Loss 7.3471e-03 (1.8747e+00)	Acc@1 100.00 ( 25.19)
Test: [ 500/6903]	Time  0.014 ( 0.041)	Loss 3.1076e-01 (1.5791e+00)	Acc@1 100.00 ( 33.13)
Test: [ 600/6903]	Time  0.029 ( 0.039)	Loss 2.1504e+00 (1.4812e+00)	Acc@1   0.00 ( 39.10)
Test: [ 700/6903]	Time  0.018 ( 0.036)	Loss 1.3740e-02 (1.3061e+00)	Acc@1 100.00 ( 46.08)
Test: [ 800/6903]	Time  0.017 ( 0.034)	Loss 2.0199e+00 (1.4893e+00)	Acc@1   0.00 ( 42.70)
Test: [ 900/6903]	Time  0.014 ( 0.032)	Loss 1.2757e-01 (1.4042e+00)	Acc@1 100.00 ( 45.84)
Test: [1000/6903]	Time  0.015 ( 0.030)	Loss 4.9747e-01 (1.2814e+00)	Acc@1 100.00 ( 51.25)
Test: [1100/6903]	Time  0.012 ( 0.029)	Loss 4.8796e+00 (1.3539e+00)	Acc@1   0.00 ( 49.41)
Test: [1200/6903]	Time  0.013 ( 0.028)	Loss 5.1443e+00 (1.6543e+00)	Acc@1   0.00 ( 45.30)
Test: [1300/6903]	Time  0.013 ( 0.028)	Loss 5.6412e+00 (1.9372e+00)	Acc@1   0.00 ( 41.81)
Test: [1400/6903]	Time  0.023 ( 0.027)	Loss 3.8309e+00 (2.1378e+00)	Acc@1   0.00 ( 38.83)
Test: [1500/6903]	Time  0.018 ( 0.026)	Loss 4.5920e+00 (2.2641e+00)	Acc@1   0.00 ( 36.24)
Test: [1600/6903]	Time  0.027 ( 0.026)	Loss 4.0346e+00 (2.3926e+00)	Acc@1   0.00 ( 33.98)
Test: [1700/6903]	Time  0.020 ( 0.025)	Loss 4.1824e+00 (2.4858e+00)	Acc@1   0.00 ( 31.98)
Test: [1800/6903]	Time  0.023 ( 0.025)	Loss 4.7837e+00 (2.5894e+00)	Acc@1   0.00 ( 30.21)
Test: [1900/6903]	Time  0.024 ( 0.024)	Loss 5.4882e+00 (2.7252e+00)	Acc@1   0.00 ( 28.62)
Test: [2000/6903]	Time  0.013 ( 0.024)	Loss 5.3980e+00 (2.8587e+00)	Acc@1   0.00 ( 27.19)
Test: [2100/6903]	Time  0.020 ( 0.024)	Loss 7.4461e-02 (2.9654e+00)	Acc@1 100.00 ( 26.18)
Test: [2200/6903]	Time  0.012 ( 0.023)	Loss 2.0497e-01 (2.8380e+00)	Acc@1 100.00 ( 29.53)
Test: [2300/6903]	Time  0.021 ( 0.023)	Loss 2.4642e-01 (2.7240e+00)	Acc@1 100.00 ( 32.59)
Test: [2400/6903]	Time  0.020 ( 0.023)	Loss 2.1949e-01 (2.6210e+00)	Acc@1 100.00 ( 35.40)
Test: [2500/6903]	Time  0.017 ( 0.023)	Loss 5.2576e+00 (2.5766e+00)	Acc@1   0.00 ( 36.95)
Test: [2600/6903]	Time  0.016 ( 0.023)	Loss 5.5361e+00 (2.6801e+00)	Acc@1   0.00 ( 35.52)
Test: [2700/6903]	Time  0.012 ( 0.022)	Loss 3.8909e+00 (2.7576e+00)	Acc@1   0.00 ( 34.21)
Test: [2800/6903]	Time  0.017 ( 0.022)	Loss 2.6718e+00 (2.7736e+00)	Acc@1   0.00 ( 32.99)
Test: [2900/6903]	Time  0.021 ( 0.022)	Loss 1.2622e+00 (2.7461e+00)	Acc@1   0.00 ( 32.20)
Test: [3000/6903]	Time  0.023 ( 0.022)	Loss 4.7960e-02 (2.6744e+00)	Acc@1 100.00 ( 34.42)
Test: [3100/6903]	Time  0.017 ( 0.022)	Loss 5.4064e-03 (2.5891e+00)	Acc@1 100.00 ( 36.54)
Test: [3200/6903]	Time  0.018 ( 0.022)	Loss 1.1576e-02 (2.5085e+00)	Acc@1 100.00 ( 38.52)
Test: [3300/6903]	Time  0.019 ( 0.022)	Loss 3.3405e-02 (2.4332e+00)	Acc@1 100.00 ( 40.38)
Test: [3400/6903]	Time  0.021 ( 0.022)	Loss 7.6759e-02 (2.3630e+00)	Acc@1 100.00 ( 42.13)
Test: [3500/6903]	Time  0.020 ( 0.022)	Loss 7.4397e-02 (2.2977e+00)	Acc@1 100.00 ( 43.79)
Test: [3600/6903]	Time  0.020 ( 0.022)	Loss 1.2598e-01 (2.2362e+00)	Acc@1 100.00 ( 45.35)
Test: [3700/6903]	Time  0.017 ( 0.022)	Loss 4.3776e-01 (2.1892e+00)	Acc@1 100.00 ( 46.83)
Test: [3800/6903]	Time  0.022 ( 0.022)	Loss 5.3500e-01 (2.1462e+00)	Acc@1 100.00 ( 48.15)
Test: [3900/6903]	Time  0.023 ( 0.021)	Loss 1.8268e-01 (2.0990e+00)	Acc@1 100.00 ( 49.47)
Test: [4000/6903]	Time  0.023 ( 0.021)	Loss 1.9284e+00 (2.0557e+00)	Acc@1   0.00 ( 50.34)
Test: [4100/6903]	Time  0.019 ( 0.022)	Loss 2.6906e+00 (2.0503e+00)	Acc@1   0.00 ( 49.11)
Test: [4200/6903]	Time  0.021 ( 0.022)	Loss 2.5652e+00 (2.0706e+00)	Acc@1   0.00 ( 47.94)
Test: [4300/6903]	Time  0.035 ( 0.022)	Loss 3.1648e+00 (2.0882e+00)	Acc@1   0.00 ( 46.83)
Test: [4400/6903]	Time  0.026 ( 0.022)	Loss 2.6399e-02 (2.0871e+00)	Acc@1 100.00 ( 46.33)
Test: [4500/6903]	Time  0.021 ( 0.022)	Loss 1.3867e-01 (2.0412e+00)	Acc@1 100.00 ( 47.52)
Test: [4600/6903]	Time  0.029 ( 0.022)	Loss 1.0739e-02 (2.0196e+00)	Acc@1 100.00 ( 47.58)
Test: [4700/6903]	Time  0.031 ( 0.022)	Loss 9.4564e-02 (1.9829e+00)	Acc@1 100.00 ( 48.56)
Test: [4800/6903]	Time  0.036 ( 0.022)	Loss 1.7298e+00 (1.9666e+00)	Acc@1   0.00 ( 48.18)
Test: [4900/6903]	Time  0.028 ( 0.022)	Loss 2.2801e+00 (1.9654e+00)	Acc@1   0.00 ( 47.19)
Test: [5000/6903]	Time  0.038 ( 0.023)	Loss 1.9599e+00 (1.9715e+00)	Acc@1   0.00 ( 46.25)
Test: [5100/6903]	Time  0.030 ( 0.023)	Loss 2.3658e+00 (1.9769e+00)	Acc@1   0.00 ( 45.34)
Test: [5200/6903]	Time  0.032 ( 0.023)	Loss 1.1243e-01 (1.9502e+00)	Acc@1 100.00 ( 45.93)
Test: [5300/6903]	Time  0.033 ( 0.023)	Loss 3.5079e-03 (1.9137e+00)	Acc@1 100.00 ( 46.95)
Test: [5400/6903]	Time  0.037 ( 0.023)	Loss 9.6098e-02 (1.8850e+00)	Acc@1 100.00 ( 47.82)
Test: [5500/6903]	Time  0.023 ( 0.023)	Loss 1.4667e-02 (1.8518e+00)	Acc@1 100.00 ( 48.77)
Test: [5600/6903]	Time  0.020 ( 0.023)	Loss 4.6746e+00 (1.8255e+00)	Acc@1   0.00 ( 49.54)
Test: [5700/6903]	Time  0.023 ( 0.023)	Loss 7.4773e-01 (1.8329e+00)	Acc@1 100.00 ( 48.97)
Test: [5800/6903]	Time  0.020 ( 0.023)	Loss 7.0682e-02 (1.8064e+00)	Acc@1 100.00 ( 49.85)
Test: [5900/6903]	Time  0.019 ( 0.023)	Loss 1.5117e+00 (1.7803e+00)	Acc@1 100.00 ( 50.70)
Test: [6000/6903]	Time  0.021 ( 0.023)	Loss 4.9127e+00 (1.7966e+00)	Acc@1   0.00 ( 50.36)
Test: [6100/6903]	Time  0.024 ( 0.023)	Loss 2.2383e+00 (1.8441e+00)	Acc@1   0.00 ( 49.53)
Test: [6200/6903]	Time  0.023 ( 0.023)	Loss 7.6171e-02 (1.8292e+00)	Acc@1 100.00 ( 49.83)
Test: [6300/6903]	Time  0.021 ( 0.023)	Loss 6.0554e-01 (1.8069e+00)	Acc@1 100.00 ( 50.63)
Test: [6400/6903]	Time  0.022 ( 0.023)	Loss 4.3220e-01 (1.7873e+00)	Acc@1 100.00 ( 51.40)
Test: [6500/6903]	Time  0.020 ( 0.023)	Loss 1.2411e+00 (1.7751e+00)	Acc@1 100.00 ( 51.87)
Test: [6600/6903]	Time  0.018 ( 0.023)	Loss 1.0786e+00 (1.7674e+00)	Acc@1   0.00 ( 51.87)
Test: [6700/6903]	Time  0.021 ( 0.023)	Loss 2.2947e-01 (1.7530e+00)	Acc@1 100.00 ( 51.99)
Test: [6800/6903]	Time  0.017 ( 0.023)	Loss 2.6224e-02 (1.7289e+00)	Acc@1 100.00 ( 52.70)
Test: [6900/6903]	Time  0.019 ( 0.023)	Loss 9.3803e-03 (1.7041e+00)	Acc@1 100.00 ( 53.38)
 * Acc@1 53.397
test_acc1 = 53.4
Traceback (most recent call last):
  File "testing_bsp.py", line 477, in <module>
    main(args)
  File "testing_bsp.py", line 305, in main
    from bokeh.plotting import figure, show
ModuleNotFoundError: No module named 'bokeh'
