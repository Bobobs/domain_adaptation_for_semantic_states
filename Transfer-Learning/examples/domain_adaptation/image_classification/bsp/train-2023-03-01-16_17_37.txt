Namespace(arch='convnext_base', batch_size=32, bottleneck_dim=256, data='Office31', epochs=20, iters_per_epoch=1000, log='bsp', lr=0.003, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', pretrain=None, pretrain_epochs=3, pretrain_lr=0.001, print_freq=100, ratio=[0.75, 1.3333333333333333], resize_size=224, root='data/office31', scale=[0.08, 1.0], scratch=False, seed=None, source=['A'], target=['W'], trade_off=1.0, trade_off_bsp=0.0002, train_resizing='default', val_resizing='default', weight_decay=0.001, workers=2)
=> using model 'convnext_base'
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:136: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top2, predicted2 = torch.topk(sm(output.data), 2, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:137: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top3, predicted3 = torch.topk(sm(output.data), 3, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:138: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top9, predicted9 = torch.topk(sm(output.data), 9, dim=1, largest=True, sorted=True)
Test: [   0/6903]	Time  2.400 ( 2.400)	Loss 1.1205e+00 (1.1205e+00)	Acc@1   0.00 (  0.00)
Test: [ 100/6903]	Time  0.024 ( 0.051)	Loss 2.6790e+00 (1.9015e+00)	Acc@1   0.00 (  0.00)
Test: [ 200/6903]	Time  0.019 ( 0.039)	Loss 3.9892e+00 (2.7880e+00)	Acc@1   0.00 (  0.00)
Test: [ 300/6903]	Time  0.019 ( 0.035)	Loss 2.0487e-02 (3.2514e+00)	Acc@1 100.00 (  0.33)
Test: [ 400/6903]	Time  0.017 ( 0.033)	Loss 4.2272e-02 (2.4451e+00)	Acc@1 100.00 ( 25.19)
Test: [ 500/6903]	Time  0.016 ( 0.032)	Loss 1.3865e-01 (2.2222e+00)	Acc@1 100.00 ( 26.55)
Test: [ 600/6903]	Time  0.019 ( 0.032)	Loss 4.5212e+00 (2.0948e+00)	Acc@1   0.00 ( 33.61)
Test: [ 700/6903]	Time  0.019 ( 0.030)	Loss 1.7840e-02 (1.8751e+00)	Acc@1 100.00 ( 41.37)
Test: [ 800/6903]	Time  0.022 ( 0.029)	Loss 2.6954e-01 (1.8024e+00)	Acc@1 100.00 ( 42.07)
Test: [ 900/6903]	Time  0.017 ( 0.028)	Loss 3.9516e-02 (1.6145e+00)	Acc@1 100.00 ( 48.50)
Test: [1000/6903]	Time  0.021 ( 0.028)	Loss 1.3065e-01 (1.4572e+00)	Acc@1 100.00 ( 53.65)
Test: [1100/6903]	Time  0.017 ( 0.027)	Loss 6.5087e+00 (1.5699e+00)	Acc@1   0.00 ( 51.14)
Test: [1200/6903]	Time  0.020 ( 0.026)	Loss 6.4289e+00 (1.9449e+00)	Acc@1   0.00 ( 46.88)
Test: [1300/6903]	Time  0.012 ( 0.025)	Loss 6.7857e+00 (2.3003e+00)	Acc@1   0.00 ( 43.27)
Test: [1400/6903]	Time  0.016 ( 0.025)	Loss 5.1891e+00 (2.5528e+00)	Acc@1   0.00 ( 40.19)
Test: [1500/6903]	Time  0.020 ( 0.024)	Loss 5.6936e+00 (2.7371e+00)	Acc@1   0.00 ( 37.51)
Test: [1600/6903]	Time  0.017 ( 0.024)	Loss 5.0568e+00 (2.9029e+00)	Acc@1   0.00 ( 35.17)
Test: [1700/6903]	Time  0.024 ( 0.024)	Loss 5.5281e+00 (3.0346e+00)	Acc@1   0.00 ( 33.10)
Test: [1800/6903]	Time  0.022 ( 0.024)	Loss 5.5164e+00 (3.1676e+00)	Acc@1   0.00 ( 31.26)
Test: [1900/6903]	Time  0.021 ( 0.023)	Loss 6.5541e+00 (3.3311e+00)	Acc@1   0.00 ( 29.62)
Test: [2000/6903]	Time  0.016 ( 0.023)	Loss 6.4333e+00 (3.4908e+00)	Acc@1   0.00 ( 28.14)
Test: [2100/6903]	Time  0.021 ( 0.023)	Loss 1.8512e-02 (3.6065e+00)	Acc@1 100.00 ( 27.08)
Test: [2200/6903]	Time  0.017 ( 0.023)	Loss 1.1584e-02 (3.4431e+00)	Acc@1 100.00 ( 30.40)
Test: [2300/6903]	Time  0.016 ( 0.023)	Loss 2.9262e-02 (3.2946e+00)	Acc@1 100.00 ( 33.42)
Test: [2400/6903]	Time  0.017 ( 0.023)	Loss 1.1852e-02 (3.1582e+00)	Acc@1 100.00 ( 36.19)
Test: [2500/6903]	Time  0.020 ( 0.023)	Loss 5.5915e+00 (3.0907e+00)	Acc@1   0.00 ( 37.70)
Test: [2600/6903]	Time  0.020 ( 0.022)	Loss 5.8307e+00 (3.1915e+00)	Acc@1   0.00 ( 36.26)
Test: [2700/6903]	Time  0.019 ( 0.022)	Loss 4.9018e+00 (3.2842e+00)	Acc@1   0.00 ( 34.91)
Test: [2800/6903]	Time  0.020 ( 0.022)	Loss 3.7659e+00 (3.3296e+00)	Acc@1   0.00 ( 33.67)
Test: [2900/6903]	Time  0.018 ( 0.022)	Loss 8.1606e-01 (3.2865e+00)	Acc@1 100.00 ( 32.95)
Test: [3000/6903]	Time  0.022 ( 0.022)	Loss 1.8597e-01 (3.1898e+00)	Acc@1 100.00 ( 35.19)
Test: [3100/6903]	Time  0.021 ( 0.022)	Loss 8.9043e-03 (3.0906e+00)	Acc@1 100.00 ( 37.28)
Test: [3200/6903]	Time  0.021 ( 0.022)	Loss 2.1768e-02 (2.9946e+00)	Acc@1 100.00 ( 39.24)
Test: [3300/6903]	Time  0.020 ( 0.022)	Loss 2.7422e-02 (2.9046e+00)	Acc@1 100.00 ( 41.08)
Test: [3400/6903]	Time  0.021 ( 0.022)	Loss 2.9394e-02 (2.8199e+00)	Acc@1 100.00 ( 42.81)
Test: [3500/6903]	Time  0.021 ( 0.022)	Loss 3.8367e-02 (2.7402e+00)	Acc@1 100.00 ( 44.44)
Test: [3600/6903]	Time  0.022 ( 0.022)	Loss 1.0179e-01 (2.6653e+00)	Acc@1 100.00 ( 45.99)
Test: [3700/6903]	Time  0.019 ( 0.022)	Loss 2.6673e-01 (2.6014e+00)	Acc@1 100.00 ( 47.45)
Test: [3800/6903]	Time  0.021 ( 0.022)	Loss 2.1335e-01 (2.5403e+00)	Acc@1 100.00 ( 48.80)
Test: [3900/6903]	Time  0.022 ( 0.022)	Loss 6.8943e-02 (2.4786e+00)	Acc@1 100.00 ( 50.12)
Test: [4000/6903]	Time  0.021 ( 0.022)	Loss 3.2259e+00 (2.4296e+00)	Acc@1   0.00 ( 50.96)
Test: [4100/6903]	Time  0.018 ( 0.022)	Loss 1.4477e+00 (2.4029e+00)	Acc@1   0.00 ( 49.79)
Test: [4200/6903]	Time  0.037 ( 0.022)	Loss 2.2401e+00 (2.3934e+00)	Acc@1   0.00 ( 48.61)
Test: [4300/6903]	Time  0.051 ( 0.022)	Loss 2.7714e+00 (2.3951e+00)	Acc@1   0.00 ( 47.48)
Test: [4400/6903]	Time  0.038 ( 0.022)	Loss 7.4003e-02 (2.3874e+00)	Acc@1 100.00 ( 46.97)
Test: [4500/6903]	Time  0.023 ( 0.022)	Loss 1.0646e+00 (2.3379e+00)	Acc@1   0.00 ( 48.08)
Test: [4600/6903]	Time  0.015 ( 0.023)	Loss 1.9413e-02 (2.3173e+00)	Acc@1 100.00 ( 47.64)
Test: [4700/6903]	Time  0.016 ( 0.023)	Loss 5.3410e-01 (2.2735e+00)	Acc@1 100.00 ( 48.65)
Test: [4800/6903]	Time  0.015 ( 0.023)	Loss 1.6713e+00 (2.2764e+00)	Acc@1   0.00 ( 47.68)
Test: [4900/6903]	Time  0.014 ( 0.023)	Loss 3.1042e+00 (2.2781e+00)	Acc@1   0.00 ( 46.70)
Test: [5000/6903]	Time  0.024 ( 0.023)	Loss 3.7346e+00 (2.3085e+00)	Acc@1   0.00 ( 45.77)
Test: [5100/6903]	Time  0.048 ( 0.023)	Loss 4.7684e+00 (2.3445e+00)	Acc@1   0.00 ( 44.87)
Test: [5200/6903]	Time  0.037 ( 0.023)	Loss 8.6471e-02 (2.3212e+00)	Acc@1 100.00 ( 45.47)
Test: [5300/6903]	Time  0.036 ( 0.023)	Loss 1.8114e-02 (2.2778e+00)	Acc@1 100.00 ( 46.50)
Test: [5400/6903]	Time  0.040 ( 0.023)	Loss 1.1887e-01 (2.2415e+00)	Acc@1 100.00 ( 47.38)
Test: [5500/6903]	Time  0.015 ( 0.023)	Loss 8.0728e-03 (2.2015e+00)	Acc@1 100.00 ( 48.34)
Test: [5600/6903]	Time  0.017 ( 0.023)	Loss 3.5897e+00 (2.1674e+00)	Acc@1   0.00 ( 49.12)
Test: [5700/6903]	Time  0.023 ( 0.023)	Loss 1.2068e-01 (2.1482e+00)	Acc@1 100.00 ( 49.27)
Test: [5800/6903]	Time  0.014 ( 0.023)	Loss 2.1792e-02 (2.1120e+00)	Acc@1 100.00 ( 50.15)
Test: [5900/6903]	Time  0.017 ( 0.023)	Loss 1.4583e+00 (2.0795e+00)	Acc@1   0.00 ( 50.94)
Test: [6000/6903]	Time  0.022 ( 0.023)	Loss 5.6387e+00 (2.0971e+00)	Acc@1   0.00 ( 50.26)
Test: [6100/6903]	Time  0.015 ( 0.023)	Loss 3.9332e+00 (2.1531e+00)	Acc@1   0.00 ( 49.43)
Test: [6200/6903]	Time  0.020 ( 0.022)	Loss 2.0049e-02 (2.1257e+00)	Acc@1 100.00 ( 49.91)
Test: [6300/6903]	Time  0.020 ( 0.022)	Loss 7.9697e-02 (2.0931e+00)	Acc@1 100.00 ( 50.71)
Test: [6400/6903]	Time  0.017 ( 0.022)	Loss 9.2019e-02 (2.0623e+00)	Acc@1 100.00 ( 51.48)
Test: [6500/6903]	Time  0.019 ( 0.022)	Loss 6.7712e-01 (2.0378e+00)	Acc@1 100.00 ( 52.22)
Test: [6600/6903]	Time  0.023 ( 0.022)	Loss 3.9943e-01 (2.0155e+00)	Acc@1 100.00 ( 52.90)
Test: [6700/6903]	Time  0.014 ( 0.022)	Loss 1.6492e-01 (1.9904e+00)	Acc@1 100.00 ( 53.60)
Test: [6800/6903]	Time  0.024 ( 0.022)	Loss 2.2866e-02 (1.9628e+00)	Acc@1 100.00 ( 54.29)
Test: [6900/6903]	Time  0.017 ( 0.022)	Loss 2.0039e-02 (1.9346e+00)	Acc@1 100.00 ( 54.95)
 * Acc@1 54.962
test_acc1 = 55.0
Traceback (most recent call last):
  File "testing_bsp.py", line 477, in <module>
    main(args)
  File "testing_bsp.py", line 305, in main
    from bokeh.plotting import figure, show
ModuleNotFoundError: No module named 'bokeh'
