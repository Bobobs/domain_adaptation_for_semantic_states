Namespace(arch='convnext_base', batch_size=32, bottleneck_dim=256, data='Office31', epochs=20, iters_per_epoch=1000, log='bsp', lr=0.003, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', pretrain=None, pretrain_epochs=3, pretrain_lr=0.001, print_freq=100, ratio=[0.75, 1.3333333333333333], resize_size=224, root='data/office31', scale=[0.08, 1.0], scratch=False, seed=None, source=['A'], target=['W'], trade_off=1.0, trade_off_bsp=0.0002, train_resizing='default', val_resizing='default', weight_decay=0.001, workers=2)
=> using model 'convnext_base'
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:136: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top2, predicted2 = torch.topk(sm(output.data), 2, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:137: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top3, predicted3 = torch.topk(sm(output.data), 3, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:138: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top9, predicted9 = torch.topk(sm(output.data), 9, dim=1, largest=True, sorted=True)
Test: [   0/6903]	Time  6.170 ( 6.170)	Loss 1.3947e+00 (1.3947e+00)	Acc@1   0.00 (  0.00)
Test: [ 100/6903]	Time  0.035 ( 0.091)	Loss 3.0626e+00 (2.8265e+00)	Acc@1   0.00 (  0.00)
Test: [ 200/6903]	Time  0.024 ( 0.061)	Loss 3.2839e+00 (3.0061e+00)	Acc@1   0.00 (  0.00)
Test: [ 300/6903]	Time  0.023 ( 0.050)	Loss 2.3963e-02 (3.1684e+00)	Acc@1 100.00 (  0.33)
Test: [ 400/6903]	Time  0.028 ( 0.045)	Loss 1.8789e-03 (2.3810e+00)	Acc@1 100.00 ( 25.19)
Test: [ 500/6903]	Time  0.027 ( 0.041)	Loss 5.4233e-01 (1.9615e+00)	Acc@1 100.00 ( 39.72)
Test: [ 600/6903]	Time  0.030 ( 0.039)	Loss 3.7725e+00 (1.8589e+00)	Acc@1   0.00 ( 44.59)
Test: [ 700/6903]	Time  0.027 ( 0.037)	Loss 4.7003e-02 (1.6591e+00)	Acc@1 100.00 ( 50.78)
Test: [ 800/6903]	Time  0.029 ( 0.036)	Loss 1.2038e-01 (1.5454e+00)	Acc@1 100.00 ( 53.68)
Test: [ 900/6903]	Time  0.024 ( 0.035)	Loss 9.4048e-02 (1.3891e+00)	Acc@1 100.00 ( 58.82)
Test: [1000/6903]	Time  0.027 ( 0.034)	Loss 1.6542e-01 (1.2600e+00)	Acc@1 100.00 ( 62.94)
Test: [1100/6903]	Time  0.028 ( 0.034)	Loss 5.9677e+00 (1.3038e+00)	Acc@1   0.00 ( 61.40)
Test: [1200/6903]	Time  0.022 ( 0.034)	Loss 5.5711e+00 (1.6508e+00)	Acc@1   0.00 ( 56.29)
Test: [1300/6903]	Time  0.027 ( 0.033)	Loss 6.1104e+00 (1.9735e+00)	Acc@1   0.00 ( 51.96)
Test: [1400/6903]	Time  0.035 ( 0.033)	Loss 4.3551e+00 (2.2022e+00)	Acc@1   0.00 ( 48.25)
Test: [1500/6903]	Time  0.027 ( 0.033)	Loss 5.4390e+00 (2.3684e+00)	Acc@1   0.00 ( 45.04)
Test: [1600/6903]	Time  0.027 ( 0.033)	Loss 4.7529e+00 (2.5452e+00)	Acc@1   0.00 ( 42.22)
Test: [1700/6903]	Time  0.031 ( 0.033)	Loss 5.7281e+00 (2.6786e+00)	Acc@1   0.00 ( 39.74)
Test: [1800/6903]	Time  0.027 ( 0.033)	Loss 5.8319e+00 (2.8388e+00)	Acc@1   0.00 ( 37.53)
Test: [1900/6903]	Time  0.035 ( 0.033)	Loss 6.8919e+00 (3.0160e+00)	Acc@1   0.00 ( 35.56)
Test: [2000/6903]	Time  0.028 ( 0.032)	Loss 6.0685e+00 (3.2011e+00)	Acc@1   0.00 ( 33.78)
Test: [2100/6903]	Time  0.040 ( 0.032)	Loss 5.1243e-03 (3.3288e+00)	Acc@1 100.00 ( 32.46)
Test: [2200/6903]	Time  0.032 ( 0.032)	Loss 8.1165e-03 (3.1779e+00)	Acc@1 100.00 ( 35.53)
Test: [2300/6903]	Time  0.026 ( 0.032)	Loss 2.6527e-02 (3.0408e+00)	Acc@1 100.00 ( 38.33)
Test: [2400/6903]	Time  0.034 ( 0.032)	Loss 1.3891e-02 (2.9151e+00)	Acc@1 100.00 ( 40.90)
Test: [2500/6903]	Time  0.026 ( 0.032)	Loss 6.0861e+00 (2.8603e+00)	Acc@1   0.00 ( 42.22)
Test: [2600/6903]	Time  0.026 ( 0.032)	Loss 6.2264e+00 (2.9799e+00)	Acc@1   0.00 ( 40.60)
Test: [2700/6903]	Time  0.027 ( 0.032)	Loss 3.2468e+00 (3.0668e+00)	Acc@1   0.00 ( 39.10)
Test: [2800/6903]	Time  0.026 ( 0.031)	Loss 7.3265e-01 (3.0298e+00)	Acc@1 100.00 ( 37.99)
Test: [2900/6903]	Time  0.026 ( 0.031)	Loss 5.7268e-01 (2.9558e+00)	Acc@1 100.00 ( 39.23)
Test: [3000/6903]	Time  0.026 ( 0.031)	Loss 8.8555e-02 (2.8648e+00)	Acc@1 100.00 ( 41.25)
Test: [3100/6903]	Time  0.026 ( 0.031)	Loss 2.7791e-02 (2.7743e+00)	Acc@1 100.00 ( 43.15)
Test: [3200/6903]	Time  0.026 ( 0.031)	Loss 5.3016e-02 (2.6894e+00)	Acc@1 100.00 ( 44.92)
Test: [3300/6903]	Time  0.023 ( 0.030)	Loss 6.7674e-02 (2.6105e+00)	Acc@1 100.00 ( 46.59)
Test: [3400/6903]	Time  0.025 ( 0.030)	Loss 6.0297e-02 (2.5360e+00)	Acc@1 100.00 ( 48.16)
Test: [3500/6903]	Time  0.026 ( 0.030)	Loss 6.6909e-02 (2.4653e+00)	Acc@1 100.00 ( 49.64)
Test: [3600/6903]	Time  0.026 ( 0.030)	Loss 4.8090e-02 (2.3999e+00)	Acc@1 100.00 ( 51.04)
Test: [3700/6903]	Time  0.020 ( 0.030)	Loss 2.4073e-01 (2.3429e+00)	Acc@1 100.00 ( 52.36)
Test: [3800/6903]	Time  0.026 ( 0.030)	Loss 6.5489e-01 (2.2949e+00)	Acc@1 100.00 ( 53.59)
Test: [3900/6903]	Time  0.026 ( 0.030)	Loss 1.0440e-01 (2.2436e+00)	Acc@1 100.00 ( 54.78)
Test: [4000/6903]	Time  0.026 ( 0.030)	Loss 8.6916e-01 (2.1923e+00)	Acc@1   0.00 ( 55.64)
Test: [4100/6903]	Time  0.023 ( 0.029)	Loss 2.4580e+00 (2.1717e+00)	Acc@1   0.00 ( 54.74)
Test: [4200/6903]	Time  0.026 ( 0.029)	Loss 3.0460e+00 (2.1957e+00)	Acc@1   0.00 ( 53.44)
Test: [4300/6903]	Time  0.027 ( 0.029)	Loss 3.4942e+00 (2.2214e+00)	Acc@1   0.00 ( 52.20)
Test: [4400/6903]	Time  0.027 ( 0.029)	Loss 3.3104e-02 (2.2302e+00)	Acc@1 100.00 ( 51.58)
Test: [4500/6903]	Time  0.026 ( 0.029)	Loss 3.2222e-02 (2.1809e+00)	Acc@1 100.00 ( 52.65)
Test: [4600/6903]	Time  0.026 ( 0.029)	Loss 6.3879e-02 (2.1423e+00)	Acc@1 100.00 ( 53.23)
Test: [4700/6903]	Time  0.026 ( 0.029)	Loss 1.9622e-02 (2.1014e+00)	Acc@1 100.00 ( 54.12)
Test: [4800/6903]	Time  0.023 ( 0.029)	Loss 9.3378e-01 (2.0662e+00)	Acc@1   0.00 ( 54.63)
Test: [4900/6903]	Time  0.026 ( 0.029)	Loss 2.9054e+00 (2.0622e+00)	Acc@1   0.00 ( 53.72)
Test: [5000/6903]	Time  0.026 ( 0.029)	Loss 2.8379e+00 (2.0767e+00)	Acc@1   0.00 ( 52.65)
Test: [5100/6903]	Time  0.026 ( 0.029)	Loss 3.1544e+00 (2.0954e+00)	Acc@1   0.00 ( 51.62)
Test: [5200/6903]	Time  0.015 ( 0.029)	Loss 5.2346e-02 (2.0705e+00)	Acc@1 100.00 ( 52.09)
Test: [5300/6903]	Time  0.028 ( 0.029)	Loss 3.1023e-02 (2.0317e+00)	Acc@1 100.00 ( 52.99)
Test: [5400/6903]	Time  0.026 ( 0.028)	Loss 9.3109e-02 (1.9984e+00)	Acc@1 100.00 ( 53.77)
Test: [5500/6903]	Time  0.026 ( 0.028)	Loss 2.4580e-02 (1.9630e+00)	Acc@1 100.00 ( 54.61)
Test: [5600/6903]	Time  0.023 ( 0.028)	Loss 2.1734e+00 (1.9316e+00)	Acc@1   0.00 ( 55.28)
Test: [5700/6903]	Time  0.025 ( 0.028)	Loss 1.0931e-01 (1.9081e+00)	Acc@1 100.00 ( 55.76)
Test: [5800/6903]	Time  0.027 ( 0.028)	Loss 5.3379e-02 (1.8771e+00)	Acc@1 100.00 ( 56.52)
Test: [5900/6903]	Time  0.027 ( 0.028)	Loss 1.3747e+00 (1.8513e+00)	Acc@1   0.00 ( 57.08)
Test: [6000/6903]	Time  0.026 ( 0.028)	Loss 4.9937e+00 (1.8696e+00)	Acc@1   0.00 ( 56.12)
Test: [6100/6903]	Time  0.026 ( 0.028)	Loss 2.6252e+00 (1.9184e+00)	Acc@1   0.00 ( 55.20)
Test: [6200/6903]	Time  0.026 ( 0.028)	Loss 2.7172e-01 (1.8928e+00)	Acc@1 100.00 ( 55.83)
Test: [6300/6903]	Time  0.025 ( 0.028)	Loss 4.6655e-01 (1.8689e+00)	Acc@1 100.00 ( 56.53)
Test: [6400/6903]	Time  0.026 ( 0.028)	Loss 5.4557e-01 (1.8508e+00)	Acc@1 100.00 ( 56.57)
Test: [6500/6903]	Time  0.026 ( 0.028)	Loss 6.8200e-01 (1.8338e+00)	Acc@1 100.00 ( 56.95)
Test: [6600/6903]	Time  0.015 ( 0.028)	Loss 9.4784e-01 (1.8197e+00)	Acc@1   0.00 ( 56.96)
Test: [6700/6903]	Time  0.027 ( 0.028)	Loss 1.2658e-01 (1.8047e+00)	Acc@1 100.00 ( 56.68)
Test: [6800/6903]	Time  0.024 ( 0.028)	Loss 1.0676e-02 (1.7792e+00)	Acc@1 100.00 ( 57.32)
Test: [6900/6903]	Time  0.026 ( 0.028)	Loss 4.8688e-03 (1.7535e+00)	Acc@1 100.00 ( 57.93)
 * Acc@1 57.946
test_acc1 = 57.9
Traceback (most recent call last):
  File "testing_bsp.py", line 477, in <module>
    main(args)
  File "testing_bsp.py", line 305, in main
    from bokeh.plotting import figure, show
ModuleNotFoundError: No module named 'bokeh'
