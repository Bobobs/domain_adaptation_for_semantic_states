Namespace(arch='convnext_base', batch_size=32, bottleneck_dim=256, data='Office31', epochs=20, iters_per_epoch=1000, log='bsp', lr=0.003, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', pretrain=None, pretrain_epochs=3, pretrain_lr=0.001, print_freq=100, ratio=[0.75, 1.3333333333333333], resize_size=224, root='data/office31', scale=[0.08, 1.0], scratch=False, seed=None, source=['A'], target=['W'], trade_off=1.0, trade_off_bsp=0.0002, train_resizing='default', val_resizing='default', weight_decay=0.001, workers=2)
=> using model 'convnext_base'
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:136: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top2, predicted2 = torch.topk(sm(output.data), 2, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:137: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top3, predicted3 = torch.topk(sm(output.data), 3, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:138: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top9, predicted9 = torch.topk(sm(output.data), 9, dim=1, largest=True, sorted=True)
Test: [   0/6903]	Time  1.468 ( 1.468)	Loss 2.9860e+00 (2.9860e+00)	Acc@1   0.00 (  0.00)
Test: [ 100/6903]	Time  0.030 ( 0.038)	Loss 3.9321e+00 (3.6300e+00)	Acc@1   0.00 (  0.00)
Test: [ 200/6903]	Time  0.035 ( 0.032)	Loss 3.8983e+00 (3.8804e+00)	Acc@1   0.00 (  0.00)
Test: [ 300/6903]	Time  0.011 ( 0.030)	Loss 3.9741e-02 (3.8897e+00)	Acc@1 100.00 (  0.33)
Test: [ 400/6903]	Time  0.011 ( 0.029)	Loss 2.8834e-03 (2.9239e+00)	Acc@1 100.00 ( 25.19)
Test: [ 500/6903]	Time  0.010 ( 0.028)	Loss 2.3592e-01 (2.4218e+00)	Acc@1 100.00 ( 33.53)
Test: [ 600/6903]	Time  0.011 ( 0.028)	Loss 3.8410e+00 (2.2840e+00)	Acc@1   0.00 ( 39.43)
Test: [ 700/6903]	Time  0.011 ( 0.026)	Loss 4.8854e-02 (2.0308e+00)	Acc@1 100.00 ( 46.36)
Test: [ 800/6903]	Time  0.012 ( 0.025)	Loss 8.2941e-02 (1.8704e+00)	Acc@1 100.00 ( 49.81)
Test: [ 900/6903]	Time  0.018 ( 0.024)	Loss 3.0975e-02 (1.6680e+00)	Acc@1 100.00 ( 55.38)
Test: [1000/6903]	Time  0.019 ( 0.023)	Loss 8.6501e-03 (1.5036e+00)	Acc@1 100.00 ( 59.84)
Test: [1100/6903]	Time  0.014 ( 0.022)	Loss 3.1499e+00 (1.4515e+00)	Acc@1   0.00 ( 58.86)
Test: [1200/6903]	Time  0.015 ( 0.022)	Loss 2.9295e+00 (1.5496e+00)	Acc@1   0.00 ( 53.96)
Test: [1300/6903]	Time  0.013 ( 0.021)	Loss 3.3929e+00 (1.6622e+00)	Acc@1   0.00 ( 49.81)
Test: [1400/6903]	Time  0.018 ( 0.021)	Loss 2.8421e+00 (1.7492e+00)	Acc@1   0.00 ( 46.25)
Test: [1500/6903]	Time  0.012 ( 0.021)	Loss 2.3696e+00 (1.8071e+00)	Acc@1   0.00 ( 43.17)
Test: [1600/6903]	Time  0.018 ( 0.020)	Loss 2.5030e+00 (1.8437e+00)	Acc@1   0.00 ( 40.47)
Test: [1700/6903]	Time  0.011 ( 0.020)	Loss 2.1710e+00 (1.8640e+00)	Acc@1   0.00 ( 38.10)
Test: [1800/6903]	Time  0.021 ( 0.020)	Loss 2.9255e+00 (1.8926e+00)	Acc@1   0.00 ( 35.98)
Test: [1900/6903]	Time  0.024 ( 0.020)	Loss 3.7533e+00 (1.9671e+00)	Acc@1   0.00 ( 34.09)
Test: [2000/6903]	Time  0.018 ( 0.019)	Loss 3.7113e+00 (2.0526e+00)	Acc@1   0.00 ( 32.38)
Test: [2100/6903]	Time  0.013 ( 0.019)	Loss 8.9042e-02 (2.1230e+00)	Acc@1 100.00 ( 31.03)
Test: [2200/6903]	Time  0.025 ( 0.019)	Loss 8.6936e-02 (2.0306e+00)	Acc@1 100.00 ( 34.17)
Test: [2300/6903]	Time  0.019 ( 0.019)	Loss 1.7553e-01 (1.9479e+00)	Acc@1 100.00 ( 37.03)
Test: [2400/6903]	Time  0.013 ( 0.019)	Loss 1.5791e-01 (1.8739e+00)	Acc@1 100.00 ( 39.65)
Test: [2500/6903]	Time  0.012 ( 0.019)	Loss 4.2883e+00 (1.8512e+00)	Acc@1   0.00 ( 41.02)
Test: [2600/6903]	Time  0.012 ( 0.019)	Loss 4.4438e+00 (1.9468e+00)	Acc@1   0.00 ( 39.45)
Test: [2700/6903]	Time  0.011 ( 0.019)	Loss 1.2695e+00 (1.9840e+00)	Acc@1   0.00 ( 37.99)
Test: [2800/6903]	Time  0.011 ( 0.019)	Loss 5.2035e-01 (1.9457e+00)	Acc@1 100.00 ( 39.06)
Test: [2900/6903]	Time  0.011 ( 0.018)	Loss 1.1570e-01 (1.8910e+00)	Acc@1 100.00 ( 41.16)
Test: [3000/6903]	Time  0.027 ( 0.018)	Loss 5.0993e-02 (1.8307e+00)	Acc@1 100.00 ( 43.12)
Test: [3100/6903]	Time  0.011 ( 0.018)	Loss 3.3262e-02 (1.7735e+00)	Acc@1 100.00 ( 44.95)
Test: [3200/6903]	Time  0.012 ( 0.018)	Loss 1.5188e-02 (1.7193e+00)	Acc@1 100.00 ( 46.67)
Test: [3300/6903]	Time  0.012 ( 0.018)	Loss 2.2171e-02 (1.6679e+00)	Acc@1 100.00 ( 48.29)
Test: [3400/6903]	Time  0.012 ( 0.018)	Loss 7.5640e-02 (1.6201e+00)	Acc@1 100.00 ( 49.81)
Test: [3500/6903]	Time  0.020 ( 0.018)	Loss 1.3203e-01 (1.5768e+00)	Acc@1 100.00 ( 51.24)
Test: [3600/6903]	Time  0.011 ( 0.018)	Loss 1.3742e-02 (1.5344e+00)	Acc@1 100.00 ( 52.60)
Test: [3700/6903]	Time  0.013 ( 0.018)	Loss 6.3002e-03 (1.4933e+00)	Acc@1 100.00 ( 53.88)
Test: [3800/6903]	Time  0.017 ( 0.018)	Loss 2.1531e-01 (1.4619e+00)	Acc@1 100.00 ( 54.96)
Test: [3900/6903]	Time  0.013 ( 0.018)	Loss 3.4429e-02 (1.4272e+00)	Acc@1 100.00 ( 56.11)
Test: [4000/6903]	Time  0.011 ( 0.018)	Loss 3.9493e+00 (1.4084e+00)	Acc@1   0.00 ( 56.81)
Test: [4100/6903]	Time  0.011 ( 0.018)	Loss 3.0392e+00 (1.4602e+00)	Acc@1   0.00 ( 55.43)
Test: [4200/6903]	Time  0.032 ( 0.018)	Loss 4.3916e+00 (1.5156e+00)	Acc@1   0.00 ( 54.11)
Test: [4300/6903]	Time  0.037 ( 0.018)	Loss 3.6619e+00 (1.5692e+00)	Acc@1   0.00 ( 52.85)
Test: [4400/6903]	Time  0.011 ( 0.018)	Loss 2.9071e-02 (1.5954e+00)	Acc@1 100.00 ( 52.22)
Test: [4500/6903]	Time  0.035 ( 0.019)	Loss 2.2976e-02 (1.5603e+00)	Acc@1 100.00 ( 53.28)
Test: [4600/6903]	Time  0.040 ( 0.019)	Loss 1.6865e-02 (1.5367e+00)	Acc@1 100.00 ( 53.36)
Test: [4700/6903]	Time  0.039 ( 0.019)	Loss 7.6100e-01 (1.5093e+00)	Acc@1   0.00 ( 54.20)
Test: [4800/6903]	Time  0.039 ( 0.019)	Loss 4.7284e+00 (1.5409e+00)	Acc@1   0.00 ( 53.57)
Test: [4900/6903]	Time  0.040 ( 0.019)	Loss 4.1249e+00 (1.5856e+00)	Acc@1   0.00 ( 52.48)
Test: [5000/6903]	Time  0.039 ( 0.019)	Loss 4.3031e+00 (1.6434e+00)	Acc@1   0.00 ( 51.43)
Test: [5100/6903]	Time  0.040 ( 0.019)	Loss 5.0323e+00 (1.7031e+00)	Acc@1   0.00 ( 50.42)
Test: [5200/6903]	Time  0.040 ( 0.019)	Loss 1.1952e-01 (1.6938e+00)	Acc@1 100.00 ( 50.91)
Test: [5300/6903]	Time  0.039 ( 0.020)	Loss 6.0421e-02 (1.6622e+00)	Acc@1 100.00 ( 51.84)
Test: [5400/6903]	Time  0.041 ( 0.020)	Loss 2.8372e-02 (1.6341e+00)	Acc@1 100.00 ( 52.66)
Test: [5500/6903]	Time  0.012 ( 0.020)	Loss 9.0586e-03 (1.6046e+00)	Acc@1 100.00 ( 53.52)
Test: [5600/6903]	Time  0.017 ( 0.020)	Loss 3.2099e+00 (1.5805e+00)	Acc@1   0.00 ( 54.20)
Test: [5700/6903]	Time  0.012 ( 0.019)	Loss 1.7471e-01 (1.5665e+00)	Acc@1 100.00 ( 54.46)
Test: [5800/6903]	Time  0.012 ( 0.019)	Loss 8.4628e-02 (1.5416e+00)	Acc@1 100.00 ( 55.25)
Test: [5900/6903]	Time  0.012 ( 0.019)	Loss 3.4792e-01 (1.5172e+00)	Acc@1 100.00 ( 56.01)
Test: [6000/6903]	Time  0.011 ( 0.019)	Loss 2.7746e+00 (1.5130e+00)	Acc@1   0.00 ( 55.94)
Test: [6100/6903]	Time  0.018 ( 0.019)	Loss 3.1514e-01 (1.5290e+00)	Acc@1 100.00 ( 55.17)
Test: [6200/6903]	Time  0.018 ( 0.019)	Loss 3.2221e-02 (1.5050e+00)	Acc@1 100.00 ( 55.89)
Test: [6300/6903]	Time  0.012 ( 0.019)	Loss 3.1842e-01 (1.4843e+00)	Acc@1 100.00 ( 56.59)
Test: [6400/6903]	Time  0.012 ( 0.019)	Loss 3.2894e-02 (1.4645e+00)	Acc@1 100.00 ( 57.27)
Test: [6500/6903]	Time  0.013 ( 0.019)	Loss 1.8478e-02 (1.4422e+00)	Acc@1 100.00 ( 57.93)
Test: [6600/6903]	Time  0.012 ( 0.019)	Loss 1.1628e-01 (1.4240e+00)	Acc@1 100.00 ( 58.52)
Test: [6700/6903]	Time  0.026 ( 0.019)	Loss 5.2547e-03 (1.4042e+00)	Acc@1 100.00 ( 59.14)
Test: [6800/6903]	Time  0.014 ( 0.019)	Loss 7.5492e-03 (1.3837e+00)	Acc@1 100.00 ( 59.74)
Test: [6900/6903]	Time  0.018 ( 0.019)	Loss 3.2317e-03 (1.3637e+00)	Acc@1 100.00 ( 60.32)
 * Acc@1 60.336
test_acc1 = 60.3
Traceback (most recent call last):
  File "testing_bsp.py", line 477, in <module>
    main(args)
  File "testing_bsp.py", line 305, in main
    from bokeh.plotting import figure, show
ModuleNotFoundError: No module named 'bokeh'
