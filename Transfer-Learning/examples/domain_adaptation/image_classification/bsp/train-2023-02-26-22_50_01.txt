Namespace(arch='convnext_base', batch_size=32, bottleneck_dim=256, data='Office31', epochs=20, iters_per_epoch=1000, log='bsp', lr=0.003, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', pretrain=None, pretrain_epochs=3, pretrain_lr=0.001, print_freq=100, ratio=[0.75, 1.3333333333333333], resize_size=224, root='data/office31', scale=[0.08, 1.0], scratch=False, seed=None, source=['A'], target=['W'], trade_off=1.0, trade_off_bsp=0.0002, train_resizing='default', val_resizing='default', weight_decay=0.001, workers=2)
=> using model 'convnext_base'
Pretraining the model on source domain.
/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:257: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
lr: [0.0001, 0.001, 0.001]
Epoch: [0][   0/1000]	Time 3.0 (3.0)	Data 0.0 (0.0)	Loss 2.29 (2.29)	Cls Acc 15.6 (15.6)
Epoch: [0][ 100/1000]	Time 0.6 (0.7)	Data 0.0 (0.1)	Loss 1.52 (1.62)	Cls Acc 50.0 (45.2)
Epoch: [0][ 200/1000]	Time 0.6 (0.7)	Data 0.0 (0.1)	Loss 0.89 (1.38)	Cls Acc 71.9 (53.5)
Epoch: [0][ 300/1000]	Time 0.7 (0.7)	Data 0.1 (0.1)	Loss 1.09 (1.24)	Cls Acc 65.6 (58.1)
Epoch: [0][ 400/1000]	Time 0.7 (0.7)	Data 0.1 (0.1)	Loss 0.88 (1.15)	Cls Acc 68.8 (61.2)
Epoch: [0][ 500/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.93 (1.09)	Cls Acc 62.5 (63.3)
Epoch: [0][ 600/1000]	Time 0.9 (0.7)	Data 0.3 (0.1)	Loss 0.70 (1.04)	Cls Acc 68.8 (64.8)
Epoch: [0][ 700/1000]	Time 0.7 (0.7)	Data 0.1 (0.1)	Loss 0.81 (0.99)	Cls Acc 75.0 (66.3)
Epoch: [0][ 800/1000]	Time 0.7 (0.7)	Data 0.1 (0.1)	Loss 0.47 (0.96)	Cls Acc 81.2 (67.4)
Epoch: [0][ 900/1000]	Time 0.7 (0.7)	Data 0.1 (0.1)	Loss 0.72 (0.93)	Cls Acc 65.6 (68.1)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:136: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top2, predicted2 = torch.topk(sm(output.data), 2, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:137: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top3, predicted3 = torch.topk(sm(output.data), 3, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:138: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top9, predicted9 = torch.topk(sm(output.data), 9, dim=1, largest=True, sorted=True)
Test: [  0/295]	Time  1.311 ( 1.311)	Loss 4.4610e-01 (4.4610e-01)	Acc@1  87.50 ( 87.50)
Test: [100/295]	Time  0.554 ( 0.370)	Loss 4.3316e-01 (3.7643e-01)	Acc@1  81.25 ( 90.97)
Test: [200/295]	Time  0.570 ( 0.363)	Loss 3.6809e-01 (3.7389e-01)	Acc@1  93.75 ( 91.20)
 * Acc@1 91.095
lr: [5.946035575013605e-05, 0.0005946035575013605, 0.0005946035575013605]
Epoch: [1][   0/1000]	Time 0.6 (0.6)	Data 0.0 (0.0)	Loss 0.93 (0.93)	Cls Acc 62.5 (62.5)
Epoch: [1][ 100/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.83 (0.69)	Cls Acc 75.0 (74.8)
Epoch: [1][ 200/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.53 (0.66)	Cls Acc 81.2 (75.9)
Epoch: [1][ 300/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.64 (0.66)	Cls Acc 81.2 (76.1)
Epoch: [1][ 400/1000]	Time 0.8 (0.7)	Data 0.1 (0.1)	Loss 0.71 (0.66)	Cls Acc 71.9 (76.4)
Epoch: [1][ 500/1000]	Time 0.8 (0.7)	Data 0.1 (0.1)	Loss 0.70 (0.65)	Cls Acc 75.0 (76.7)
Epoch: [1][ 600/1000]	Time 0.7 (0.7)	Data 0.1 (0.1)	Loss 0.53 (0.64)	Cls Acc 81.2 (77.0)
Epoch: [1][ 700/1000]	Time 0.7 (0.7)	Data 0.1 (0.1)	Loss 0.60 (0.64)	Cls Acc 81.2 (77.0)
Epoch: [1][ 800/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.66 (0.63)	Cls Acc 78.1 (77.3)
Epoch: [1][ 900/1000]	Time 0.7 (0.7)	Data 0.1 (0.1)	Loss 0.44 (0.63)	Cls Acc 87.5 (77.4)
Test: [  0/295]	Time  1.010 ( 1.010)	Loss 3.0357e-01 (3.0357e-01)	Acc@1  93.75 ( 93.75)
Test: [100/295]	Time  0.132 ( 0.362)	Loss 4.1611e-01 (3.1047e-01)	Acc@1  87.50 ( 92.33)
Test: [200/295]	Time  0.128 ( 0.358)	Loss 3.1369e-01 (3.0667e-01)	Acc@1  93.75 ( 92.60)
 * Acc@1 92.604
lr: [4.3869133765083086e-05, 0.0004386913376508308, 0.0004386913376508308]
Epoch: [2][   0/1000]	Time 0.6 (0.6)	Data 0.0 (0.0)	Loss 0.61 (0.61)	Cls Acc 75.0 (75.0)
Epoch: [2][ 100/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.46 (0.58)	Cls Acc 84.4 (79.4)
Epoch: [2][ 200/1000]	Time 0.6 (0.7)	Data 0.0 (0.1)	Loss 0.58 (0.58)	Cls Acc 87.5 (79.1)
Epoch: [2][ 300/1000]	Time 0.7 (0.7)	Data 0.0 (0.1)	Loss 0.44 (0.57)	Cls Acc 90.6 (78.8)
Epoch: [2][ 400/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.65 (0.58)	Cls Acc 71.9 (78.6)
Epoch: [2][ 500/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.47 (0.58)	Cls Acc 84.4 (78.6)
Epoch: [2][ 600/1000]	Time 0.8 (0.7)	Data 0.1 (0.1)	Loss 0.77 (0.58)	Cls Acc 71.9 (78.6)
Epoch: [2][ 700/1000]	Time 0.8 (0.7)	Data 0.1 (0.1)	Loss 0.60 (0.58)	Cls Acc 84.4 (78.7)
Epoch: [2][ 800/1000]	Time 0.8 (0.7)	Data 0.2 (0.1)	Loss 0.66 (0.57)	Cls Acc 68.8 (78.8)
Epoch: [2][ 900/1000]	Time 0.8 (0.7)	Data 0.1 (0.1)	Loss 0.58 (0.57)	Cls Acc 78.1 (78.7)
Test: [  0/295]	Time  0.951 ( 0.951)	Loss 3.5028e-01 (3.5028e-01)	Acc@1  87.50 ( 87.50)
Test: [100/295]	Time  0.558 ( 0.367)	Loss 4.2678e-01 (2.8222e-01)	Acc@1  81.25 ( 92.76)
Test: [200/295]	Time  0.557 ( 0.367)	Loss 2.8116e-01 (2.7788e-01)	Acc@1  93.75 ( 93.19)
 * Acc@1 93.071
Pretraining process is done.
after pretraining lr: 0.00030000000000000003
Epoch: [0][   0/1000]	Time  3.54 ( 3.54)	Data  0.01 ( 0.01)	Loss   2.20 (  2.20)	Cls Acc 62.5 (62.5)	Domain Acc 59.4 (59.4)
Epoch: [0][ 100/1000]	Time  1.40 ( 1.37)	Data  0.02 ( 0.02)	Loss   1.14 (  1.54)	Cls Acc 75.0 (78.1)	Domain Acc 96.9 (85.7)
Epoch: [0][ 200/1000]	Time  1.41 ( 1.39)	Data  0.02 ( 0.02)	Loss   1.02 (  1.37)	Cls Acc 81.2 (78.4)	Domain Acc 98.4 (91.1)
Epoch: [0][ 300/1000]	Time  1.43 ( 1.40)	Data  0.02 ( 0.02)	Loss   1.34 (  1.28)	Cls Acc 68.8 (78.3)	Domain Acc 100.0 (93.6)
Epoch: [0][ 400/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.03 (  1.22)	Cls Acc 78.1 (78.4)	Domain Acc 95.3 (94.8)
Epoch: [0][ 500/1000]	Time  1.40 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.51 (  1.22)	Cls Acc 87.5 (78.4)	Domain Acc 75.0 (93.9)
Epoch: [0][ 600/1000]	Time  1.41 ( 1.42)	Data  0.03 ( 0.02)	Loss   1.66 (  1.52)	Cls Acc 56.2 (77.5)	Domain Acc 98.4 (88.3)
Epoch: [0][ 700/1000]	Time  1.42 ( 1.42)	Data  0.02 ( 0.02)	Loss   2.04 (  1.64)	Cls Acc 71.9 (77.1)	Domain Acc 65.6 (85.4)
Epoch: [0][ 800/1000]	Time  1.42 ( 1.42)	Data  0.02 ( 0.03)	Loss   2.22 (  1.69)	Cls Acc 84.4 (76.8)	Domain Acc 42.2 (83.6)
Epoch: [0][ 900/1000]	Time  1.42 ( 1.42)	Data  0.02 ( 0.03)	Loss   2.85 (  1.73)	Cls Acc 81.2 (76.5)	Domain Acc 26.6 (82.1)
Test: [  0/295]	Time  1.070 ( 1.070)	Loss 8.8281e+00 (8.8281e+00)	Acc@1  18.75 ( 18.75)
Test: [100/295]	Time  0.628 ( 0.367)	Loss 6.3579e+00 (7.0955e+00)	Acc@1  37.50 ( 27.41)
Test: [200/295]	Time  0.581 ( 0.364)	Loss 7.3655e+00 (6.9823e+00)	Acc@1  25.00 ( 28.33)
 * Acc@1 28.693
after pretraining lr: 0.00017838106725040818
Epoch: [1][   0/1000]	Time  1.30 ( 1.30)	Data  0.02 ( 0.02)	Loss   1.67 (  1.67)	Cls Acc 78.1 (78.1)	Domain Acc 60.9 (60.9)
Epoch: [1][ 100/1000]	Time  1.37 ( 1.37)	Data  0.02 ( 0.04)	Loss   1.46 (  2.06)	Cls Acc 65.6 (73.8)	Domain Acc 89.1 (64.1)
Epoch: [1][ 200/1000]	Time  1.42 ( 1.39)	Data  0.02 ( 0.04)	Loss   1.85 (  2.15)	Cls Acc 68.8 (73.5)	Domain Acc 78.1 (61.5)
Epoch: [1][ 300/1000]	Time  1.42 ( 1.40)	Data  0.02 ( 0.03)	Loss   1.97 (  2.18)	Cls Acc 78.1 (72.9)	Domain Acc 54.7 (60.5)
Epoch: [1][ 400/1000]	Time  1.44 ( 1.41)	Data  0.02 ( 0.03)	Loss   2.41 (  2.16)	Cls Acc 65.6 (72.7)	Domain Acc 46.9 (59.2)
Epoch: [1][ 500/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.62 (  2.12)	Cls Acc 56.2 (72.7)	Domain Acc 85.9 (59.0)
Epoch: [1][ 600/1000]	Time  1.41 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.82 (  2.10)	Cls Acc 59.4 (72.6)	Domain Acc 67.2 (60.0)
Epoch: [1][ 700/1000]	Time  1.44 ( 1.42)	Data  0.02 ( 0.03)	Loss   1.34 (  2.07)	Cls Acc 71.9 (72.8)	Domain Acc 76.6 (60.3)
Epoch: [1][ 800/1000]	Time  1.42 ( 1.42)	Data  0.02 ( 0.03)	Loss   1.34 (  2.02)	Cls Acc 78.1 (72.9)	Domain Acc 81.2 (60.8)
Epoch: [1][ 900/1000]	Time  1.42 ( 1.42)	Data  0.02 ( 0.03)	Loss   1.50 (  2.00)	Cls Acc 71.9 (72.7)	Domain Acc 87.5 (60.4)
Test: [  0/295]	Time  0.999 ( 0.999)	Loss 1.2778e+01 (1.2778e+01)	Acc@1  18.75 ( 18.75)
Test: [100/295]	Time  0.489 ( 0.361)	Loss 1.0266e+01 (1.1127e+01)	Acc@1  37.50 ( 27.85)
Test: [200/295]	Time  0.572 ( 0.357)	Loss 1.1451e+01 (1.0965e+01)	Acc@1  25.00 ( 28.61)
 * Acc@1 29.033
after pretraining lr: 0.00013160740129524923
Epoch: [2][   0/1000]	Time  1.31 ( 1.31)	Data  0.02 ( 0.02)	Loss   1.06 (  1.06)	Cls Acc 87.5 (87.5)	Domain Acc 92.2 (92.2)
Epoch: [2][ 100/1000]	Time  1.38 ( 1.35)	Data  0.02 ( 0.02)	Loss   1.91 (  1.78)	Cls Acc 78.1 (71.5)	Domain Acc 40.6 (60.8)
Epoch: [2][ 200/1000]	Time  1.40 ( 1.38)	Data  0.02 ( 0.03)	Loss   1.73 (  1.83)	Cls Acc 78.1 (72.0)	Domain Acc 50.0 (57.3)
Epoch: [2][ 300/1000]	Time  1.40 ( 1.39)	Data  0.02 ( 0.03)	Loss   2.06 (  1.85)	Cls Acc 71.9 (72.4)	Domain Acc 45.3 (54.5)
Epoch: [2][ 400/1000]	Time  1.41 ( 1.40)	Data  0.02 ( 0.03)	Loss   1.88 (  1.83)	Cls Acc 56.2 (72.6)	Domain Acc 54.7 (52.7)
Epoch: [2][ 500/1000]	Time  1.40 ( 1.40)	Data  0.02 ( 0.02)	Loss   1.66 (  1.80)	Cls Acc 84.4 (72.9)	Domain Acc 34.4 (52.8)
Epoch: [2][ 600/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.44 (  1.77)	Cls Acc 87.5 (73.3)	Domain Acc 56.2 (52.4)
Epoch: [2][ 700/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.02)	Loss   2.33 (  1.77)	Cls Acc 62.5 (73.2)	Domain Acc 34.4 (51.6)
Epoch: [2][ 800/1000]	Time  1.39 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.71 (  1.76)	Cls Acc 68.8 (73.4)	Domain Acc 45.3 (51.1)
Epoch: [2][ 900/1000]	Time  1.43 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.26 (  1.72)	Cls Acc 87.5 (73.9)	Domain Acc 46.9 (52.1)
Test: [  0/295]	Time  1.017 ( 1.017)	Loss 1.4260e+01 (1.4260e+01)	Acc@1  31.25 ( 31.25)
Test: [100/295]	Time  0.526 ( 0.364)	Loss 7.4201e+00 (1.0050e+01)	Acc@1  56.25 ( 42.45)
Test: [200/295]	Time  0.429 ( 0.358)	Loss 9.9843e+00 (9.8489e+00)	Acc@1  37.50 ( 43.91)
 * Acc@1 43.634
after pretraining lr: 0.00010606601717798215
Epoch: [3][   0/1000]	Time  1.31 ( 1.31)	Data  0.02 ( 0.02)	Loss   1.52 (  1.52)	Cls Acc 75.0 (75.0)	Domain Acc 64.1 (64.1)
Epoch: [3][ 100/1000]	Time  1.40 ( 1.35)	Data  0.02 ( 0.02)	Loss   1.56 (  1.63)	Cls Acc 78.1 (75.2)	Domain Acc 56.2 (45.7)
Epoch: [3][ 200/1000]	Time  1.41 ( 1.38)	Data  0.02 ( 0.02)	Loss   1.80 (  1.56)	Cls Acc 62.5 (75.4)	Domain Acc 45.3 (52.4)
Epoch: [3][ 300/1000]	Time  1.42 ( 1.40)	Data  0.02 ( 0.02)	Loss   1.51 (  1.55)	Cls Acc 68.8 (75.6)	Domain Acc 51.6 (52.2)
Epoch: [3][ 400/1000]	Time  1.43 ( 1.40)	Data  0.02 ( 0.02)	Loss   1.77 (  1.54)	Cls Acc 56.2 (75.9)	Domain Acc 31.2 (52.3)
Epoch: [3][ 500/1000]	Time  1.43 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.46 (  1.56)	Cls Acc 68.8 (75.6)	Domain Acc 75.0 (51.7)
Epoch: [3][ 600/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.15 (  1.55)	Cls Acc 78.1 (75.8)	Domain Acc 84.4 (52.3)
Epoch: [3][ 700/1000]	Time  1.42 ( 1.42)	Data  0.02 ( 0.03)	Loss   1.36 (  1.53)	Cls Acc 81.2 (75.9)	Domain Acc 67.2 (52.8)
Epoch: [3][ 800/1000]	Time  1.41 ( 1.42)	Data  0.02 ( 0.02)	Loss   1.34 (  1.53)	Cls Acc 78.1 (76.0)	Domain Acc 56.2 (52.8)
Epoch: [3][ 900/1000]	Time  1.40 ( 1.42)	Data  0.02 ( 0.02)	Loss   1.82 (  1.52)	Cls Acc 65.6 (76.2)	Domain Acc 35.9 (53.4)
Test: [  0/295]	Time  0.997 ( 0.997)	Loss 1.7363e+01 (1.7363e+01)	Acc@1  25.00 ( 25.00)
Test: [100/295]	Time  0.423 ( 0.362)	Loss 8.7178e+00 (1.1604e+01)	Acc@1  56.25 ( 44.99)
Test: [200/295]	Time  0.422 ( 0.356)	Loss 1.0900e+01 (1.1397e+01)	Acc@1  43.75 ( 46.58)
 * Acc@1 46.334
after pretraining lr: 8.972092687327323e-05
Epoch: [4][   0/1000]	Time  1.30 ( 1.30)	Data  0.02 ( 0.02)	Loss   1.25 (  1.25)	Cls Acc 81.2 (81.2)	Domain Acc 68.8 (68.8)
Epoch: [4][ 100/1000]	Time  1.37 ( 1.37)	Data  0.02 ( 0.04)	Loss   1.21 (  1.46)	Cls Acc 90.6 (76.7)	Domain Acc 67.2 (54.2)
Epoch: [4][ 200/1000]	Time  1.42 ( 1.38)	Data  0.02 ( 0.03)	Loss   1.60 (  1.42)	Cls Acc 65.6 (77.1)	Domain Acc 51.6 (57.4)
Epoch: [4][ 300/1000]	Time  1.41 ( 1.39)	Data  0.02 ( 0.02)	Loss   1.12 (  1.43)	Cls Acc 81.2 (77.3)	Domain Acc 87.5 (54.8)
Epoch: [4][ 400/1000]	Time  1.42 ( 1.40)	Data  0.02 ( 0.03)	Loss   1.54 (  1.42)	Cls Acc 81.2 (77.3)	Domain Acc 43.8 (55.8)
Epoch: [4][ 500/1000]	Time  1.43 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.48 (  1.42)	Cls Acc 75.0 (77.2)	Domain Acc 43.8 (57.1)
Epoch: [4][ 600/1000]	Time  1.40 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.35 (  1.42)	Cls Acc 87.5 (77.2)	Domain Acc 34.4 (56.1)
Epoch: [4][ 700/1000]	Time  1.41 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.85 (  1.42)	Cls Acc 68.8 (77.4)	Domain Acc 32.8 (55.7)
Epoch: [4][ 800/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.40 (  1.41)	Cls Acc 75.0 (77.5)	Domain Acc 54.7 (56.5)
Epoch: [4][ 900/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.37 (  1.41)	Cls Acc 78.1 (77.6)	Domain Acc 46.9 (55.3)
Test: [  0/295]	Time  0.975 ( 0.975)	Loss 1.8602e+01 (1.8602e+01)	Acc@1  31.25 ( 31.25)
Test: [100/295]	Time  0.390 ( 0.362)	Loss 1.0395e+01 (1.3545e+01)	Acc@1  56.25 ( 45.67)
Test: [200/295]	Time  0.289 ( 0.357)	Loss 1.3001e+01 (1.3297e+01)	Acc@1  43.75 ( 47.01)
 * Acc@1 46.759
after pretraining lr: 7.825422900366438e-05
Epoch: [5][   0/1000]	Time  1.31 ( 1.31)	Data  0.02 ( 0.02)	Loss   1.30 (  1.30)	Cls Acc 84.4 (84.4)	Domain Acc 45.3 (45.3)
Epoch: [5][ 100/1000]	Time  1.38 ( 1.37)	Data  0.02 ( 0.03)	Loss   1.13 (  1.44)	Cls Acc 84.4 (77.5)	Domain Acc 81.2 (48.8)
Epoch: [5][ 200/1000]	Time  1.41 ( 1.39)	Data  0.02 ( 0.03)	Loss   1.20 (  1.38)	Cls Acc 84.4 (77.6)	Domain Acc 56.2 (57.5)
Epoch: [5][ 300/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.75 (  1.39)	Cls Acc 65.6 (77.4)	Domain Acc 45.3 (55.9)
Epoch: [5][ 400/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.49 (  1.39)	Cls Acc 68.8 (77.4)	Domain Acc 53.1 (56.0)
Epoch: [5][ 500/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.40 (  1.36)	Cls Acc 78.1 (77.8)	Domain Acc 53.1 (58.1)
Epoch: [5][ 600/1000]	Time  1.42 ( 1.42)	Data  0.02 ( 0.03)	Loss   1.34 (  1.37)	Cls Acc 81.2 (78.0)	Domain Acc 65.6 (56.5)
Epoch: [5][ 700/1000]	Time  1.44 ( 1.42)	Data  0.02 ( 0.02)	Loss   1.34 (  1.36)	Cls Acc 71.9 (78.1)	Domain Acc 64.1 (56.8)
Epoch: [5][ 800/1000]	Time  1.40 ( 1.42)	Data  0.02 ( 0.02)	Loss   1.38 (  1.36)	Cls Acc 78.1 (78.2)	Domain Acc 46.9 (56.7)
Epoch: [5][ 900/1000]	Time  1.42 ( 1.42)	Data  0.02 ( 0.03)	Loss   1.19 (  1.36)	Cls Acc 81.2 (78.2)	Domain Acc 57.8 (56.6)
Test: [  0/295]	Time  0.992 ( 0.992)	Loss 1.6555e+01 (1.6555e+01)	Acc@1  18.75 ( 18.75)
Test: [100/295]	Time  0.134 ( 0.364)	Loss 9.1585e+00 (1.1759e+01)	Acc@1  25.00 ( 24.50)
Test: [200/295]	Time  0.130 ( 0.359)	Loss 1.0711e+01 (1.1535e+01)	Acc@1  18.75 ( 25.62)
 * Acc@1 24.973
after pretraining lr: 6.971042407276225e-05
Epoch: [6][   0/1000]	Time  1.30 ( 1.30)	Data  0.01 ( 0.01)	Loss   1.30 (  1.30)	Cls Acc 68.8 (68.8)	Domain Acc 57.8 (57.8)
Epoch: [6][ 100/1000]	Time  1.38 ( 1.35)	Data  0.02 ( 0.02)	Loss   1.22 (  1.34)	Cls Acc 84.4 (78.7)	Domain Acc 62.5 (54.7)
Epoch: [6][ 200/1000]	Time  1.40 ( 1.38)	Data  0.02 ( 0.03)	Loss   1.50 (  1.33)	Cls Acc 81.2 (78.8)	Domain Acc 48.4 (56.1)
Epoch: [6][ 300/1000]	Time  1.41 ( 1.39)	Data  0.02 ( 0.02)	Loss   1.41 (  1.33)	Cls Acc 78.1 (78.9)	Domain Acc 56.2 (55.2)
Epoch: [6][ 400/1000]	Time  1.40 ( 1.39)	Data  0.02 ( 0.02)	Loss   1.22 (  1.33)	Cls Acc 96.9 (78.8)	Domain Acc 37.5 (54.9)
Epoch: [6][ 500/1000]	Time  1.43 ( 1.40)	Data  0.02 ( 0.03)	Loss   1.27 (  1.32)	Cls Acc 75.0 (79.0)	Domain Acc 59.4 (55.9)
Epoch: [6][ 600/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.47 (  1.32)	Cls Acc 81.2 (79.0)	Domain Acc 40.6 (56.2)
Epoch: [6][ 700/1000]	Time  1.43 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.51 (  1.33)	Cls Acc 65.6 (79.0)	Domain Acc 53.1 (54.3)
Epoch: [6][ 800/1000]	Time  1.41 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.51 (  1.31)	Cls Acc 65.6 (79.1)	Domain Acc 71.9 (56.9)
Epoch: [6][ 900/1000]	Time  1.41 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.29 (  1.32)	Cls Acc 78.1 (79.2)	Domain Acc 43.8 (56.6)
Test: [  0/295]	Time  1.037 ( 1.037)	Loss 1.9509e+01 (1.9509e+01)	Acc@1  12.50 ( 12.50)
Test: [100/295]	Time  0.135 ( 0.364)	Loss 1.0562e+01 (1.3448e+01)	Acc@1  25.00 ( 21.10)
Test: [200/295]	Time  0.129 ( 0.360)	Loss 1.1963e+01 (1.3190e+01)	Acc@1  18.75 ( 21.83)
 * Acc@1 21.148
after pretraining lr: 6.306723114402858e-05
Epoch: [7][   0/1000]	Time  1.30 ( 1.30)	Data  0.01 ( 0.01)	Loss   1.24 (  1.24)	Cls Acc 78.1 (78.1)	Domain Acc 68.8 (68.8)
Epoch: [7][ 100/1000]	Time  1.38 ( 1.35)	Data  0.02 ( 0.02)	Loss   1.25 (  1.26)	Cls Acc 75.0 (80.6)	Domain Acc 71.9 (61.0)
Epoch: [7][ 200/1000]	Time  1.42 ( 1.38)	Data  0.02 ( 0.02)	Loss   1.19 (  1.29)	Cls Acc 78.1 (80.0)	Domain Acc 71.9 (56.4)
Epoch: [7][ 300/1000]	Time  1.42 ( 1.40)	Data  0.02 ( 0.02)	Loss   1.14 (  1.30)	Cls Acc 90.6 (80.0)	Domain Acc 42.2 (55.5)
Epoch: [7][ 400/1000]	Time  1.41 ( 1.40)	Data  0.02 ( 0.02)	Loss   1.43 (  1.29)	Cls Acc 75.0 (80.1)	Domain Acc 68.8 (55.9)
Epoch: [7][ 500/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.12 (  1.29)	Cls Acc 84.4 (80.1)	Domain Acc 51.6 (56.2)
Epoch: [7][ 600/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.28 (  1.29)	Cls Acc 78.1 (79.9)	Domain Acc 60.9 (56.6)
Epoch: [7][ 700/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.28 (  1.30)	Cls Acc 84.4 (80.0)	Domain Acc 57.8 (54.9)
Epoch: [7][ 800/1000]	Time  1.41 ( 1.42)	Data  0.02 ( 0.02)	Loss   1.41 (  1.30)	Cls Acc 75.0 (80.0)	Domain Acc 53.1 (55.2)
Epoch: [7][ 900/1000]	Time  1.41 ( 1.42)	Data  0.02 ( 0.02)	Loss   1.19 (  1.29)	Cls Acc 90.6 (80.0)	Domain Acc 65.6 (55.3)
Test: [  0/295]	Time  0.985 ( 0.985)	Loss 2.6899e+01 (2.6899e+01)	Acc@1  25.00 ( 25.00)
Test: [100/295]	Time  0.545 ( 0.369)	Loss 1.3944e+01 (1.9374e+01)	Acc@1  37.50 ( 34.59)
Test: [200/295]	Time  0.571 ( 0.361)	Loss 1.7826e+01 (1.8973e+01)	Acc@1  37.50 ( 36.07)
 * Acc@1 35.940
after pretraining lr: 5.7735026918962585e-05
Epoch: [8][   0/1000]	Time  1.31 ( 1.31)	Data  0.01 ( 0.01)	Loss   1.26 (  1.26)	Cls Acc 78.1 (78.1)	Domain Acc 50.0 (50.0)
Epoch: [8][ 100/1000]	Time  1.40 ( 1.36)	Data  0.02 ( 0.02)	Loss   1.28 (  1.26)	Cls Acc 84.4 (81.3)	Domain Acc 59.4 (58.1)
Epoch: [8][ 200/1000]	Time  1.41 ( 1.39)	Data  0.02 ( 0.03)	Loss   1.47 (  1.25)	Cls Acc 71.9 (81.3)	Domain Acc 54.7 (58.8)
Epoch: [8][ 300/1000]	Time  1.40 ( 1.40)	Data  0.02 ( 0.02)	Loss   1.39 (  1.25)	Cls Acc 68.8 (81.3)	Domain Acc 56.2 (58.6)
Epoch: [8][ 400/1000]	Time  1.40 ( 1.40)	Data  0.02 ( 0.03)	Loss   1.44 (  1.25)	Cls Acc 68.8 (81.2)	Domain Acc 46.9 (57.7)
Epoch: [8][ 500/1000]	Time  1.41 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.29 (  1.25)	Cls Acc 75.0 (81.4)	Domain Acc 45.3 (57.9)
Epoch: [8][ 600/1000]	Time  1.40 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.40 (  1.24)	Cls Acc 81.2 (81.4)	Domain Acc 54.7 (58.9)
Epoch: [8][ 700/1000]	Time  1.40 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.20 (  1.25)	Cls Acc 81.2 (81.5)	Domain Acc 50.0 (58.4)
Epoch: [8][ 800/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.31 (  1.26)	Cls Acc 81.2 (81.3)	Domain Acc 67.2 (57.7)
Epoch: [8][ 900/1000]	Time  1.43 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.19 (  1.25)	Cls Acc 84.4 (81.2)	Domain Acc 73.4 (58.6)
Test: [  0/295]	Time  0.992 ( 0.992)	Loss 2.6871e+01 (2.6871e+01)	Acc@1  12.50 ( 12.50)
Test: [100/295]	Time  0.352 ( 0.361)	Loss 1.4748e+01 (1.9657e+01)	Acc@1  25.00 ( 21.60)
Test: [200/295]	Time  0.282 ( 0.356)	Loss 1.7947e+01 (1.9248e+01)	Acc@1  18.75 ( 22.48)
 * Acc@1 21.785
after pretraining lr: 5.334838230116769e-05
Epoch: [9][   0/1000]	Time  1.31 ( 1.31)	Data  0.01 ( 0.01)	Loss   1.26 (  1.26)	Cls Acc 68.8 (68.8)	Domain Acc 53.1 (53.1)
Epoch: [9][ 100/1000]	Time  1.38 ( 1.37)	Data  0.02 ( 0.03)	Loss   1.24 (  1.25)	Cls Acc 84.4 (80.2)	Domain Acc 64.1 (56.5)
Epoch: [9][ 200/1000]	Time  1.41 ( 1.38)	Data  0.02 ( 0.03)	Loss   1.14 (  1.24)	Cls Acc 84.4 (80.6)	Domain Acc 67.2 (57.6)
Epoch: [9][ 300/1000]	Time  1.42 ( 1.39)	Data  0.02 ( 0.02)	Loss   1.17 (  1.25)	Cls Acc 87.5 (80.3)	Domain Acc 50.0 (57.9)
Epoch: [9][ 400/1000]	Time  1.42 ( 1.40)	Data  0.02 ( 0.03)	Loss   1.19 (  1.26)	Cls Acc 78.1 (80.1)	Domain Acc 67.2 (57.0)
Epoch: [9][ 500/1000]	Time  1.40 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.13 (  1.25)	Cls Acc 84.4 (80.1)	Domain Acc 60.9 (58.4)
Epoch: [9][ 600/1000]	Time  1.43 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.14 (  1.26)	Cls Acc 87.5 (80.2)	Domain Acc 59.4 (57.7)
Epoch: [9][ 700/1000]	Time  1.43 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.32 (  1.25)	Cls Acc 84.4 (80.5)	Domain Acc 54.7 (58.2)
Epoch: [9][ 800/1000]	Time  1.41 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.25 (  1.25)	Cls Acc 84.4 (80.4)	Domain Acc 53.1 (58.2)
Epoch: [9][ 900/1000]	Time  1.40 ( 1.42)	Data  0.02 ( 0.03)	Loss   1.29 (  1.26)	Cls Acc 78.1 (80.4)	Domain Acc 54.7 (57.4)
Test: [  0/295]	Time  1.081 ( 1.081)	Loss 2.5672e+01 (2.5672e+01)	Acc@1  18.75 ( 18.75)
Test: [100/295]	Time  0.135 ( 0.365)	Loss 1.5065e+01 (1.9757e+01)	Acc@1  25.00 ( 23.58)
Test: [200/295]	Time  0.131 ( 0.359)	Loss 1.8314e+01 (1.9339e+01)	Acc@1  18.75 ( 24.97)
 * Acc@1 24.251
after pretraining lr: 4.966800782285106e-05
Epoch: [10][   0/1000]	Time  1.31 ( 1.31)	Data  0.01 ( 0.01)	Loss   1.04 (  1.04)	Cls Acc 87.5 (87.5)	Domain Acc 75.0 (75.0)
Epoch: [10][ 100/1000]	Time  1.40 ( 1.36)	Data  0.02 ( 0.02)	Loss   1.28 (  1.26)	Cls Acc 87.5 (80.2)	Domain Acc 48.4 (56.7)
Epoch: [10][ 200/1000]	Time  1.41 ( 1.39)	Data  0.02 ( 0.03)	Loss   1.13 (  1.26)	Cls Acc 90.6 (80.7)	Domain Acc 62.5 (54.0)
Epoch: [10][ 300/1000]	Time  1.42 ( 1.40)	Data  0.02 ( 0.02)	Loss   0.96 (  1.25)	Cls Acc 90.6 (80.8)	Domain Acc 62.5 (56.0)
Epoch: [10][ 400/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.03 (  1.24)	Cls Acc 84.4 (81.1)	Domain Acc 64.1 (57.7)
Epoch: [10][ 500/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.09 (  1.24)	Cls Acc 81.2 (81.1)	Domain Acc 57.8 (57.6)
Epoch: [10][ 600/1000]	Time  1.44 ( 1.42)	Data  0.02 ( 0.03)	Loss   1.28 (  1.24)	Cls Acc 75.0 (81.2)	Domain Acc 50.0 (57.0)
Epoch: [10][ 700/1000]	Time  1.42 ( 1.42)	Data  0.02 ( 0.03)	Loss   1.21 (  1.24)	Cls Acc 87.5 (81.3)	Domain Acc 64.1 (56.9)
Epoch: [10][ 800/1000]	Time  1.40 ( 1.42)	Data  0.02 ( 0.02)	Loss   1.20 (  1.24)	Cls Acc 84.4 (81.3)	Domain Acc 57.8 (57.3)
Epoch: [10][ 900/1000]	Time  1.42 ( 1.42)	Data  0.02 ( 0.03)	Loss   1.12 (  1.24)	Cls Acc 81.2 (81.3)	Domain Acc 59.4 (57.7)
Test: [  0/295]	Time  0.986 ( 0.986)	Loss 2.1699e+01 (2.1699e+01)	Acc@1  25.00 ( 25.00)
Test: [100/295]	Time  0.545 ( 0.362)	Loss 1.1795e+01 (1.6253e+01)	Acc@1  31.25 ( 28.96)
Test: [200/295]	Time  0.301 ( 0.356)	Loss 1.5116e+01 (1.5904e+01)	Acc@1  31.25 ( 31.03)
 * Acc@1 30.755
after pretraining lr: 4.6530242955104985e-05
Epoch: [11][   0/1000]	Time  1.30 ( 1.30)	Data  0.01 ( 0.01)	Loss   1.28 (  1.28)	Cls Acc 78.1 (78.1)	Domain Acc 51.6 (51.6)
Epoch: [11][ 100/1000]	Time  1.38 ( 1.35)	Data  0.02 ( 0.02)	Loss   1.25 (  1.25)	Cls Acc 78.1 (80.7)	Domain Acc 65.6 (54.3)
Epoch: [11][ 200/1000]	Time  1.42 ( 1.38)	Data  0.02 ( 0.03)	Loss   1.12 (  1.25)	Cls Acc 84.4 (80.9)	Domain Acc 60.9 (55.1)
Epoch: [11][ 300/1000]	Time  1.42 ( 1.40)	Data  0.02 ( 0.03)	Loss   1.57 (  1.25)	Cls Acc 65.6 (80.6)	Domain Acc 54.7 (55.1)
Epoch: [11][ 400/1000]	Time  1.43 ( 1.40)	Data  0.02 ( 0.03)	Loss   1.02 (  1.24)	Cls Acc 81.2 (80.7)	Domain Acc 70.3 (56.8)
Epoch: [11][ 500/1000]	Time  1.43 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.27 (  1.24)	Cls Acc 75.0 (80.8)	Domain Acc 46.9 (56.9)
Epoch: [11][ 600/1000]	Time  1.43 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.33 (  1.24)	Cls Acc 81.2 (81.0)	Domain Acc 53.1 (56.7)
Epoch: [11][ 700/1000]	Time  3.14 ( 1.41)	Data  1.74 ( 0.03)	Loss   1.30 (  1.24)	Cls Acc 78.1 (81.3)	Domain Acc 59.4 (57.1)
Epoch: [11][ 800/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.06 (  1.24)	Cls Acc 81.2 (81.2)	Domain Acc 64.1 (56.9)
Epoch: [11][ 900/1000]	Time  1.44 ( 1.42)	Data  0.02 ( 0.03)	Loss   1.15 (  1.24)	Cls Acc 87.5 (81.3)	Domain Acc 59.4 (57.0)
Test: [  0/295]	Time  0.994 ( 0.994)	Loss 2.4691e+01 (2.4691e+01)	Acc@1  12.50 ( 12.50)
Test: [100/295]	Time  0.561 ( 0.370)	Loss 1.4163e+01 (1.8820e+01)	Acc@1  25.00 ( 22.09)
Test: [200/295]	Time  0.564 ( 0.363)	Loss 1.7312e+01 (1.8426e+01)	Acc@1  18.75 ( 23.10)
 * Acc@1 22.402
after pretraining lr: 4.381912897190635e-05
Epoch: [12][   0/1000]	Time  1.32 ( 1.32)	Data  0.01 ( 0.01)	Loss   1.35 (  1.35)	Cls Acc 78.1 (78.1)	Domain Acc 45.3 (45.3)
Epoch: [12][ 100/1000]	Time  1.40 ( 1.35)	Data  0.02 ( 0.02)	Loss   1.27 (  1.25)	Cls Acc 78.1 (81.7)	Domain Acc 57.8 (52.7)
Epoch: [12][ 200/1000]	Time  1.42 ( 1.38)	Data  0.02 ( 0.02)	Loss   1.06 (  1.24)	Cls Acc 87.5 (81.2)	Domain Acc 70.3 (57.1)
Epoch: [12][ 300/1000]	Time  1.42 ( 1.40)	Data  0.02 ( 0.02)	Loss   1.14 (  1.21)	Cls Acc 84.4 (81.8)	Domain Acc 56.2 (59.1)
Epoch: [12][ 400/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.29 (  1.22)	Cls Acc 84.4 (81.7)	Domain Acc 35.9 (56.5)
Epoch: [12][ 500/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.30 (  1.22)	Cls Acc 65.6 (81.8)	Domain Acc 50.0 (56.1)
Epoch: [12][ 600/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.33 (  1.22)	Cls Acc 78.1 (81.7)	Domain Acc 62.5 (57.6)
Epoch: [12][ 700/1000]	Time  1.43 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.25 (  1.22)	Cls Acc 78.1 (81.6)	Domain Acc 65.6 (57.6)
Epoch: [12][ 800/1000]	Time  1.42 ( 1.42)	Data  0.02 ( 0.02)	Loss   1.19 (  1.22)	Cls Acc 84.4 (81.7)	Domain Acc 56.2 (57.7)
Epoch: [12][ 900/1000]	Time  1.40 ( 1.42)	Data  0.02 ( 0.03)	Loss   1.20 (  1.22)	Cls Acc 78.1 (81.7)	Domain Acc 54.7 (57.8)
Test: [  0/295]	Time  1.035 ( 1.035)	Loss 2.3519e+01 (2.3519e+01)	Acc@1  25.00 ( 25.00)
Test: [100/295]	Time  0.543 ( 0.364)	Loss 1.3009e+01 (1.7736e+01)	Acc@1  31.25 ( 25.80)
Test: [200/295]	Time  0.576 ( 0.358)	Loss 1.6182e+01 (1.7365e+01)	Acc@1  31.25 ( 27.74)
 * Acc@1 27.439
after pretraining lr: 4.145006614859292e-05
Epoch: [13][   0/1000]	Time  1.30 ( 1.30)	Data  0.01 ( 0.01)	Loss   1.10 (  1.10)	Cls Acc 84.4 (84.4)	Domain Acc 59.4 (59.4)
Epoch: [13][ 100/1000]	Time  1.37 ( 1.36)	Data  0.02 ( 0.03)	Loss   1.18 (  1.16)	Cls Acc 84.4 (82.7)	Domain Acc 64.1 (65.1)
Epoch: [13][ 200/1000]	Time  1.41 ( 1.38)	Data  0.02 ( 0.03)	Loss   1.26 (  1.18)	Cls Acc 78.1 (82.1)	Domain Acc 59.4 (62.7)
Epoch: [13][ 300/1000]	Time  1.43 ( 1.39)	Data  0.02 ( 0.02)	Loss   1.25 (  1.19)	Cls Acc 81.2 (82.3)	Domain Acc 45.3 (60.2)
Epoch: [13][ 400/1000]	Time  1.43 ( 1.40)	Data  0.02 ( 0.02)	Loss   1.32 (  1.20)	Cls Acc 81.2 (82.4)	Domain Acc 53.1 (58.6)
Epoch: [13][ 500/1000]	Time  1.40 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.27 (  1.20)	Cls Acc 81.2 (82.4)	Domain Acc 67.2 (60.1)
Epoch: [13][ 600/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.27 (  1.20)	Cls Acc 75.0 (82.2)	Domain Acc 62.5 (60.3)
Epoch: [13][ 700/1000]	Time  1.40 ( 1.41)	Data  0.02 ( 0.03)	Loss   0.89 (  1.20)	Cls Acc 96.9 (82.2)	Domain Acc 65.6 (59.5)
Epoch: [13][ 800/1000]	Time  1.40 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.39 (  1.21)	Cls Acc 78.1 (82.2)	Domain Acc 53.1 (58.5)
Epoch: [13][ 900/1000]	Time  1.43 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.18 (  1.20)	Cls Acc 71.9 (82.1)	Domain Acc 70.3 (59.0)
Test: [  0/295]	Time  0.983 ( 0.983)	Loss 2.4892e+01 (2.4892e+01)	Acc@1  18.75 ( 18.75)
Test: [100/295]	Time  0.134 ( 0.367)	Loss 1.4204e+01 (1.8955e+01)	Acc@1  25.00 ( 23.33)
Test: [200/295]	Time  0.130 ( 0.362)	Loss 1.7277e+01 (1.8558e+01)	Acc@1  25.00 ( 24.63)
 * Acc@1 23.868
after pretraining lr: 3.9359793425308615e-05
Epoch: [14][   0/1000]	Time  1.30 ( 1.30)	Data  0.01 ( 0.01)	Loss   1.12 (  1.12)	Cls Acc 90.6 (90.6)	Domain Acc 65.6 (65.6)
Epoch: [14][ 100/1000]	Time  1.40 ( 1.37)	Data  0.02 ( 0.03)	Loss   1.10 (  1.26)	Cls Acc 87.5 (82.7)	Domain Acc 50.0 (46.6)
Epoch: [14][ 200/1000]	Time  1.40 ( 1.39)	Data  0.02 ( 0.03)	Loss   1.18 (  1.22)	Cls Acc 71.9 (81.9)	Domain Acc 75.0 (55.7)
Epoch: [14][ 300/1000]	Time  1.41 ( 1.40)	Data  0.02 ( 0.03)	Loss   1.20 (  1.21)	Cls Acc 81.2 (82.0)	Domain Acc 56.2 (59.1)
Epoch: [14][ 400/1000]	Time  1.40 ( 1.40)	Data  0.02 ( 0.03)	Loss   1.36 (  1.22)	Cls Acc 75.0 (81.9)	Domain Acc 54.7 (57.1)
Epoch: [14][ 500/1000]	Time  1.43 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.16 (  1.22)	Cls Acc 84.4 (82.1)	Domain Acc 64.1 (55.9)
Epoch: [14][ 600/1000]	Time  1.41 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.13 (  1.21)	Cls Acc 84.4 (82.2)	Domain Acc 56.2 (57.4)
Epoch: [14][ 700/1000]	Time  1.43 ( 1.42)	Data  0.02 ( 0.03)	Loss   1.18 (  1.21)	Cls Acc 87.5 (82.1)	Domain Acc 68.8 (57.5)
Epoch: [14][ 800/1000]	Time  1.42 ( 1.42)	Data  0.02 ( 0.03)	Loss   1.24 (  1.21)	Cls Acc 84.4 (82.2)	Domain Acc 62.5 (57.3)
Epoch: [14][ 900/1000]	Time  1.42 ( 1.42)	Data  0.02 ( 0.03)	Loss   1.32 (  1.21)	Cls Acc 62.5 (82.1)	Domain Acc 65.6 (57.3)
Test: [  0/295]	Time  1.024 ( 1.024)	Loss 2.3609e+01 (2.3609e+01)	Acc@1  25.00 ( 25.00)
Test: [100/295]	Time  0.452 ( 0.363)	Loss 1.3665e+01 (1.8188e+01)	Acc@1  31.25 ( 25.99)
Test: [200/295]	Time  0.338 ( 0.359)	Loss 1.6556e+01 (1.7812e+01)	Acc@1  37.50 ( 27.89)
 * Acc@1 27.609
after pretraining lr: 3.7500000000000003e-05
Epoch: [15][   0/1000]	Time  1.31 ( 1.31)	Data  0.01 ( 0.01)	Loss   1.12 (  1.12)	Cls Acc 84.4 (84.4)	Domain Acc 71.9 (71.9)
Epoch: [15][ 100/1000]	Time  1.40 ( 1.36)	Data  0.02 ( 0.02)	Loss   0.99 (  1.17)	Cls Acc 93.8 (82.5)	Domain Acc 54.7 (63.1)
Epoch: [15][ 200/1000]	Time  1.42 ( 1.39)	Data  0.02 ( 0.02)	Loss   1.34 (  1.19)	Cls Acc 87.5 (82.8)	Domain Acc 51.6 (59.2)
Epoch: [15][ 300/1000]	Time  1.43 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.14 (  1.20)	Cls Acc 93.8 (82.6)	Domain Acc 64.1 (58.2)
Epoch: [15][ 400/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   0.96 (  1.19)	Cls Acc 90.6 (82.7)	Domain Acc 78.1 (59.4)
Epoch: [15][ 500/1000]	Time  1.41 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.29 (  1.19)	Cls Acc 75.0 (82.9)	Domain Acc 62.5 (59.0)
Epoch: [15][ 600/1000]	Time  1.40 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.23 (  1.19)	Cls Acc 81.2 (82.8)	Domain Acc 48.4 (58.3)
Epoch: [15][ 700/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.22 (  1.19)	Cls Acc 84.4 (82.6)	Domain Acc 59.4 (58.4)
Epoch: [15][ 800/1000]	Time  1.43 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.50 (  1.19)	Cls Acc 62.5 (82.6)	Domain Acc 54.7 (58.9)
Epoch: [15][ 900/1000]	Time  1.42 ( 1.42)	Data  0.02 ( 0.03)	Loss   1.13 (  1.19)	Cls Acc 90.6 (82.6)	Domain Acc 51.6 (59.0)
Test: [  0/295]	Time  0.997 ( 0.997)	Loss 2.3895e+01 (2.3895e+01)	Acc@1  12.50 ( 12.50)
Test: [100/295]	Time  0.564 ( 0.365)	Loss 1.4470e+01 (1.8661e+01)	Acc@1  25.00 ( 21.29)
Test: [200/295]	Time  0.572 ( 0.358)	Loss 1.7172e+01 (1.8288e+01)	Acc@1  18.75 ( 22.11)
 * Acc@1 21.339
after pretraining lr: 3.583311502709878e-05
Epoch: [16][   0/1000]	Time  1.31 ( 1.31)	Data  0.02 ( 0.02)	Loss   1.28 (  1.28)	Cls Acc 81.2 (81.2)	Domain Acc 42.2 (42.2)
Epoch: [16][ 100/1000]	Time  1.38 ( 1.34)	Data  0.02 ( 0.02)	Loss   1.08 (  1.23)	Cls Acc 90.6 (83.0)	Domain Acc 57.8 (48.9)
Epoch: [16][ 200/1000]	Time  1.40 ( 1.37)	Data  0.02 ( 0.02)	Loss   0.94 (  1.18)	Cls Acc 96.9 (82.9)	Domain Acc 60.9 (57.3)
Epoch: [16][ 300/1000]	Time  1.42 ( 1.38)	Data  0.02 ( 0.02)	Loss   1.38 (  1.18)	Cls Acc 78.1 (82.9)	Domain Acc 56.2 (58.5)
Epoch: [16][ 400/1000]	Time  1.43 ( 1.39)	Data  0.02 ( 0.02)	Loss   0.97 (  1.19)	Cls Acc 90.6 (82.8)	Domain Acc 56.2 (57.5)
Epoch: [16][ 500/1000]	Time  1.41 ( 1.40)	Data  0.02 ( 0.03)	Loss   1.30 (  1.19)	Cls Acc 78.1 (83.0)	Domain Acc 56.2 (57.1)
Epoch: [16][ 600/1000]	Time  1.40 ( 1.40)	Data  0.02 ( 0.02)	Loss   1.07 (  1.19)	Cls Acc 84.4 (83.0)	Domain Acc 70.3 (57.8)
Epoch: [16][ 700/1000]	Time  1.40 ( 1.40)	Data  0.02 ( 0.03)	Loss   1.11 (  1.19)	Cls Acc 87.5 (82.9)	Domain Acc 60.9 (58.6)
Epoch: [16][ 800/1000]	Time  1.41 ( 1.40)	Data  0.02 ( 0.02)	Loss   1.51 (  1.19)	Cls Acc 75.0 (82.8)	Domain Acc 51.6 (58.1)
Epoch: [16][ 900/1000]	Time  1.41 ( 1.40)	Data  0.02 ( 0.02)	Loss   1.26 (  1.19)	Cls Acc 81.2 (82.8)	Domain Acc 60.9 (57.8)
Test: [  0/295]	Time  0.982 ( 0.982)	Loss 2.3895e+01 (2.3895e+01)	Acc@1  25.00 ( 25.00)
Test: [100/295]	Time  0.163 ( 0.361)	Loss 1.3916e+01 (1.8557e+01)	Acc@1  25.00 ( 24.94)
Test: [200/295]	Time  0.265 ( 0.356)	Loss 1.6992e+01 (1.8168e+01)	Acc@1  31.25 ( 26.90)
 * Acc@1 26.631
after pretraining lr: 3.432945239845196e-05
Epoch: [17][   0/1000]	Time  1.31 ( 1.31)	Data  0.01 ( 0.01)	Loss   1.15 (  1.15)	Cls Acc 87.5 (87.5)	Domain Acc 51.6 (51.6)
Epoch: [17][ 100/1000]	Time  1.38 ( 1.37)	Data  0.02 ( 0.03)	Loss   1.11 (  1.19)	Cls Acc 84.4 (82.9)	Domain Acc 67.2 (56.7)
Epoch: [17][ 200/1000]	Time  1.43 ( 1.39)	Data  0.02 ( 0.03)	Loss   1.14 (  1.19)	Cls Acc 84.4 (82.8)	Domain Acc 53.1 (57.7)
Epoch: [17][ 300/1000]	Time  1.42 ( 1.40)	Data  0.02 ( 0.02)	Loss   1.34 (  1.20)	Cls Acc 75.0 (82.6)	Domain Acc 43.8 (55.4)
Epoch: [17][ 400/1000]	Time  1.41 ( 1.40)	Data  0.02 ( 0.02)	Loss   1.15 (  1.20)	Cls Acc 87.5 (82.6)	Domain Acc 64.1 (55.7)
Epoch: [17][ 500/1000]	Time  1.40 ( 1.41)	Data  0.02 ( 0.02)	Loss   1.16 (  1.20)	Cls Acc 75.0 (82.4)	Domain Acc 59.4 (57.1)
Epoch: [17][ 600/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.36 (  1.20)	Cls Acc 78.1 (82.3)	Domain Acc 48.4 (56.5)
Epoch: [17][ 700/1000]	Time  1.42 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.04 (  1.21)	Cls Acc 90.6 (82.5)	Domain Acc 53.1 (55.3)
Epoch: [17][ 800/1000]	Time  1.41 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.01 (  1.20)	Cls Acc 87.5 (82.5)	Domain Acc 65.6 (56.4)
Epoch: [17][ 900/1000]	Time  1.44 ( 1.41)	Data  0.02 ( 0.03)	Loss   1.48 (  1.20)	Cls Acc 71.9 (82.5)	Domain Acc 56.2 (57.4)
Test: [  0/295]	Time  0.985 ( 0.985)	Loss 2.3997e+01 (2.3997e+01)	Acc@1  25.00 ( 25.00)
Test: [100/295]	Time  0.348 ( 0.355)	Loss 1.4360e+01 (1.9029e+01)	Acc@1  25.00 ( 24.26)
Test: [200/295]	Time  0.394 ( 0.350)	Loss 1.7556e+01 (1.8623e+01)	Acc@1  31.25 ( 26.09)
 * Acc@1 25.611
after pretraining lr: 3.2965225735734386e-05
Epoch: [18][   0/1000]	Time  1.30 ( 1.30)	Data  0.01 ( 0.01)	Loss   1.14 (  1.14)	Cls Acc 90.6 (90.6)	Domain Acc 60.9 (60.9)
Epoch: [18][ 100/1000]	Time  1.36 ( 1.34)	Data  0.02 ( 0.02)	Loss   1.12 (  1.20)	Cls Acc 87.5 (83.6)	Domain Acc 53.1 (51.5)
Epoch: [18][ 200/1000]	Time  1.36 ( 1.37)	Data  0.02 ( 0.04)	Loss   1.28 (  1.20)	Cls Acc 81.2 (83.5)	Domain Acc 57.8 (53.8)
Epoch: [18][ 300/1000]	Time  1.36 ( 1.37)	Data  0.02 ( 0.03)	Loss   1.24 (  1.19)	Cls Acc 84.4 (83.3)	Domain Acc 62.5 (55.3)
Epoch: [18][ 400/1000]	Time  1.35 ( 1.37)	Data  0.03 ( 0.03)	Loss   1.12 (  1.19)	Cls Acc 84.4 (83.2)	Domain Acc 46.9 (55.0)
Epoch: [18][ 500/1000]	Time  1.36 ( 1.37)	Data  0.02 ( 0.03)	Loss   1.21 (  1.19)	Cls Acc 81.2 (83.0)	Domain Acc 68.8 (56.4)
Epoch: [18][ 600/1000]	Time  1.33 ( 1.36)	Data  0.02 ( 0.03)	Loss   1.25 (  1.18)	Cls Acc 78.1 (83.1)	Domain Acc 53.1 (57.7)
Epoch: [18][ 700/1000]	Time  1.33 ( 1.36)	Data  0.02 ( 0.03)	Loss   1.12 (  1.19)	Cls Acc 84.4 (82.9)	Domain Acc 43.8 (56.6)
Epoch: [18][ 800/1000]	Time  1.32 ( 1.36)	Data  0.02 ( 0.03)	Loss   1.03 (  1.19)	Cls Acc 87.5 (83.0)	Domain Acc 59.4 (56.7)
Epoch: [18][ 900/1000]	Time  1.32 ( 1.35)	Data  0.02 ( 0.03)	Loss   1.11 (  1.18)	Cls Acc 87.5 (82.9)	Domain Acc 60.9 (57.1)
Test: [  0/295]	Time  0.974 ( 0.974)	Loss 2.1584e+01 (2.1584e+01)	Acc@1  25.00 ( 25.00)
Test: [100/295]	Time  0.123 ( 0.356)	Loss 1.2134e+01 (1.6789e+01)	Acc@1  37.50 ( 32.55)
Test: [200/295]	Time  0.121 ( 0.358)	Loss 1.5462e+01 (1.6431e+01)	Acc@1  37.50 ( 33.99)
 * Acc@1 33.539
after pretraining lr: 3.1721137903216925e-05
Epoch: [19][   0/1000]	Time  1.27 ( 1.27)	Data  0.02 ( 0.02)	Loss   1.26 (  1.26)	Cls Acc 90.6 (90.6)	Domain Acc 45.3 (45.3)
Epoch: [19][ 100/1000]	Time  1.30 ( 1.29)	Data  0.02 ( 0.02)	Loss   0.99 (  1.20)	Cls Acc 93.8 (82.8)	Domain Acc 57.8 (50.2)
Epoch: [19][ 200/1000]	Time  1.31 ( 1.30)	Data  0.02 ( 0.02)	Loss   1.16 (  1.17)	Cls Acc 81.2 (83.3)	Domain Acc 62.5 (57.0)
Epoch: [19][ 300/1000]	Time  1.32 ( 1.31)	Data  0.02 ( 0.02)	Loss   1.09 (  1.17)	Cls Acc 87.5 (83.4)	Domain Acc 56.2 (59.2)
Epoch: [19][ 400/1000]	Time  1.33 ( 1.32)	Data  0.02 ( 0.03)	Loss   1.08 (  1.17)	Cls Acc 90.6 (83.6)	Domain Acc 53.1 (56.7)
Epoch: [19][ 500/1000]	Time  1.33 ( 1.32)	Data  0.02 ( 0.03)	Loss   1.06 (  1.18)	Cls Acc 81.2 (83.2)	Domain Acc 57.8 (56.2)
Traceback (most recent call last):
  File "cloth_bsp.py", line 461, in <module>
    main(args)
  File "cloth_bsp.py", line 279, in main
    train(train_source_iter, train_target_iter, classifier, domain_adv, bsp_penalty, optimizer,
  File "cloth_bsp.py", line 367, in train
    optimizer.step()
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/optim/optimizer.py", line 140, in wrapper
    out = func(*args, **kwargs)
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/optim/optimizer.py", line 23, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/optim/sgd.py", line 151, in step
    sgd(params_with_grad,
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/optim/sgd.py", line 202, in sgd
    func(params,
  File "/home/gtzelepis/miniconda3/envs/domain_adaptation/lib/python3.8/site-packages/torch/optim/sgd.py", line 238, in _single_tensor_sgd
    buf.mul_(momentum).add_(d_p, alpha=1 - dampening)
KeyboardInterrupt
