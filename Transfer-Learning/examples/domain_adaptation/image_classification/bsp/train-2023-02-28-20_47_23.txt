Namespace(arch='convnext_base', batch_size=32, bottleneck_dim=256, data='Office31', epochs=20, iters_per_epoch=1000, log='bsp', lr=0.003, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', pretrain=None, pretrain_epochs=3, pretrain_lr=0.001, print_freq=100, ratio=[0.75, 1.3333333333333333], resize_size=224, root='data/office31', scale=[0.08, 1.0], scratch=False, seed=None, source=['A'], target=['W'], trade_off=1.0, trade_off_bsp=0.0002, train_resizing='default', val_resizing='default', weight_decay=0.001, workers=2)
=> using model 'convnext_base'
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:136: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top2, predicted2 = torch.topk(sm(output.data), 2, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:137: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top3, predicted3 = torch.topk(sm(output.data), 3, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:138: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top9, predicted9 = torch.topk(sm(output.data), 9, dim=1, largest=True, sorted=True)
Test: [   0/6903]	Time  2.678 ( 2.678)	Loss 4.8415e+00 (4.8415e+00)	Acc@1   0.00 (  0.00)
Test: [ 100/6903]	Time  0.035 ( 0.052)	Loss 5.7469e+00 (5.4914e+00)	Acc@1   0.00 (  0.00)
Test: [ 200/6903]	Time  0.030 ( 0.039)	Loss 6.1546e+00 (5.7111e+00)	Acc@1   0.00 (  0.00)
Test: [ 300/6903]	Time  0.025 ( 0.035)	Loss 4.7745e-03 (5.8000e+00)	Acc@1 100.00 (  0.33)
Test: [ 400/6903]	Time  0.020 ( 0.033)	Loss 6.5091e-04 (4.3543e+00)	Acc@1 100.00 ( 25.19)
Test: [ 500/6903]	Time  0.015 ( 0.032)	Loss 6.0265e-01 (3.5138e+00)	Acc@1 100.00 ( 38.92)
Test: [ 600/6903]	Time  0.018 ( 0.031)	Loss 1.8096e+00 (3.0944e+00)	Acc@1   0.00 ( 43.93)
Test: [ 700/6903]	Time  0.018 ( 0.029)	Loss 9.1142e-03 (2.6873e+00)	Acc@1 100.00 ( 50.21)
Test: [ 800/6903]	Time  0.014 ( 0.028)	Loss 2.6741e-01 (2.5257e+00)	Acc@1 100.00 ( 49.06)
Test: [ 900/6903]	Time  0.018 ( 0.028)	Loss 6.3936e-02 (2.2627e+00)	Acc@1 100.00 ( 54.72)
Test: [1000/6903]	Time  0.018 ( 0.027)	Loss 1.1697e-01 (2.0415e+00)	Acc@1 100.00 ( 59.24)
Test: [1100/6903]	Time  0.014 ( 0.026)	Loss 4.6896e+00 (1.9653e+00)	Acc@1   0.00 ( 59.31)
Test: [1200/6903]	Time  0.017 ( 0.026)	Loss 4.1584e+00 (2.1149e+00)	Acc@1   0.00 ( 54.37)
Test: [1300/6903]	Time  0.014 ( 0.025)	Loss 3.6852e+00 (2.2530e+00)	Acc@1   0.00 ( 50.19)
Test: [1400/6903]	Time  0.030 ( 0.025)	Loss 2.0387e+00 (2.2914e+00)	Acc@1   0.00 ( 46.61)
Test: [1500/6903]	Time  0.020 ( 0.024)	Loss 2.7898e+00 (2.2948e+00)	Acc@1   0.00 ( 43.50)
Test: [1600/6903]	Time  0.018 ( 0.024)	Loss 2.5584e+00 (2.3099e+00)	Acc@1   0.00 ( 40.79)
Test: [1700/6903]	Time  0.028 ( 0.023)	Loss 3.0313e+00 (2.3186e+00)	Acc@1   0.00 ( 38.39)
Test: [1800/6903]	Time  0.012 ( 0.023)	Loss 3.0075e+00 (2.3490e+00)	Acc@1   0.00 ( 36.26)
Test: [1900/6903]	Time  0.011 ( 0.023)	Loss 4.1675e+00 (2.4123e+00)	Acc@1   0.00 ( 34.35)
Test: [2000/6903]	Time  0.011 ( 0.023)	Loss 4.8523e+00 (2.5211e+00)	Acc@1   0.00 ( 32.63)
Test: [2100/6903]	Time  0.014 ( 0.023)	Loss 1.9143e-02 (2.6130e+00)	Acc@1 100.00 ( 31.37)
Test: [2200/6903]	Time  0.014 ( 0.022)	Loss 1.8121e-02 (2.4950e+00)	Acc@1 100.00 ( 34.48)
Test: [2300/6903]	Time  0.018 ( 0.022)	Loss 2.9858e-02 (2.3878e+00)	Acc@1 100.00 ( 37.33)
Test: [2400/6903]	Time  0.013 ( 0.022)	Loss 2.3380e-02 (2.2896e+00)	Acc@1 100.00 ( 39.94)
Test: [2500/6903]	Time  0.014 ( 0.022)	Loss 4.5925e+00 (2.2480e+00)	Acc@1   0.00 ( 41.30)
Test: [2600/6903]	Time  0.015 ( 0.022)	Loss 5.1372e+00 (2.3435e+00)	Acc@1   0.00 ( 39.72)
Test: [2700/6903]	Time  0.014 ( 0.022)	Loss 1.5902e+00 (2.3921e+00)	Acc@1   0.00 ( 38.25)
Test: [2800/6903]	Time  0.014 ( 0.022)	Loss 2.5459e-01 (2.3394e+00)	Acc@1 100.00 ( 38.66)
Test: [2900/6903]	Time  0.016 ( 0.022)	Loss 4.4644e-01 (2.2721e+00)	Acc@1 100.00 ( 40.78)
Test: [3000/6903]	Time  0.015 ( 0.021)	Loss 5.2958e-02 (2.2040e+00)	Acc@1 100.00 ( 42.75)
Test: [3100/6903]	Time  0.015 ( 0.021)	Loss 1.7419e-02 (2.1341e+00)	Acc@1 100.00 ( 44.60)
Test: [3200/6903]	Time  0.015 ( 0.021)	Loss 1.1838e-02 (2.0679e+00)	Acc@1 100.00 ( 46.33)
Test: [3300/6903]	Time  0.013 ( 0.021)	Loss 1.4810e-02 (2.0058e+00)	Acc@1 100.00 ( 47.96)
Test: [3400/6903]	Time  0.027 ( 0.021)	Loss 4.0195e-02 (1.9479e+00)	Acc@1 100.00 ( 49.49)
Test: [3500/6903]	Time  0.014 ( 0.021)	Loss 4.8050e-02 (1.8935e+00)	Acc@1 100.00 ( 50.93)
Test: [3600/6903]	Time  0.014 ( 0.021)	Loss 1.2537e-01 (1.8421e+00)	Acc@1 100.00 ( 52.29)
Test: [3700/6903]	Time  0.011 ( 0.021)	Loss 2.5733e-01 (1.8010e+00)	Acc@1 100.00 ( 53.58)
Test: [3800/6903]	Time  0.015 ( 0.021)	Loss 4.3976e-01 (1.7680e+00)	Acc@1 100.00 ( 54.72)
Test: [3900/6903]	Time  0.016 ( 0.021)	Loss 7.4932e-02 (1.7285e+00)	Acc@1 100.00 ( 55.88)
Test: [4000/6903]	Time  0.017 ( 0.021)	Loss 6.1506e+00 (1.7135e+00)	Acc@1   0.00 ( 56.59)
Test: [4100/6903]	Time  0.011 ( 0.021)	Loss 5.1599e+00 (1.8098e+00)	Acc@1   0.00 ( 55.21)
Test: [4200/6903]	Time  0.011 ( 0.021)	Loss 5.6601e+00 (1.9066e+00)	Acc@1   0.00 ( 53.89)
Test: [4300/6903]	Time  0.011 ( 0.021)	Loss 5.5291e+00 (1.9929e+00)	Acc@1   0.00 ( 52.64)
Test: [4400/6903]	Time  0.014 ( 0.021)	Loss 5.4824e-03 (2.0439e+00)	Acc@1 100.00 ( 52.01)
Test: [4500/6903]	Time  0.042 ( 0.021)	Loss 1.1644e-02 (1.9986e+00)	Acc@1 100.00 ( 53.08)
Test: [4600/6903]	Time  0.018 ( 0.021)	Loss 1.4954e-01 (1.9587e+00)	Acc@1 100.00 ( 54.01)
Test: [4700/6903]	Time  0.022 ( 0.022)	Loss 1.7516e-01 (1.9227e+00)	Acc@1 100.00 ( 54.86)
Test: [4800/6903]	Time  0.015 ( 0.022)	Loss 4.8358e+00 (1.9616e+00)	Acc@1   0.00 ( 54.34)
Test: [4900/6903]	Time  0.013 ( 0.022)	Loss 4.3392e+00 (2.0088e+00)	Acc@1   0.00 ( 53.23)
Test: [5000/6903]	Time  0.011 ( 0.022)	Loss 4.5997e+00 (2.0616e+00)	Acc@1   0.00 ( 52.17)
Test: [5100/6903]	Time  0.012 ( 0.022)	Loss 4.9426e+00 (2.1159e+00)	Acc@1   0.00 ( 51.15)
Test: [5200/6903]	Time  0.018 ( 0.022)	Loss 7.3243e-01 (2.1006e+00)	Acc@1   0.00 ( 51.57)
Test: [5300/6903]	Time  0.014 ( 0.022)	Loss 1.3350e-02 (2.0632e+00)	Acc@1 100.00 ( 52.41)
Test: [5400/6903]	Time  0.025 ( 0.022)	Loss 3.1977e-01 (2.0294e+00)	Acc@1 100.00 ( 53.19)
Test: [5500/6903]	Time  0.024 ( 0.022)	Loss 4.8375e-03 (1.9935e+00)	Acc@1 100.00 ( 54.04)
Test: [5600/6903]	Time  0.012 ( 0.022)	Loss 4.5378e+00 (1.9646e+00)	Acc@1   0.00 ( 54.72)
Test: [5700/6903]	Time  0.017 ( 0.022)	Loss 1.9609e-01 (1.9571e+00)	Acc@1 100.00 ( 54.53)
Test: [5800/6903]	Time  0.016 ( 0.022)	Loss 1.9693e-02 (1.9245e+00)	Acc@1 100.00 ( 55.32)
Test: [5900/6903]	Time  0.020 ( 0.022)	Loss 3.6261e-01 (1.8939e+00)	Acc@1 100.00 ( 56.08)
Test: [6000/6903]	Time  0.015 ( 0.022)	Loss 2.5840e+00 (1.8879e+00)	Acc@1   0.00 ( 56.02)
Test: [6100/6903]	Time  0.017 ( 0.022)	Loss 1.8498e+00 (1.8989e+00)	Acc@1   0.00 ( 55.11)
Test: [6200/6903]	Time  0.016 ( 0.022)	Loss 4.4671e-02 (1.8696e+00)	Acc@1 100.00 ( 55.80)
Test: [6300/6903]	Time  0.014 ( 0.022)	Loss 1.3436e-01 (1.8418e+00)	Acc@1 100.00 ( 56.50)
Test: [6400/6903]	Time  0.027 ( 0.022)	Loss 9.9754e-02 (1.8160e+00)	Acc@1 100.00 ( 57.18)
Test: [6500/6903]	Time  0.018 ( 0.022)	Loss 1.4725e+00 (1.8014e+00)	Acc@1 100.00 ( 57.58)
Test: [6600/6903]	Time  0.013 ( 0.022)	Loss 5.9990e-01 (1.7903e+00)	Acc@1 100.00 ( 58.11)
Test: [6700/6903]	Time  0.017 ( 0.022)	Loss 1.5232e-01 (1.7716e+00)	Acc@1 100.00 ( 58.74)
Test: [6800/6903]	Time  0.011 ( 0.022)	Loss 8.5588e-02 (1.7468e+00)	Acc@1 100.00 ( 59.34)
Test: [6900/6903]	Time  0.014 ( 0.022)	Loss 1.0508e-01 (1.7241e+00)	Acc@1 100.00 ( 59.93)
 * Acc@1 59.945
test_acc1 = 59.9
Traceback (most recent call last):
  File "testing_bsp.py", line 477, in <module>
    main(args)
  File "testing_bsp.py", line 305, in main
    from bokeh.plotting import figure, show
ModuleNotFoundError: No module named 'bokeh'
