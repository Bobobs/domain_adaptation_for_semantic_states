Namespace(arch='convnext_base', batch_size=32, bottleneck_dim=256, data='Office31', epochs=20, iters_per_epoch=1000, log='bsp', lr=0.003, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', pretrain=None, pretrain_epochs=3, pretrain_lr=0.001, print_freq=100, ratio=[0.75, 1.3333333333333333], resize_size=224, root='data/office31', scale=[0.08, 1.0], scratch=False, seed=None, source=['A'], target=['W'], trade_off=1.0, trade_off_bsp=0.0002, train_resizing='default', val_resizing='default', weight_decay=0.001, workers=2)
=> using model 'convnext_base'
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:136: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top2, predicted2 = torch.topk(sm(output.data), 2, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:137: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top3, predicted3 = torch.topk(sm(output.data), 3, dim=1, largest=True, sorted=True)
/home/gtzelepis/Transfer-Learning-Library/examples/domain_adaptation/image_classification/utils.py:138: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  top9, predicted9 = torch.topk(sm(output.data), 9, dim=1, largest=True, sorted=True)
Test: [   0/6903]	Time  1.929 ( 1.929)	Loss 1.6183e+00 (1.6183e+00)	Acc@1   0.00 (  0.00)
Test: [ 100/6903]	Time  0.014 ( 0.044)	Loss 3.1658e+00 (2.5374e+00)	Acc@1   0.00 (  0.00)
Test: [ 200/6903]	Time  0.011 ( 0.035)	Loss 2.8103e+00 (2.6537e+00)	Acc@1   0.00 (  0.00)
Test: [ 300/6903]	Time  0.013 ( 0.032)	Loss 1.2930e-01 (2.6876e+00)	Acc@1 100.00 (  0.33)
Test: [ 400/6903]	Time  0.024 ( 0.031)	Loss 2.1379e-02 (2.0370e+00)	Acc@1 100.00 ( 25.19)
Test: [ 500/6903]	Time  0.019 ( 0.030)	Loss 7.2774e-02 (1.8431e+00)	Acc@1 100.00 ( 29.74)
Test: [ 600/6903]	Time  0.014 ( 0.030)	Loss 3.2706e+00 (1.7417e+00)	Acc@1   0.00 ( 36.27)
Test: [ 700/6903]	Time  0.018 ( 0.028)	Loss 8.0310e-03 (1.5477e+00)	Acc@1 100.00 ( 43.65)
Test: [ 800/6903]	Time  0.019 ( 0.027)	Loss 2.0579e-01 (1.4708e+00)	Acc@1 100.00 ( 47.32)
Test: [ 900/6903]	Time  0.018 ( 0.026)	Loss 4.0331e-02 (1.3170e+00)	Acc@1 100.00 ( 53.16)
Test: [1000/6903]	Time  0.019 ( 0.025)	Loss 2.1451e-01 (1.1949e+00)	Acc@1 100.00 ( 57.84)
Test: [1100/6903]	Time  0.014 ( 0.025)	Loss 5.5378e+00 (1.2624e+00)	Acc@1   0.00 ( 56.77)
Test: [1200/6903]	Time  0.016 ( 0.024)	Loss 5.5271e+00 (1.6021e+00)	Acc@1   0.00 ( 52.04)
Test: [1300/6903]	Time  0.016 ( 0.024)	Loss 5.9890e+00 (1.9235e+00)	Acc@1   0.00 ( 48.04)
Test: [1400/6903]	Time  0.016 ( 0.023)	Loss 4.1631e+00 (2.1427e+00)	Acc@1   0.00 ( 44.61)
Test: [1500/6903]	Time  0.040 ( 0.023)	Loss 5.3033e+00 (2.3065e+00)	Acc@1   0.00 ( 41.64)
Test: [1600/6903]	Time  0.016 ( 0.022)	Loss 4.1636e+00 (2.4550e+00)	Acc@1   0.00 ( 39.04)
Test: [1700/6903]	Time  0.013 ( 0.022)	Loss 4.6846e+00 (2.5631e+00)	Acc@1   0.00 ( 36.74)
Test: [1800/6903]	Time  0.013 ( 0.022)	Loss 4.9230e+00 (2.6777e+00)	Acc@1   0.00 ( 34.70)
Test: [1900/6903]	Time  0.022 ( 0.022)	Loss 6.2097e+00 (2.8366e+00)	Acc@1   0.00 ( 32.88)
Test: [2000/6903]	Time  0.017 ( 0.021)	Loss 7.0716e+00 (3.0325e+00)	Acc@1   0.00 ( 31.23)
Test: [2100/6903]	Time  0.022 ( 0.021)	Loss 7.4336e-03 (3.1992e+00)	Acc@1 100.00 ( 30.03)
Test: [2200/6903]	Time  0.020 ( 0.021)	Loss 4.9552e-03 (3.0541e+00)	Acc@1 100.00 ( 33.21)
Test: [2300/6903]	Time  0.019 ( 0.021)	Loss 1.5820e-02 (2.9219e+00)	Acc@1 100.00 ( 36.11)
Test: [2400/6903]	Time  0.012 ( 0.020)	Loss 5.9063e-03 (2.8007e+00)	Acc@1 100.00 ( 38.78)
Test: [2500/6903]	Time  0.021 ( 0.020)	Loss 6.2703e+00 (2.7553e+00)	Acc@1   0.00 ( 40.18)
Test: [2600/6903]	Time  0.015 ( 0.020)	Loss 6.6208e+00 (2.8944e+00)	Acc@1   0.00 ( 38.64)
Test: [2700/6903]	Time  0.014 ( 0.020)	Loss 3.9754e+00 (3.0027e+00)	Acc@1   0.00 ( 37.21)
Test: [2800/6903]	Time  0.024 ( 0.020)	Loss 2.5334e+00 (3.0170e+00)	Acc@1   0.00 ( 35.88)
Test: [2900/6903]	Time  0.013 ( 0.020)	Loss 5.9323e-01 (2.9661e+00)	Acc@1 100.00 ( 35.71)
Test: [3000/6903]	Time  0.013 ( 0.020)	Loss 2.6970e-01 (2.8781e+00)	Acc@1 100.00 ( 37.85)
Test: [3100/6903]	Time  0.012 ( 0.020)	Loss 6.5124e-02 (2.7918e+00)	Acc@1 100.00 ( 39.86)
Test: [3200/6903]	Time  0.013 ( 0.019)	Loss 6.7387e-02 (2.7070e+00)	Acc@1 100.00 ( 41.74)
Test: [3300/6903]	Time  0.019 ( 0.019)	Loss 1.1968e-01 (2.6276e+00)	Acc@1 100.00 ( 43.50)
Test: [3400/6903]	Time  0.014 ( 0.019)	Loss 1.2277e-01 (2.5541e+00)	Acc@1 100.00 ( 45.16)
Test: [3500/6903]	Time  0.011 ( 0.019)	Loss 1.7852e-01 (2.4859e+00)	Acc@1 100.00 ( 46.73)
Test: [3600/6903]	Time  0.012 ( 0.019)	Loss 6.8448e-02 (2.4217e+00)	Acc@1 100.00 ( 48.21)
Test: [3700/6903]	Time  0.017 ( 0.019)	Loss 8.0400e-02 (2.3593e+00)	Acc@1 100.00 ( 49.61)
Test: [3800/6903]	Time  0.026 ( 0.019)	Loss 4.2234e-01 (2.3080e+00)	Acc@1 100.00 ( 50.83)
Test: [3900/6903]	Time  0.016 ( 0.019)	Loss 4.6793e-02 (2.2537e+00)	Acc@1 100.00 ( 52.09)
Test: [4000/6903]	Time  0.045 ( 0.019)	Loss 2.1934e+00 (2.2077e+00)	Acc@1   0.00 ( 52.89)
Test: [4100/6903]	Time  0.032 ( 0.019)	Loss 2.2672e+00 (2.2021e+00)	Acc@1   0.00 ( 51.60)
Test: [4200/6903]	Time  0.036 ( 0.019)	Loss 2.9084e+00 (2.2203e+00)	Acc@1   0.00 ( 50.37)
Test: [4300/6903]	Time  0.037 ( 0.020)	Loss 3.1720e+00 (2.2375e+00)	Acc@1   0.00 ( 49.20)
Test: [4400/6903]	Time  0.012 ( 0.020)	Loss 7.8644e-02 (2.2399e+00)	Acc@1 100.00 ( 48.65)
Test: [4500/6903]	Time  0.011 ( 0.020)	Loss 9.0251e-02 (2.1916e+00)	Acc@1 100.00 ( 49.79)
Test: [4600/6903]	Time  0.012 ( 0.020)	Loss 1.9860e-02 (2.1679e+00)	Acc@1 100.00 ( 49.71)
Test: [4700/6903]	Time  0.012 ( 0.021)	Loss 2.0510e-01 (2.1271e+00)	Acc@1 100.00 ( 50.65)
Test: [4800/6903]	Time  0.060 ( 0.021)	Loss 1.6746e+00 (2.1071e+00)	Acc@1   0.00 ( 50.22)
Test: [4900/6903]	Time  0.038 ( 0.021)	Loss 2.3540e+00 (2.0990e+00)	Acc@1   0.00 ( 49.19)
Test: [5000/6903]	Time  0.038 ( 0.021)	Loss 2.1455e+00 (2.1042e+00)	Acc@1   0.00 ( 48.21)
Test: [5100/6903]	Time  0.038 ( 0.021)	Loss 2.8639e+00 (2.1110e+00)	Acc@1   0.00 ( 47.27)
Test: [5200/6903]	Time  0.038 ( 0.021)	Loss 9.9429e-02 (2.0844e+00)	Acc@1 100.00 ( 47.82)
Test: [5300/6903]	Time  0.040 ( 0.021)	Loss 9.0112e-03 (2.0456e+00)	Acc@1 100.00 ( 48.80)
Test: [5400/6903]	Time  0.041 ( 0.021)	Loss 1.2259e-01 (2.0174e+00)	Acc@1 100.00 ( 49.62)
Test: [5500/6903]	Time  0.017 ( 0.021)	Loss 3.8497e-03 (1.9813e+00)	Acc@1 100.00 ( 50.54)
Test: [5600/6903]	Time  0.012 ( 0.021)	Loss 3.1692e+00 (1.9513e+00)	Acc@1   0.00 ( 51.28)
Test: [5700/6903]	Time  0.012 ( 0.021)	Loss 7.7876e-02 (1.9269e+00)	Acc@1 100.00 ( 51.87)
Test: [5800/6903]	Time  0.027 ( 0.021)	Loss 6.4859e-02 (1.8948e+00)	Acc@1 100.00 ( 52.70)
Test: [5900/6903]	Time  0.014 ( 0.021)	Loss 1.5302e+00 (1.8689e+00)	Acc@1   0.00 ( 53.40)
Test: [6000/6903]	Time  0.011 ( 0.021)	Loss 5.9681e+00 (1.9016e+00)	Acc@1   0.00 ( 52.51)
Test: [6100/6903]	Time  0.019 ( 0.021)	Loss 4.4091e+00 (1.9670e+00)	Acc@1   0.00 ( 51.65)
Test: [6200/6903]	Time  0.023 ( 0.021)	Loss 8.8978e-02 (1.9458e+00)	Acc@1 100.00 ( 51.98)
Test: [6300/6903]	Time  0.011 ( 0.021)	Loss 3.9481e-01 (1.9199e+00)	Acc@1 100.00 ( 52.74)
Test: [6400/6903]	Time  0.012 ( 0.021)	Loss 3.1877e-01 (1.8974e+00)	Acc@1 100.00 ( 53.48)
Test: [6500/6903]	Time  0.017 ( 0.021)	Loss 3.6262e-01 (1.8727e+00)	Acc@1 100.00 ( 54.19)
Test: [6600/6903]	Time  0.015 ( 0.021)	Loss 6.1464e-01 (1.8541e+00)	Acc@1 100.00 ( 54.84)
Test: [6700/6903]	Time  0.017 ( 0.020)	Loss 8.8562e-02 (1.8353e+00)	Acc@1 100.00 ( 55.51)
Test: [6800/6903]	Time  0.012 ( 0.020)	Loss 1.9369e-02 (1.8091e+00)	Acc@1 100.00 ( 56.17)
Test: [6900/6903]	Time  0.012 ( 0.020)	Loss 8.2500e-03 (1.7830e+00)	Acc@1 100.00 ( 56.80)
 * Acc@1 56.816
test_acc1 = 56.8
Traceback (most recent call last):
  File "testing_bsp.py", line 477, in <module>
    main(args)
  File "testing_bsp.py", line 305, in main
    from bokeh.plotting import figure, show
ModuleNotFoundError: No module named 'bokeh'
